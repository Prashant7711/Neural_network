{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55856bdc",
   "metadata": {},
   "source": [
    "## Importing the neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8de8b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5df092d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12508c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0  6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1  6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2  6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3  7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4  7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "\n",
       "       CO     NOX  \n",
       "0  3.1547  82.722  \n",
       "1  3.2363  82.776  \n",
       "2  3.2012  82.468  \n",
       "3  3.1923  82.670  \n",
       "4  3.2484  82.311  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt = pd.read_csv(\"gas_turbines.csv\")\n",
    "df_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d90059b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 11)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39fb5a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_gt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c285560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>44.103000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
       "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
       "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
       "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
       "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
       "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
       "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
       "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
       "\n",
       "                NOX  \n",
       "count  15039.000000  \n",
       "mean      68.190934  \n",
       "std       10.470586  \n",
       "min       27.765000  \n",
       "25%       61.303500  \n",
       "50%       66.601000  \n",
       "75%       73.935500  \n",
       "max      119.890000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd1f4289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      0\n",
       "AP      0\n",
       "AH      0\n",
       "AFDP    0\n",
       "GTEP    0\n",
       "TIT     0\n",
       "TAT     0\n",
       "TEY     0\n",
       "CDP     0\n",
       "CO      0\n",
       "NOX     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8627e87e",
   "metadata": {},
   "source": [
    "## Correlation matrix with the help of heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65eb9f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAHYCAYAAAAlPfX6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADuEElEQVR4nOzdd3gUxRvA8e/c5dJ7hRB6r9JRpCNIt1fsBcSCov5sqAiKXVQElWLHigUQUEQRAkiX3jskIb335G5+f1xMIQVCkrsLeT/Pcw/Z3Xfv3uG2zc7MntJaI4QQQgghhBDVzWDvBIQQQgghhBAXJ6lsCCGEEEIIIWqEVDaEEEIIIYQQNUIqG0IIIYQQQogaIZUNIYQQQgghRI2QyoYQQgghhBCiRkhlQwghhBBCCFEjyq1sKKUa2TIRIYQQQgghxMWlopaNRbZKQgghhBBCCFGzlFKfKqVilVJ7ylmulFIzlVJHlFK7lFJdq/qZFVU2VFXfXAghhBBCCOEwPgeGVbB8ONCy4DUO+KiqH+hUwbIGSqmZ5S3UWk+s6ocLIYQQQgghbENrHa6UalJByFXAl1prDWxUSvkqpeprrc9c6GdWVNnIAraVs0xf6AcKIYQQQgghHFID4HSx6YiCeTVS2UjQWn9x9kylVB/gFuDL8lZUSo3D2vTCw4bgbsMMvheaX630z5xd9k7B5iJPJds7BZu7+Wo/e6dgc+6mPHunYHMhron2TsGmwmK22DsFm/vFfI29U7C5QK+6ty8bVd27Tzrvywu+Pqy1fninSa0YBrDM1LraN8hR+YfGU3D9XWCu1npuJd+mrP+/KuVaUWUjt/BTleoM3ArcCBwHfqroTQsKNhdq5j9TCCGEEEIIUaT49XcVRAANi02HAVFVecOKKht3KqVexNqKkQB8Dyit9cCqfKAQQgghhBB1mTI5bAPMEuBhpdR3QC8gpSrjNaDiysZ+YC0wWmt9BEApNakqHyaEEEIIIURdZ3CyT2VDKfUtMAAIVEpFAFMAE4DW+mNgOTACOAJkAndX9TMrqmxcB9wM/K2U+h34DnkcrhBCCCGEELWS1vqWcyzXwEPV+ZnlVja01r8AvyilPICrgUlAiFLqI+AXrfUf1ZmIEEIIIYQQdYEyVfRTdxeXc5ZUa52htf5aaz0K6yCRHcAzNZ2YEEIIIYQQonarqBtVKVrrRGBOwUsIIYQQQghRSfYas2EPlapsCCGEEEIIIarGgZ9GVe3qTocxIYQQQgghhE1Jy4YQQgghhBA2VJe6UUnLhhBCCCGEEKJGSMuGEEIIIYQQNiRjNoQQQgghhBCiiqRlQwghhBBCCBuqS2M2amVlo9O8VwkeMYDc2ATCu4wuM6bdu5MJHtYfc1Y2O+99htTt+wAIGtqXdjMmo4wGTn+6kKNvzbNl6lUyspeR1g2N5OVrflqbT1SCLjd21KVOdG1pYNpXuQAE+iiu6+tEaIBi5TYz6/aYbZV2lYwd7kWnls7k5mnmL0rl5Jn8UjH3Xe1N68bOZOVYAJi/KJVT0fm0aWJi4s2+xCdby7p1fw5L1mTYNP/K0lrz8+evs2/7Wkwuroyd8AoNm7UrFRf++zesWb6A+JjTTJ8Xjqe3X6XWdyRaa7775C12/7sOZxdX7n54Ko2bty0VFxcTybwZz5KRnkKjpm2499FXcDKZOLhnK7Nff5yA4FAAul46iNE3jrN1Mc7btq2bmT/nQ8wWC0OvHM71N95SYrnWmnlzZrN1y2ZcXFx47PGnaN6iJQBLFv3MHyuWo7Vm6LARXHX1dfYoQqWt332Qt79Zitli4Zp+Pbh75IASy1f/u48Pf1mJQSmMRgNP3jKKLq2aFC43WyzcNnUWQX7ezHzsLpvmfqG01qz4djpHdodjcnZlzD2vUb9x+1Jxv8x7kqgTezAaTYQ27cjI26didDIRf+YYSz57luhT+xh4zWNcduW9dihF5dTV49ePn73B3u1rcXZx5fYHXy4z5/jYCD577yky01Np2LQtdzzyKk5OJjLTU1nw0YvEx5zGZHJh7ISphDZqaYeSVM7dV/vTpa0bObmaD7+L53hkbplxNw/35dJLPLBYNCv/SeO3dWmVWv9ipox1p7JRK7tRRXzxM5tH3Vfu8qBh/fBo0YTVbYeye8ILdJj1knWBwUD7mS+yefR9rOk0ktCbR+HZtrltkq6iVmEGAn0MzPgxl0Xr8xnTu/x6YoMAhatzyXlZOZqlG/NrTSUDoFNLZ0L8jTw9M4HPf03jjpHe5cZ+vzKNFz9O5MWPEzkVXVQhOXQqr3C+o1c0APbtWEtc9Emef38ZN98/hYWfvFJmXLPWXXjw+Xn4B4Ve0PqOZM+/64k9c4rpsxdz+wPP8/Xc18qM++mrmVwxeizTZy/G3dObdX8tKlzWom1npsz4jikzvnPoiobZbGbOhx8wZdqrzP74E8LX/M2pUydLxGzbupmoyEjmzP+ChyZO4qNZ7wNw8sRx/lixnHfencXM2XPZunkjUZER9ihGpZgtFt74agkfTLqbn6ZP4vdNOzkWGVMipme75nw/bSLfTZvIlHuu4+XPfi6x/NuV62laP9iWaVfZkd3hJMae5KFXVzDyjmksXzC1zLgOvUbz4Cu/MX7qEvLzstm+9kcA3Dx8GHbL81w69B5bpl0ldfH4tW/7OuKiTzJl5lJuGfci380vO+fFC95j4MjbmTJzKW4e3mxYZd3GV/wyj7AmrXnu7Z+4/eHp/Pj5G7ZM/4J0aeNGvUAnJr4WydyFCdx3XUCZcQN6eBLg68SkNyJ5/M0o1u/IqNT64uJRKysbieu2kpeYUu7ykDGDiVywCIDkTTsx+XjjUi8I356dyDx6kqzjEei8PKK+X0bI6ME2yrpq2jYysP2ItaJwOk7j6gxebqXjlIJhPZ1YsaVkC0BGNkTGa8wWW2RbPbq0dmH9zmwAjkbk4e6q8PGslZvseduz5W969BuDUoomrS4hKyONlKS4UnFhTdsSENzggtd3JDs2r+bSAaNQStG8dScyM9JITiyZs9aag7u30O0y6/7ae+Aotm/+2x7pVsnhQwepHxpKvfqhmEwm+vYbwKYN60vEbNr4DwMHD0EpRZs27cjISCcxMYHTp0/RunVbXFxdMRqNtO9wCRv+WV/OJzmOPcdOExYcQFiwPyYnJ67seQmrt+8vEePu6oJS1rt8WTm5UOyGX0xiCmt3HuTqfj1smXaVHdrxF50uuwqlFGHNO5OdmUpacmypuJad+qOUQilFaJNOpCZFA+DhHUBo044YjbWnA0JdPH7t2vo3PfuNRilF03Jy1lpzaO9mulw6BIBeA8awc4v1+BUdcYzWHXsBUK9BUxLjokhNTrBtISqpewd3wrdZKw6HT+Xg4WbA18tYKm5oby9+/CMZXdAJIzXdUqn1L3YGo6r2l6O6KK/cXENDyIqILpzOjozGtUFIGfNjcG0QYo8UK83bHVIyirpNpWaAt3vpDevStkb2n7KQlmXL7GqGn7eRxNSilpikVDN+3mVvstcN8uTlCf7ccqUnTsWOWS3CTEx7wJ/Hx/oSGuT4B7PkpFh8A+oVTvsEhJCSWPoCpabWt4ekxFj8A4v2Q7+A4FKVjfS0ZNw8PAsvvPwCQkhOKIo5dnA3UyfdxPsvP0zkqaO2SfwCJCTEExhYdIc+MDCIhISSFxYJ8fEEBQUVTgcEBpEQH0/jxk3Yu2cXqakp5GRns23rJuLjHfu7BYhLSqWev0/hdLC/N7FJpW8Wrdq2l2ufncGj733BlHuKuoe9/e1SHr1xOAaD455Iy5KWHIO3f/3CaW+/eqQlx5Qbb87PY/fGJbTo0NcW6dWIunj8Sk6MxS+wKGffgBCSz8o5Iy0ZN3evouOXfwgpidZtoUHjVuzY9BcAJ47sJjHuDMmJ5W8njsDfx0h8ctENzYSUfPx9Sp9fQwKc6N3Zg9ceq8+z9wVTL9CpUuuLi0ftuWVSCf/dIStOa2297V96gQ0yqroyUz9r2ssNOjQ18MnyPJvkVNPKurQo6+ta+Gc6KekWnIxw12hvRvTxYMmaDE6cyeeJ9+LJydV0aunMxJt9eeYDx75jVFYBy/rua2x9eyjjOy2Vc5kx1qBGzdrw+pxluLq5s3vbOj5843Gmz15c/XlWA31e309ZMYqGjRpz7Q038+Lkp3F1daNp0+YYjY5/gi7rCFvWMXpQt/YM6taebQeP89EvK/n4f/cRvmM//l4etGvSgK0HjtV8stWorGOVKvOoZvXb19No1Ko7jVp1r8GsalidPH6Vvb+WCCl7LwBgyNX38uPnb/Da/24gtFFLwpq2wWBw7P26zHNzGfNMToq8fM2z752hZ0d3JtwUyJTZ0ee9/sVO1bIbKFVxUVY2siKjcQurR1LBtGuDeuRExWJwNuEWVnQHwrVBCNlRjnvXpFdbAz1aWQ86EfEaHw/Ff7uktwekZZbcPUMDDAR4KR6/3jpgw+QEj1/vzIwfa8/Aq8E93Ojfzdo/7HhkHv7eRsBaefLzNpKcVrofWEpB02y+GdbtyGJYbw8AsnOK/n92Hc7ljpEKT3dFeqZjHdbWrviWDX/9BECj5h1ITihqfUtJiMHb7/z7qvv6h1RpfVv5+7fvCV/5CwBNW7QnMb7oTl5SQiw+fkEl4j29fcnKSMdszsdodCIpIQYf/0AA3Nw9C+M6duvD13NfIy01Ca+CQaeOJDAwqERrRHx8HP7+JfsrBwQGERdX1GqTEB+Hf4A1ZuiVwxl65XAAvvz8EwIDA22QddUE+3kTXazba2xiKkG+5Y+/6ta6KVNiE0lKy2Dn4ZOs2bGfdbsOkpuXT0Z2DpPnfM/08TfZIvVK27Lqa7avXQhAaJOOpCaeKVyWmhSNp2/Z++KaJbPISEvkxts/sEme1akuHr/W/P4d/xSUuXHz9iTFF+WcnBBT+vjl5UdWZlrR8SsxBh9/a7nc3D25/cGXAevNiCkPDy+zi5m9XXm5F4N7eQFw9HQOgb5OHCQHgAAfJ5JSSo8HTUgxs2lXJgCbd2fy4E2BhfPPZ/2LnTJelJ2LynRRVjZif11F4wdvI+r7Zfj2uoT81DRyouPIjUvEo0UT3JqEkR0ZQ+hNI9l++xP2Trdcm/Zb2LTfeiHdOszApe2M7DpmoWGQIieXUl2lDkZYeP27oorFi7fXrooGwF9bsvhri7Vgl7R0ZnBPdzbtyaZ5mImsHF1YsSjOx9NQOL9rGxciY/NLzW/awAmlcLiKBkDfK2+h75XWJxLt/TectSu+oWvv4Zw8vAtXd89SJ66KdOg+sErr28rA4TcxcLj1gnHX1rX8/dv39OxzJccO7cbN3RNf/5I5K6Vo3aE72zb8Rc8+V/LP30vp3GMAAClJ8Xj7BqCU4vjhPWit8fTytXGJzk/LVq2JiookOvoMAQGBrA1fzZNPPVcipmevy1j262L69R/IwYP7cffwKKyQJCcn4evrR1xsDBv+Wcdb78y0RzEqpX3TME7HxhMZl0iwnzcrNu/k1fE3l4g5FRNPw2Drd7j/RCR5+WZ8Pd155IZhPHLDMAC2HjjGl7+HO2xFA6DHoLH0GDQWgMO7VrNl1de07zmSyGM7cXXzwquMysb28IUc27uO2574HGWofRcfdfH41X/YzfQfZt2G9/wbTvjv39Lt8uGcOLwLN3evUjkrpWjVvgfbN66k++XD2bR6CZ26DwAgMyMVZxc3nJxM/PPXT7Ro27XEDRRHsWJ9GivWW58k1aWtG8Mu92L99gxaNnIhM9tCclrpysKWPZl0aOnK35vTadfclag4643DrXszz2t9cfGolZWNzl+9Q0D/njgH+jHo+BoOT/sAZbIW5dTc74j9bQ1Bw/sz4MBKzFlZ7LrPejLXZjN7Hp1Gz2XzUUYjEZ//RPq+I/Ysynk7GGGhVUMDj1/vTF6+5ue1Rf0d7xjixC/r8iscp+HpBg+OccbFZG317d3eyPs/55LjwD2udh7OpVNLF96cGEBOnuaTxamFyyaN9eWzJakkp1kYf50PXu7WAZanovP4Yqn1gNi9nQuDurtjtmjy8jUf/Vj+QwUcRbsufdm3PZyXHx2Bs7Mrt04oerLJx69N4JbxU/HxD2bNb1/z15JPSUtO4I2nrqNd577c8sDUCtd3VB279WH3v+uY/OBVOLu4ctfDLxUue/+VR7jzwRfx9Q/iutsnMnfGsyz6ZjaNmrahzxVXA7Btw5+sXvEjRoMRk7ML9z/+WpnddByB0Whk/IRHeOn5Z7BYLFwxdBiNGjfht2W/AjB85Gi69+jFti2bGX/vHbi4uDBx0v8K1399+lTSUlMxOjnxwIOP4OnlZa+inDcno5Gnx47hoXc+xWLRjOnbneYNQvjx700AXD+wF6u27mXpP//iZDTi4uzE6xNucdjv8Hy16NifI7vDmf3cUJycXRlz96uFy759bxyj7noZL98Qli14Cd+AUD57zXrx2qbrEPqNfoj0lDjmv3I9OVnpKGVg059fMmHaMlzcHO9C9D918fjVvktf9v67lqkTR2JyduW2glYKgA9fe5Bbx7+Er38wV42dxGfvPcXS72bRsGkbLht0LQDRkcf5atZkDAYD9cKaM/aBsp9a5ki278+ia1s3Zj7bgNw866Nr//PMfcHM+SGBpFQzi/5KYeLYQEb28yY7x8KcH+LPuX5d4sgDuqubKqsPcXVaZmrteLeSa9g/c3bZOwWbizyVbO8UbO7mqx2vm05Nczc5cO20hoS4Jto7BZsKi9li7xRs7hfzNfZOweYCverevmxUde5yhHlfnjl30EXmh3ea1Iqr+I29elb7Bnnpps0OWfZa2bIhhBBCCCFEbSUDxIUQQgghhBA1oi51o6p9o9GEEEIIIYQQtYK0bAghhBBCCGFDSlo2hBBCCCGEEKJqpGVDCCGEEEIIG6qNv6tzoaSyIYQQQgghhA3VpadR1Z1qlRBCCCGEEMKmpGVDCCGEEEIIG5JH3wohhBBCCCFEFUnLhhBCCCGEEDZUl8ZsVFjZUEpdDbQAdmutV9gkIyGEEEIIIcRFodzKhlLqQ6A98A/wslKqp9b6ZZtlJoQQQgghxEVIHn1r1Q+4RGttVkq5A2sBqWwIIYQQQghRBXWpG1VF1apcrbUZQGudCdSd/xUhhBBCCCFElVXUstFGKbWr4G8FNC+YVoBFa31JeSsqpcYB4wCG3zGLLv3vq658a4Xe4zvZOwWba7hvrb1TsINkeydgcyZDnr1TsLlMi5u9U7CphbnX2jsFmxsYdtDeKdicRRntnYLNpVm87Z2Czc2546S9U7CDJvZO4LzUpUffVlTZaFvGPAWEAc9V9KZa67nAXIDJn+boC85OCCGEEEIIUWuVW9nQWhdWh5VSnYFbgRuB48BPNZ6ZEEIIIYQQF6G6NGajoqdRtQJuBm4BEoDvAaW1Hmij3IQQQgghhLjoyNOorA5gfQLVaK31EQCl1CSbZCWEEEIIIYSo9SqqbFyHtWXjb6XU78B3yBOphBBCCCGEqJK61I2q3DYcrfUvWuubgDbAamASEKKU+kgpNdRG+QkhhBBCCCFqqXN2GNNaZ2itv9Zaj8L6JKodwDM1nZgQQgghhBAXI2VQ1f46r89VaphS6qBS6ohSqtT1vFLKRyn1q1Jqp1Jqr1Lq7qqWtaJuVKVorROBOQUvIYQQQgghRCXZoxuVUsoIzAaGABHAFqXUEq31vmJhDwH7tNajlVJBwEGl1Nda69wL/dy6MxReCCGEEEKIuqsncERrfayg8vAdcNVZMRrwUkopwBNIBPKr8qGVatkQQgghhBBCVE1NPPpWKTUOGFds1tyCH9r+TwPgdLHpCKDXWW8zC1gCRAFewE1aa0tV8pLKhhBCCCGEELVcQcVibgUhZfXd0mdNX4l1fPYgoDmwUim1VmudeqF5SWVDCCGEEEIIGzIY7fLo2wigYbHpMKwtGMXdDbyutdbAEaXUcaxPpt18oR8qYzaEEEIIIYS4+G0BWiqlmiqlnLH+nt6Ss2JOAYMBlFIhQGvgWFU+VFo2hBBCCCGEsCF7PI1Ka52vlHoYWAEYgU+11nuVUg8ULP8YeBn4XCm1G2u3q6e11vFV+VypbAghhBBCCGFDNTFA/HxorZcDy8+a93Gxv6OAav3x7lpb2RjZy0jrhkby8jU/rc0nKuHs8S1FRl3qRNeWBqZ9ZX1EcKCP4rq+ToQGKFZuM7Nuj9lWaV+QTvNeJXjEAHJjEwjvMrrMmHbvTiZ4WH/MWdnsvPcZUrdbH5kcNLQv7WZMRhkNnP50IUffmmfL1Ktk+7ZNfDb3fSwWC4OHjuKaG24rsVxrzWdz3+ffrRtxcXHhoceeo1mL1oXLzWYzz0y6H/+AQJ6d8qat078gdbHM/27dzPw5s7BYLAy5cgTX3XhrieVaa+bPmcW2LZtwcXFl4uNP0bxFKwCW/LKQlSuWo5SicZOmPDLpaZydne1RjPO2Y9tGvpj7HhaLhUFDR3PVDbeXWK615ou577F96wZcXFyZ8NhkmrZoTW5uDlOffoi8vDwslnx6XT6QG8beZ6dSVI7WmpXfT+fonjWYnF0Zddfr1GvUvlTc4k+eIPrkHgxGE6FNOjLstmkYjSb2bFrCxhXWY5eziwdX3voSIQ3b2LoYlbJl6zY+mjsfi8XMsKFDufnG60ssP3U6gnfee58jR45y1x23c8N11xQuu/3u+3Bzc8NgMGA0Gpn9/gxbp39Btm7dykdz5mKxWBh25VBuuvHGEstPnz7NO+++x9EjR7jzzju4/rrrAMjNzeXJp54mLy8Ps9lM3z6Xc/ttt5X1EQ6nLh6zN+zYw7uffY/FYmHM4D7ccfXwEst/X7uJrxb/DoC7qwtP3TeWlk2swwTSMjJ59eMvOXY6EpTi+Ql30rFVc5uXQdhWrRyz0SrMQKCPgRk/5rJofT5jepdfZ2oQoHA969ojK0ezdGO+w1cy/hPxxc9sHlX+RUXQsH54tGjC6rZD2T3hBTrMesm6wGCg/cwX2Tz6PtZ0GknozaPwbFs7dmqz2cwnH81g8tS3effDr1i/5k9OnzpeImb71o2ciYrgg7nfMv7hp5j34Tslli9fspAGDRvbMu0qqatlnvPh+7w47XU++Pgz1q5ZxelTJ0rEbNu6iTORkXw0/ysenPg4H896D4CE+DiWLvmFt9//mJkffYrZbGHtmlW2L0QlWMxmPv3oHZ6Z+g7vfPg169f8ScRZ3/GOrRs4ExXBe3O/5/6Hn2L+h28DYDI588KrM3lz1he8PvMLdmzbxOEDe+xRjEo7uiecpNgTPPDyHwy/7WV+//qlMuPa9xzDuKm/c9+Lv5KXl8POdQsB8A0MY+wTC7jvxV+5fOQEflvwgg2zrzyz2cysj+YwfeoU5n00m9Xh4Zw8dapEjJeXJw+OH8f1115T5nu89dp0Pp71fq2paJjNZmZ/+BGvTJvK3I8/YvWassrsxYQHxnPdddeWmG8ymXjjtVf5aPYsPpz1AVu3bmP/gQO2TP+C1MljtsXC2598w7vPTeTbd6fyx/otHI8oOb44NDiQj156kq/fnsLd143ktblfFS5797PvubRze75/72UWvPUiTRrUt3URHIa9fkHcHmplZaNtIwPbj1grCqfjNK7O4OVWOk4pGNbTiRVbSv4WSUY2RMZrzFV6arDtJK7bSl5iSrnLQ8YMJnLBIgCSN+3E5OONS70gfHt2IvPoSbKOR6Dz8oj6fhkhowfbKOuqOXJoP/XqNyCkXigmk4nL+w1m68Z1JWK2bFpH/0HDUErRqk17MjLSSUq0ditMiI/l3y0bGDx0lD3SvyB1scyHDx2gfmgD6tW3lrlPv0Fs2vBPiZjNG/9hwOAhKKVo3aYdGRnpJCYmANaTfW5ujvXfnBz8AwLsUYzzZv2Owwip1wAnk4ne/QazdePaEjFbN62jX8F33LJNBzIz0khKjEcphaubOwDm/HzM5nzrQa4WOLzzLzpcejVKKRo060xOVirpKbGl4lp07I9SCqUUoU06kZYUA0BY8664efgAENq0M2nJ0TbNv7IOHjpMaGh96tevh8lkon+/vvyzcVOJGD9fX1q3aonRyWinLKvXwUOHqB8aSv369QvK3I8NGzaWiPH19aV1q1YYjSVvECqlcHOznsTz8/PJN5vLfD6no6mLx+x9R44TVi+YBiFBmJycGNK7B+FbdpaI6dS6Od6eHgB0aNmMuIRkADIys9i+/xBjBvUBwOTkhJeHu03zF/ZRKysb3u6QklHUbSo1A7zdSx+aLm1rZP8pC2lZtszO9lxDQ8iKKDr5ZkdG49ogpIz5Mbg2CLFHipWWmBBHQFBw4bR/YBAJCfGlYwKLYgICgkgsiPls7kxuu+dBDKr2bOJ1s8zxBBYvT2AgiQlxJWPi4wkMKh4TRGJ8PAGBQVx97Y3cf+fN3D32etw9POjStYfNcr8Qpb/j4NLlPes79g8oirGYzTz9yJ2Mu20UHTv3oGXr0l2RHFFacgze/vUKp7186xVWJMpiNuexZ+NimrXvW2rZrvU/0rx9vxrJs7rEJyQQFBhYOB0UGEhCQsL5v4GCZ194kQcnTmLZb7/XQIbVL+GsMgdWssxms5kHH36Ym28dS9cunWnTxrG7yUHdPGbHJSYTHOBfOB0c4EtcYlK58b+uWs+lXToAEBkbj5+3Fy9/+Dl3PPUy0z/+kqzsnBrP2VFJy4aDK+tm3tkjNrzcoENTAxv31Y6uUlWhyvgP0VqX8x9V/tgWR3d2cXRZZVGKbZvX4+PrR/Ni/WJrq4u9zOWVp0RMqb3bGpOelsbmjeuZ89k3fLpgIdnZ2axetbKGMq0upctSav8t4//kvxiD0cgbH3zBh5//wtFD+zh9okpPI7Sd8/iei1vxzVQatuxOw5bdS8w/eXAjO9f/yIBrn6zuDKtXWd9hJe7Vv/fWG3w48z2mT5vCr8uWs2uP43eXK2tfrkzDm9Fo5MNZs1jw5RccPHSIEydOVF9yNiTH7CLb9hxgyd/reHistduc2Wzm4PFTXDu0P1+++QJuLs58uah2VKZrgjIYqv3lqGrNAPFebQ30aGVtbo6I1/h4KP47cXt7QFpmyR0gNMBAgJfi8eutAzZMTvD49c7M+DHXpnnbQlZkNG5h9fjv3oJrg3rkRMVicDbhFlZ0N9G1QQjZUaW7Ljgi/4AgEuKKck2Mj8PfP7BETEBgMAnxRTEJCXH4+wewcd3fbN20nu1bN5Kbm0tWVgYz357GxCdftFn+F6IuljkgMIj44uWJjy+jzEHExxWPicM/IICdO7YRXK8+Pj6+AFx2eV8O7N/LgEFDbJL7hfAPCD7rO47F76zy+p/1HScmlI7x8PSiXceu7Ph3Iw2bNKvZpC/Qtr+/Zse6HwCo36QjqYlFraxpydF4+QaXud7aX2eRmZbIdQ/MKjE/NuIAy798nhsnzsPd06/mEq8GgYGBxMUX3eGOi4/Hv9jd4HMJKOgO6OfrS+/LLuXgwcN06tCh2vOsTmeXOT4+Hn//yndr9PT0pFPHTmzdto0mTZpUY4bVry4es4MD/IhNSCycjk1IJsjPt1Tc4ZMRvDrnS9599lF8vDwL1w0K8KNDS+sxa9Cl3fhy0W82yVvYl+NWg86yab+FWYvzmLU4j/0nLXRpYa14NAxS5ORSqqvUwQgLr3+Xy9sLra+8fC7KigZA7K+raHDb1QD49rqE/NQ0cqLjSNmyG48WTXBrEoYymQi9aSQxSx17AO1/WrRqw5moCGKio8jLy2N9+F9079WnREz3XpezZtXvaK05dGAv7u6e+PkHMvauB5jzxc98+OlCJj31Eh06dXX4AzjUzTK3bNWGM1GRxESfIS8vj3Xhq+h56WUlYnr26s3qv1aitebggX14eHjg7x9AUFAIhw7sIyc7G601u3b8S1jDRnYqyflp3qoN0VERxEZHkZ+Xxz/hf9HtrO+4W68+hBd8x4cP7Cn8jlNTkshITwMgNyeH3Tu2EBrmuANLuw0cy70vLObeFxbTqvMV7Nm4CK01kcd24OLmhadP6crGjnULOb5vHVfdN6PEXbqUxCh++vgRRt/zJgEhTW1ZjAvSulVLIiOjOBMdTV5eHmvC13JZr17ntW5WdjaZmZmFf//77w6aNHbs7RqgdatWREVFEl1Y5nAuvfT8ypyckkJ6ejoAOTk5bN+xg4ZhDc+xlv3VxWN22+ZNOH0mlqjYePLy81n5zxb6dr+kREx0fALPvv0RUx6+l0ahRV23A3x9CAnw42SU9cbDlt37aRoWatP8HUld6kZVa1o2ijsYYaFVQwOPX+9MXr7m57VFA8DvGOLEL+vyKxyn4ekGD45xxsVkbe3u3d7I+z/nkpNng+QvQOev3iGgf0+cA/0YdHwNh6d9gDJZv7pTc78j9rc1BA3vz4ADKzFnZbHrvucA0GYzex6dRs9l81FGIxGf/0T6viP2LMp5MxqduPeBSUx/8QksFgsDh4ykYeOm/LF8EQBDR1xN1+6XsX3rRh65/2acXVx56LFn7Zt0FdXNMhu5f8IjTH3+acwWM1cMHU6jxk35fZn1B02HjRxDtx692LZlEw/ce5v10beTngKgVZu29O7Tn8cnjsdoNNK0WQuuHO7YAy2NRifufmASr774OBaLmYFDRtGwcTNWLv8FgCEjrqFL98vYsXUDj95/Iy4urjzwmHV/TkpM4KN3X8FisWCxWLis7yC69bzcnsU5b8079Ofo7jV8/PwQTM5ujLzz1cJl339wPyNufwUv3xB+/3oKPv6hfPnGTQC07jKEPqMeZv3S2WRnJLPim6kAGAxG7p78s13Kcj6MRiMPTxjPcy+8hMVi4cohV9CkcSOWLrfexR01YjiJiUk8/NjjZGZmogwGflm8hHkfzyY1JZWp063/P2azmYH9+9Ojezd7Fue8GI1GHpwwgcnPv4DFYmHo0CE0adyYZcusj/MfOXIEiYmJTHz0scIyL1q0mDlzPiYxMZF33pmB2WJBa02/vn3o1aunnUt0bnXxmO1kNPLkPbfw6HTr47tHDbycZg1D+fmPNQBcO7Q/n/y4jJT0DN6a/zVg3TY+f30yAE/ccwtTZn5CXn4+DYIDef7Bu+xVFGFDqsz+d9Vo8qc5tXeQwAXqPb6TvVOwuYb71p47SNR6JoOD1shrULbFxd4p2NTOyMBzB11kBoYdtHcKNmdRF8dTsCojzeJt7xRsrmHmfnunYHN+l/R33Fv8xUQ8fEO1Xx+HzVrokGWvlS0bQgghhBBC1Fq15NHl1aHWjNkQQgghhBBC1C7SsiGEEEIIIYQNOfKA7uomLRtCCCGEEEKIGiEtG0IIIYQQQtiQI/8IX3WrOyUVQgghhBBC2JS0bAghhBBCCGFDdWnMhlQ2hBBCCCGEsCHpRiWEEEIIIYQQVSQtG0IIIYQQQthQXepGJS0bQgghhBBCiBpRbsuGUurxilbUWs+o/nSEEEIIIYS4uNWllo2KulF5Fft7PDCnhnMRQgghhBDi4leHBoiXW9nQWk/972+l1NXFp4UQQgghhBDiXM53gLiu0SyEEEIIIYSoI5SSblRVopQaB4wDuGzUW7TqdntNfIzDarhvrb1TsLnT7fraOwWb05v22jsFm0vOMNo7BZvLzq07JwSAzmFJ9k7B5valNbN3CjaXklX3HkbZJ7DuHbNTPerZOwWb87N3AqKUigaI76aoRaOFUmrXf4sAi9b6kvLW1VrPBeYC3PVSjLSKCCGEEEIIUaAu/ahfRbc2RpUxTwFhwHM1k44QQgghhBAXN3kaFaC1Pvnf30qpzsCtwI3AceCnGs9MCCGEEEIIUatV1I2qFXAzcAuQAHwPKK31QBvlJoQQQgghxMVHulEBcABYC4zWWh8BUEpNsklWQgghhBBCiFqvosrGdVhbNv5WSv0OfId1zIYQQgghhBDiAtWlMRvltuForX/RWt8EtAFWA5OAEKXUR0qpoTbKTwghhBBCCFFLnbPDmNY6Q2v9tdZ6FNYnUe0AnqnpxIQQQgghhLgYKWWo9pejqtSv+mitE4E5BS8hhBBCCCFEZUk3KiGEEEIIIYSomkq1bAghhBBCCCGqpi79gnjdKakQQgghhBDCpqRlQwghhBBCCBuqS4++lcqGEEIIIYQQtuTAT4+qbrW2sjF2uBedWjqTm6eZvyiVk2fyS8Xcd7U3rRs7k5VjAWD+olRORefTpomJiTf7Ep9sBmDr/hyWrMmwaf6VtX3bJj6b+z4Wi4XBQ0dxzQ23lViuteazue/z79aNuLi48NBjz9GsRevC5WazmWcm3Y9/QCDPTnnT1ulXWqd5rxI8YgC5sQmEdxldZky7dycTPKw/5qxsdt77DKnb9wEQNLQv7WZMRhkNnP50IUffmmfL1KtEa82iL15j/45wnJ3duHnCdMKatisVt27F14T/9hUJMaeZOmcdnt5+AGxbt5S/l3wCgLOrO9ff+wKhjdvYtAyVpbVmxbfTObI7HJOzK2PueY36jduXivtl3pNEndiD0WgitGlHRt4+FaOT6bzXdxRaa1YtnM6xvWtwMrky4o7XCWlUOt+lnz1B9Elrees16cjQW6dhNJo4dWgTv3z8ID6BYQC06jyE3iMetnUxKmXntg18Nf9dLGYLA4aOYcz1d5RYrrXmy3kz2Ll1A84uLox/7AWaNrdut3Pff4XtW9fj7ePHG7O+sUf6F0Rrzc9fvMb+7Wsxubhy64TpNCxjX177+zes+e0r4mNO88rctYX7ckzkMb75+AUiju9j5E0TGTT6blsXodK01vz2zXQO77Lui1ff+xqhTUpv25v+XMDGlV+SGHuKp2ZuwMPLWubszDR+mvs/UhLPYDGbuXzY3XTpe52ti1Epm7dtZ/a8T7FYLIwYMphbbri2xPJTpyN48/3ZHDl6jHtuv5Ubr70KgNMRkbz85ozCuDPRMdw19mauu2qUTfO/EFu2buOjufOxWMwMGzqUm2+8vsTyU6cjeOe99zly5Ch33XE7N1x3TYnlZrOZhx97nMCAAF5+6UVbpi7spFZWqzq1dCbE38jTMxP4/Nc07hjpXW7s9yvTePHjRF78OJFT0UUVkkOn8grnO3pFw2w288lHM5g89W3e/fAr1q/5k9OnjpeI2b51I2eiIvhg7reMf/gp5n34Tonly5cspEHDxrZMu0oivviZzaPuK3d50LB+eLRowuq2Q9k94QU6zHrJusBgoP3MF9k8+j7WdBpJ6M2j8Gzb3DZJV4MDO9YSH32SZ9/9jRvuf4mfPplWZlyTVl15YPIn+AWGlpjvH9yAB1/8nCff/IUh1z7Awnkv2SDrqjmyO5zE2JM89OoKRt4xjeULppYZ16HXaB585TfGT11Cfl4229f+WKn1HcXxveEkxZ7gvpf+4MqxL7Pyu5fKjGvXYwz3Tvmdu57/lfy8HHatX1i4LKxFd+56bjF3PbfY4SsaFrOZz+e8zVNT3uXN2d+yIfwPIs46fu3ctoHoqNO8M2ch9z70LJ99VHRDpO/gkTz10ru2TrvK9u9YS9yZU0x+bzk33f8SC+e/XGZc09ZdmDB5fql92d3Th+vueoZBo+6yQbbV4/CucBJiTjLx9RWMvmsaS78qe19s1LIrd/zvU3wDSpZ586qvCQptwYPTFnP301+y4vs3yc/PtUXqF8RsNjPz43m89tJkPp39HqvC13Hi1OkSMV5eXjw87l5uuGZMifkNwxowd+Y7zJ35Dh+9+yYuLi70uaynLdO/IGazmVkfzWH61CnM+2g2q8PDOXnqVIkYLy9PHhw/juuvvabM9/hlya80atjQFuk6NGVQ1f46r89VaphS6qBS6ohSqszfzVNKDVBK7VBK7VVKralqWWtlZaNLaxfW78wG4GhEHu6uCh/PWlmU83Lk0H7q1W9ASL1QTCYTl/cbzNaN60rEbNm0jv6DhqGUolWb9mRkpJOUGA9AQnws/27ZwOChjn/H5D+J67aSl5hS7vKQMYOJXLAIgORNOzH5eONSLwjfnp3IPHqSrOMR6Lw8or5fRsjowTbKuur2bFtFt75jUErRuOUlZGWmkZoUVyourGlb/IMalJrftFUX3D19AGjcohPJiTE1nnNVHdrxF50uuwqlFGHNO5OdmUpacmypuJad+qOUQilFaJNOpCZFV2p9R3F411+073W1tRxNrfmmp5TOt1mHovLWb9yJ9CTH/y7LcvTwPkLqhxFcrwFOJhOX9h3Ctk3hJWK2bQqn78ARKKVo2aYDmcWOX207dMHTs/wbSo5q99a/6dHPui83KdiXU8rZlwOCS+/LXj4BNGreEYOx9nRAOLD9Lzr3tu6LDSvYF+s3bodfQctcSYrc7Ay01uTmZOLm4YPB4LjlP3D4CA3q1yO0Xj1MJhMD+/Xhn01bSsT4+frQplULnJzKL8f2nbsJrR9CSHBwTadcZQcPHSY0tD7161vL3L9fX/7ZuKlEjJ+vL61btcToZCy1flx8PJu3bGXYlUNslbIoRillBGYDw4F2wC1KqXZnxfgCHwJjtNbtgRuq+rm18grdz9tIYqq5cDop1Yyfd9lFuW6QJy9P8OeWKz0pvt23CDMx7QF/Hh/rS2hQ6R3CkSQmxBEQVHQQ8g8MIiEhvnRMYFFMQEAQiQUxn82dyW33PIjhIuof6BoaQlZEdOF0dmQ0rg1Cypgfg2uDEHukeEFSEmPxDahXOO3jH0LKBVYYNq3+mTad+1ZXajUmLTkGb//6hdPefvVISy6/zOb8PHZvXEKLDn0vaH17S0+Owcuv6Dv28qtHekXlNeexd/NimrYv+i6jju/g8+lj+HHWfcRHHa7RfKvq7GOTf2AwSQlxpWOKH+MCSsfUNimJMfgV25d9q7Av1xZl7Yuplagk9xo8lrgzR3l7Uj8+fGEMw299DoMDPx40PiGRoMDAwumgAH/iExIq/T5/r13PoH59qjO1GhOfkFCyzIGBJFSizB/Nnc99d991UV2PXDCDofpf59YTOKK1Pqa1zgW+A646K+ZW4Get9SkArXWV797Vym+7rIYirUvPW/hnOs/OSmDq3EQ83AyM6OMBwIkz+TzxXjwvfpzIn5szmXizb43mWxPUWf8Juqz/AKXYtnk9Pr5+NC82fuNioM7+D6Dg/6CM+WVuHI6qnO+xso7s3cTmv39m1C2PV0NSNavMIpe5l1v99vU0GrXqTqNW3S9ofbur5Hf853dTadiiO2EtrOUNadie8S+v4q7JS+g64HZ+mfNQTWVaPcoob+nilhXjwN/hebkYy1Sxsjft8y/zkT3rqNeoLU++G84DU39h2YKXyc5Kr8YMq1mZ23blvuO8vDz+2bSFfpf3rq6salZZZT7P4+3GzVvw9fGhVcsW1Z1VrfRfy3V1vs5DA6B4X7+IgnnFtQL8lFKrlVLblFJ3UEWO2z55lsE93OjfzQ2A45F5+HsbgTzA2tKRnGYptU5KunVevhnW7chiWG9rZSM7p2hn2XU4lztGKjzdFemZjnlR6h8QREJcUcUyMT4Of//AEjEBgcEkxBfFJCTE4e8fwMZ1f7N103q2b91Ibm4uWVkZzHx7GhOfrN2DsrIio3ELq0dSwbRrg3rkRMVicDbhFlZ0N9G1QQjZUY7bpQZg3R/fsGmVdfxBw2YdSE4oaplJSYzBx69yTetRJw/yw9wp3P/Mx3h4+VZnqtVmy6qv2b7WOgYhtElHUhPPFC5LTYrG07fsMq9ZMouMtERuvP2DwnnefiHnvb69/Lvma3at/wGA+o07kpZU9B2nJUXj6VN2vuuXzSIzLZGrx80qnOfi5ln4d7MO/Vn53VQy0xNx9/Svoeyrxv+sY1NifCy+/kElYwKCSx7jEmLxPesYVxusXfEtGwr25UbNO5BUbF9OTozBu5L7cm2w6a+v+XdNwb7ctPS+7FWJfXH7ul/oO/J+lFIEhDTGLzCM+DPHCGvWqdrzrg6BgQHExRf1MohLSCTAv3L74eZt22nZvBn+fr7VnF3NCAwMLFnm+Hj8A86vzHv37WPjps1s2bqN3NxcMrMyef2td3jmf0/UVLp1jlJqHDCu2Ky5Wuu5xUPKWO3si18noBswGHADNiilNmqtD11oXrWmsvHXliz+2pIFwCUtnRnc051Ne7JpHmYiK0cXViyK8/E0FM7v2saFyNj8UvObNnBCKRy2ogHQolUbzkRFEBMdhX9AEOvD/+LR/00pEdO91+X8vvRnLu83mMMH9+Hu7omffyBj73qAsXc9AMDeXdtZ8su3tb6iARD76yoaP3gbUd8vw7fXJeSnppETHUduXCIeLZrg1iSM7MgYQm8ayfbbHftA1mforfQZeisA+/5dw/o/vqFL7xGcOrILV3dPvP2CzvEORZLio/j83Ue55aHXCKrfpIYyrroeg8bSY9BYAA7vWs2WVV/TvudIIo/txNXNq8wLlO3hCzm2dx23PfF5iV9ebdV50Hmtb09d+4+la39reY/uXs32NQto030kZ07sxMXNq8zKxq71Czmxbx03PlqyvOkpcXh4B6KU4syJXWhtwc3Dz1ZFqbRmLdsSHXWa2ILj18a1K3noyZIPPujasy9/LFvIZf2GcOTgXtwKjl+1Td8rb6HvlbcAsPffNaxd8S1dew/n5JFduLl74lOJfbm26DV4LL0GW7ftQztXs+mvr+nQayQRF7Av+gTU59i+DTRu1Z30lHjio4/jF+S4A4nbtGxBZNQZzkTHEBjgz9/h65j85GOVeo9V4esY1L92dKECaN2qJZGRUZyJjiYwIIA14Wt55n9Pnte69951J/fedScAO3ft5seff6nbFY0a6CJYULGYW0FIBFB8pwoDosqIiddaZwAZSqlw4BLg4q9sFLfzcC6dWrrw5sQAcvI0nyxOLVw2aawvny1JJTnNwvjrfPBytzYtnYrO44ulaQB0b+fCoO7umC2avHzNRz+WPxDZERiNTtz7wCSmv/gEFouFgUNG0rBxU/5YvgiAoSOupmv3y9i+dSOP3H8zzi6uPPTYs/ZNuoo6f/UOAf174hzox6Djazg87QOUybq5npr7HbG/rSFoeH8GHFiJOSuLXfc9B4A2m9nz6DR6LpuPMhqJ+Pwn0vcdsWdRKqVtl37s3xHOa48Nx+Tiys3jXylcNu+NB7jx/mn4+Aez9vcF/P3rp6Qlx/PO09fQpks/bho3jT9+/pjM9BR+/tT65BuDwYlJr/5gr+KclxYd+3NkdziznxuKk7MrY+5+tXDZt++NY9RdL+PlG8KyBS/hGxDKZ6/dDECbrkPoN/qhCtd3RM069OfY3jXMmzIEk7Mbw28vyvfH2fczbOwrePqG8Me3U/D2D+Xrt28Cih5xe2j7Cnas/RaDwYiTyZXR98xw6O45RqMTd41/kjdeehSLxUL/K0YR1qgZf/72MwBXDL+Wzt17s2PbPzw+/nqcXVwZP/H5wvVnvfUC+/f8S1pqMg/fPZrrb7mfAUPHlPdxDqNdl37s37GWVx4djrOLG7c8UPQ0qjmvT+DmcVPx8Q9mzW8LWPXrZ6Qlx/Pm09fSrnNfbh4/jdTkeN557iays9JRysCa3xbw7NuLcXX3rOBT7atlp/4c2hXO+08PLXj0bdG2vWDGOMbc/TLefiFsXPkl63/7hPSUeD56cQwtO/bnqnteof/oCSz65FlmP2993PmQG54sfCyuIzIajTzywH08PeVlLBYLw68YRJPGjfj1txUAjB5+JYlJSUyY9BSZmVkog+KnJUv59MP38XB3Jzs7h207djLpofF2Lsn5MxqNPDxhPM+98BIWi4Urh1xBk8aNWLr8NwBGjRhOYmISDz/2OJmZmSiDgV8WL2Hex7PxcHe3c/YC2AK0VEo1BSKBm7GO0ShuMTBLKeUEOAO9gCo9ElCV2de/Gt31UozjNhnUkMfHOu6Jv6acbuf4A5Grm960194p2FxyhmM/TKEmZOfWrf25c1jSuYMuMnGZjnsBX1NSsmrlvcYq6RNY947ZZoPJ3inYXOMWrWvFQTt99lPVfn3s+dCb5yy7UmoE8B5gBD7VWk9XSj0AoLX+uCDmf8DdgAWYr7V+ryp51b2jjRBCCCGEEHWQ1no5sPyseR+fNf0W8FZ1faZUNoQQQgghhLClOvT4X6lsCCGEEEIIYUvn+YvfF4O6U60SQgghhBBC2JS0bAghhBBCCGFDqg51oyq3pEqpXkqpnUqpdKXUBqVUO1smJoQQQgghhKjdKqpWzQaeBAKAGVTxGbtCCCGEEEIIrGM2qvvloCrqRmXQWq8s+HuhUqp2/0qcEEIIIYQQDkDVwC+IO6qKKhu+Sqlry5vWWv9cc2kJIYQQQggharuKKhtrgNHlTGtAKhtCCCGEEEJUlnLcbk/VrdzKhtb6blsmIoQQQgghhLi4VPjoW6VUa2Ac0KZg1n5grtb6UE0nJoQQQgghxEWpDo3ZqOjRt5cBq4F0YC4wD8gAViulLrVJdkIIIYQQQlxslKr+l4OqqGXjReAWrfXqYvMWKaVWAVOA4TWZmBBCCCGEEKJ2q6iy0fysigYAWus1Sqm5NZeSEEIIIYQQF6+69OjbikqaVsGyjOpORAghhBBCCHFxqahlo6FSamYZ8xXQoKI3VUqNwzqwnEeen82I6+678AxrpWR7J2BzetNee6dgc6pXe3unYHMDxneydwo259W4nr1TsKmHVtW93299K/she6dgc5Z8s71TsLmv+31r7xRsrnfbLHunYHON7Z3A+VJ1p2WjosrG/ypYtrWiN9Vaz8U6qJzfd+TqC8hLCCGEEEIIUctVVNn4Wmudb7NMhBBCCCGEqAsMjvv0qOpWURvO5v/+UEp9YINchBBCCCGEuOgpZaj2l6OqKLPiVa7LazoRIYQQQgghxMWlom5UMtZCCCGEEEKI6laHulFVVNloo5TahbWFo3nB3xRMW7TWl9R4dkIIIYQQQohaq6LKRtsy5ikgDHiuZtIRQgghhBDiIufAYyyqW7mVDa31yf/+Vkp1Bm4FbgSOAz/VeGZCCCGEEEJcjJR0o0Ip1Qq4GbgFSAC+B5TWeqCNchNCCCGEEELUYhV1ozoArAVGa62PACilJtkkKyGEEEIIIS5WhrrTjaqikl4HRAN/K6XmKaUGU/JxuEIIIYQQQghRrnIrG1rrX7TWNwFtgNXAJCBEKfWRUmqojfITQgghhBDi4qIM1f9yUOfMTGudobX+Wms9CuuTqHYAz9R0YkIIIYQQQlyUDKr6Xw6qUtUgrXWi1nqO1npQTSUkhBBCCCGEuDhUNEDcYWmt+fnz19m3fS0mF1fGTniFhs3alYoL//0b1ixfQHzMaabPC8fT269S6zuS7ds28dnc97FYLAweOoprbritxHKtNZ/NfZ9/t27ExcWFhx57jmYtWhcuN5vNPDPpfvwDAnl2ypu2Tv+CaK1Z9MVr7N8RjrOzGzdPmE5Y09Lf07oVXxP+21ckxJxm6px1hd/ztnVL+XvJJwA4u7pz/b0vENq4jU3LUBmd5r1K8IgB5MYmEN5ldJkx7d6dTPCw/pizstl57zOkbt8HQNDQvrSbMRllNHD604UcfWueLVOvEpe2nfG9/m6UwUDGP3+RtnJRieWeg8fg3qMvAMpgwKleGFHP3IvOTKdgJsFPvY45JZGEj1+3cfaV59SkLa6DrwNlIG/XBnI2rywVY2zYArdB14HBiM5KJ+O7mWB0wuOWx1BGJzAYyDu0g5z1y+1Qggtz+0hvOrd2JSdPM/enZE5E5ZWKGXedL22aOJOVowGY81MSp87kM7KPB707uwPWMZUNgpyY8Go0GVnapmWoDJfWnfC++g4wGMjc9DcZq34tsdxjwCjcuva2ThiMOIU0IObF8SgXF3xvmYDRyxetNZkbV5G59nc7lKDyXNpcgs+1d1n35Y2rSP9zcYnlnoNG49atDwDKaC3zmcn3oXNzCZr4EsrJBAYDWTs3kfbbQnsUodK01mxc+iqnD4bj5OxKv+teJbBB+1Jxa3+aTHzkXjQan4Am9Lv+VUwuHpzc9xfb/pyJUgYMBiO9Rj5LvSbd7FCS86e15ttP3mL3tnU4u7hyzyNTady89E+zxcVEMuedZ8lIT6Fxszbc9+grOJlMhcuPH97L9Gfu5IEnXqd77ytsWQTH4MDdnqpbraxs7Nuxlrjokzz//jJOHt7Fwk9e4fHp35SKa9a6C+279mfWtHsuaH1HYTab+eSjGbzwyrv4BwTx7KT76d7rcho2aloYs33rRs5ERfDB3G85fHAf8z58h9dmzC1cvnzJQho0bExWZoY9inBBDuxYS3z0SZ599zdOHdnFT59M49FXvisV16RVV9p1HcCH0+4qMd8/uAEPvvg57p4+7N+xloXzXipzfUcR8cXPnPhwAZ0/faPM5UHD+uHRogmr2w7Ft9cldJj1Ev9cfiMYDLSf+SKbht9NdkQMfTb+SMzSVaTvP2rjElwAZcDvxnuJm/Uy5uREgv/3Glm7t5IfHVEYkv7XEtL/WgKAa4dueA4cVVTRADwHjiA/JhLl6mbz9CtNKVyH3EDGD7PRacl43v4/8o7uxpIQXRTj4obbFTeS8eNH6LQklLundb45n4zvZ0JeLhgMeNwyifxj+zCfOWGXolTGJa1cqBfoxBMzYmne0MRdY3x46eP4MmO//T2VLXuzS8xbti6DZeusx64ubVwY1tvToSsaKIX3tXeTOOc1zCkJBD72Cjl7/yU/JrIwJGP1UjJWLwXApV1XPPoNR2dloJxMpC75mvzIEygXVwInTSf30O4S6zokpfC94R7iP5yOOTmB4CdeI3v31hJ5p6/6lfSCSpdr+654DhiJLjgnxc+ahs7NAYORoEenkr1vB3knD9ulKJURcSic1IST3PDE78Sd3sk/i6cx5sHvS8X1Gvkszq7WfXnjstfZt/EbLul/P6HNL6VR20EopUg8c5BV307i+scd+ybC7n/XExN1ilc/XMyxQ7v5as5rPP/ml6XifvxyJkNGj6VX3yv58qPprP1rEQOH3QCAxWzmxy/fp0Pny2ydvrCDWlmt2rPlb3r0G4NSiiatLiErI42UpLhScWFN2xIQ3OCC13cURw7tp179BoTUC8VkMnF5v8Fs3biuRMyWTevoP2gYSilatWlPRkY6SYnWk3lCfCz/btnA4KGj7JH+BduzbRXd+lq/p8YtLyErM43Ucr5n/6DS33PTVl1w9/QBoHGLTiQnxtR4zlWRuG4reYkp5S4PGTOYyAWLAEjetBOTjzcu9YLw7dmJzKMnyToegc7LI+r7ZYSMHmyjrKvGuUkL8uOjMSfEgjmfrH/X49ape7nx7t37kLWtaNs3+vrj2r4rGf/8ZYt0q8xYvzGWpHh0SgJYzOQd2IapRccSMc5tu5N3eCc6LQmgRMWKvFzrvwYjymgEHPiCu5hubV1Ztz0LgKOn8/BwNeDrdWGnn8s6ubFhV1Z1plftTI1aYE6IwZwYC2YzWds34NK+/LvVbl0uI2v7PwBY0pLJjzwBgM7JJj8mEoOPny3SrhLnxi3Ij4sp2JfNZP77D64de5Qb79btcjL/XV84rXNzAGuLB0Ynasu2fXLfKlp0uQqlFMGNOpObnUpmamypuP8qGlprzHlFlWmTiweq4Mfd8vIya8UPve3YvJreA0ehlKJ5605kZqSRnFjy3Ky15sDuLXTvbT0X9R44iu2b/i5c/tfy7+h22WC8fPxtmrtDUar6Xw6qVlY2kpNi8Q2oVzjtExBCSmLpnbum1re1xIQ4AoKCC6f9A4NISIgvHRNYFBMQEERiQcxnc2dy2z0PYqhlTXYpiWd9T/4hpFxghWHT6p9p07lvdaVmF66hIWRFFN0Bz46MxrVBSBnzY3BtEGKPFCvN6OOPOSmhcNqclIjRJ6DMWGVyxrVtZzJ3bCqc53Pd3aQsWgDaUuO5Vgfl6VtYiQDrhaXy9C0RY/ALQrm643HTRDxv/x+m9j2LvYHC886n8X7oNfJPHMB85qSNMq8aP28jCSnmwunEVDN+3sYyY28c4s2rjwQxdoQ3TmeFOJsUnVq6smWvY1c2jD5+mJOLtmtLSiLG8i6qTM64tLmE7F2bS7+PXyCmBk3IO+n4rZQGH/8SZTYnJ2Asp5KkTM64tulM1s5NxWYqgv73BvWmzyPn4C7yTh6p6ZSrRWZqDB4+Recpd+96ZJRR2QAI//E5vnm1Lylxx2l/WVFX6BN7V/LjjBH88cUE+l73So3nXFVJCbH4BxSdY/wCgktVNtLTknH38MRotHag8Q8MISkhrnD9fzf+zYArr7dd0sKuatfV53906TselarQVXV9B3B2vrqMMqEU2zavx8fXj+bFxm/UGuWUqbKO7N3E5r9/ZtQtj1dDUvajyii71rrs/5Oy/u8cUZlfZ9m5u3bsTs6xA4V3+l07dMWSlkLe6WM1l59NnFVegxFjSEMyfv6YjB8/xOWyKzH4BRWEatK/eIPUj1/AWL8xhsD6tk/3ApzvJvrDH6n8771YXvwwDk83A6P6eZZY3qWNC4dO5Tp2Fyqg7A27nO26fVdyjx9CZ5Xs4qqcXfC7cxKpi79C5zh25Qqo1LHZtUM3co4fLOxCBYDWxL31NNFTJuDcuAVO9RvWQJLVT5fxvZZ1rAbod/2r3PLsGnyCm3Fs92+F85u0H8L1jy/nits+4N+VM2ss1+pS5pZ8dpHLPH1bg7795G2uv2MiBmPZNxzqDIOh+l8OqtaM2Vi74ls2/PUTAI2adyC5WB/nlIQYvP2Cy1u1FF//kCqtb2v+AUEkxBXdKUmMj8PfP7BETEBgMAnxRTEJCXH4+wewcd3fbN20nu1bN5Kbm0tWVgYz357GxCdftFn+lbHuj2/YtOpHABo2O+t7TozBp5LfU9TJg/wwdwr3P/MxHl6+1ZmqzWVFRuMWVo//7ou7NqhHTlQsBmcTbmFFd9ZcG4SQHeW4LXXFmZMTMfoVtWQY/fwxpySWGeve7XIytxV1u3Bu1gbXjt2p174LyuSMcnXD745HSPrygxrP+0Lp9GSUV9HdXoOXLzq9ZNc5nZZMflY65OWi83Ixnz6KIagBluJdCHOyyD99BKembcmNP2Or9Cvlil7uDOzhAcCxiFwCfIouLPy9jSSnmUutk5xmbaHKN0P4v5mM6FOysnFZJzc27HT8C29zSiJG36Lt2uDjjzklqcxYt85FXaiKVjDid9cksv5dT/buLTWZarWxJCeUKLPRN6D8MnftTVaxLlTF6axMco7sw7XNJaSfOV0juVbVvg1fc3Cr9TwV2KADGSlF56nM1GjcvYLKXddgMNKs43B2r/2UVt2uLbGsftMehCeeJjsjCVcPx+o6t2r594Sv/AWAJi3ak5hQ1MsgKSEWX7+SZfb09iUzIx2zOR+j0YnE+Bh8C65bTh7dx5x3ngWsLSC7t63DYDTStddAG5XGQdS2u9xV4LjVoLP0vfIWnnrzR55680c69hjElvAlaK05cWgnru6e+PiVv3OfrUP3gVVa39ZatGrDmagIYqKjyMvLY334X3Tv1adETPdel7Nm1e9orTl0YC/u7p74+Qcy9q4HmPPFz3z46UImPfUSHTp1ddiKBkCfobfyxOs/88TrP9Oh+2C2rbV+TycPW78n70p8T0nxUXz+7qPc8tBrBNVvUnNJ20jsr6tocNvVAPj2uoT81DRyouNI2bIbjxZNcGsShjKZCL1pJDFLV9k32fOUe/IITkH1MQYEg9EJt66Xk7Vra6k45eqOS4t2ZO8quvBKXfIN0S88QPSUh0j87F1yDu1x6IoGgPnMKYx+QSifADAYMbXpRt6R3SVi8o7swimsufVJJU4m6ziPxBiUmye4FAyCdzLh1Lg1lgTHHYf056ZMJs+KY/KsOLbtz6ZPF2vuzRuayMyxFFYsiis+jqNbW1ciYoqeWOXmomjTxIV/92eXWs/R5J0+ijGwHkb/IDAacetyGTl7t5WKU65uODdvW2qZz03jyI+JJCPcsQcKF5d76ihOQUVldu/am+w9Ze3Lbrg0b0f27qJlBg8vlJv1aWOYTLi06kB+bJStUq+0dpeN5ZpHfuGaR36hcbvBHNm+GK01sad2YHL1wt275E0xrTWpCScL/z51YDU+Qc0ASE04WdgzIT5yLxZzHi7uvjYtz/kYNOImXnr3O1569zu69BrAP38vRWvN0YO7cHf3xNe/5LlZKUXrDt3ZWjCe7p+/l9K55wAA3pizlDfnLuPNucvodtkV3Db+2bpX0ahjak3LRnHtuvRl3/ZwXn50BM7Ortw6oaiP48evTeCW8VPx8Q9mzW9f89eST0lLTuCNp66jXee+3PLA1ArXd0RGoxP3PjCJ6S8+gcViYeCQkTRs3JQ/li8CYOiIq+na/TK2b93II/ffjLOLKw899qx9k64Gbbv0Y/+OcF57bDgmF1duHl/0Pc174wFuvH8aPv7BrP19AX//+ilpyfG88/Q1tOnSj5vGTeOPnz8mMz2Fnz99GQCDwYlJr/5gr+KcU+ev3iGgf0+cA/0YdHwNh6d9gDJZd9FTc78j9rc1BA3vz4ADKzFnZbHrvucA0GYzex6dRs9l81FGIxGf/0T6vtrR3xmLheQfPiHwockoZSBj49/kR0fg0WcIABnrrI+FdbukJ9kHdhYOIq21tIWsPxficf2DYFDk7d6IJSEa50suByB353osiTHkHd+P513PgNbk7t6AJf4MhqBQPIbfVtBUrsg7uJ38Y3vtW57ztONgDpe0cuWdx4PJzdPM/Tm5cNmTd/gz/5dkktMsTLjBD28PAyg4dSaPTxcXtfp0b+fK7iM55OQ5ehcqwGIh9efP8R/3DCgDWZtXkx8Tiftl1sGymRusF2CuHXuQc3B3ie3a1LQ17t37khd1isDHXwUgbfkP5BzYYfNiVIrFQvJPnxI44TkwGMjYuJr86AjcL7c+0jRz/Z8AuHXqSfbBXSXKbPDxw2/sgyiD9VeQs7ZvIHvvv3YpRmU1bN2fiIPhLHznSpxMrvS97tXCZSs+H0efa1/B3TOQNQufJS8nHa01AfXb0PuqKQAc3/MHR7YvxmA0YXRyYeDNM8rthuUoOnXrw+5t63h2wlUFj759qXDZey8/wp0PvYiffxA33DGROe88y6JvZtOwaRv6XnG13XJ2SLVsHG1VqDL7+lej33fk1oIzQ/UK9Ui2dwo2dyqt7j1RQvUq/Sz1i90l4zvZOwWb82pc79xBF5GHkmv/jYrKeiv7SXunYHOW/NLd2C52X/f71t4p2Fzvto7f7bC69Wnn4di1tQLZy+dW+/Wx64hxDln2WtmyIYQQQgghRK3lwAO6q5tUNoQQQgghhLAlB+8uV53qTrVKCCGEEEKIOkwpNUwpdVApdUQp9UwFcT2UUmalVJV/EEVaNoQQQgghhLAlOwwQV0oZgdnAECAC2KKUWqK13ldG3BvAiur43HOWVCkVpJTqrpTyrY4PFEIIIYQQQthcT+CI1vqY1joX+A64qoy4R4CfgGr50a4KKxtKqfuAvcAHwAGl1Jjq+FAhhBBCCCHqLKWq/aWUGqeU2lrsNe6sT20AFP+1zIiCecXSUg2Aa4CPq6uo5+pG9RjQXmsdp5RqBnwNLKmuDxdCCCGEEKLOqYGnUWmt5wJzKwgpa1T62Y/gfQ94Wmttrq7ffDlXZSNXax0HoLU+ppRyqZZPFUIIIYQQQthSBNCw2HQYEHVWTHfgu4KKRiAwQimVr7VedKEfeq7KRphSamZ501rriRf6wUIIIYQQQtRF2j6Pvt0CtFRKNQUigZuBW0vkpXXT//5WSn0OLK1KRQPOXdn431nT26ryYUIIIYQQQgjb01rnK6UexvqUKSPwqdZ6r1LqgYLl1TZOo7gKKxta6y/KW6aUksfmCiGEEEIIUVl2ePQtgNZ6ObD8rHllVjK01ndVx2ee62lU64r9/dVZizdXRwJCCCGEEEKIi9O5Wic8iv3d/qxlded31oUQQgghhKgudmrZsIdzVTbOfhzW+S4TQgghhBBClMFOA8Tt4lyVDV+l1DVYu1v5KqWuLZivAJ8azUwIIYQQQghRq52rsrEGGFPs79HFloWXt1LBLxaOA3hiykzG3HBPVXKsdUyGPHunYHPJGUZ7p2BzA8Z3sncKNrdzzi57p2Bz9fudsXcKNnXC/bC9U7C5Xf/stHcKNpefmm/vFGzuWGiKvVOwufpBfvZOweb62DuB8yXdqAr9qrX+ubJvWvwXDMP3Zkh3KyGEEEIIIeqgc1WrnrdJFkIIIYQQQtQVSlX/y0HJb2UIIYQQQghhSwbpRvWfNkqpsjppK0Brretep3UhhBBCCCHEeTlXZeM4JQeFCyGEEEIIIapAHn1bJEdrfdImmQghhBBCCCEuKufqMOaslHrovwml1Cal1LGC1/U1nJsQQgghhBAXH2Wo/peDOlfLRiqwpNi0C9AD8AA+A36sobyEEEIIIYS4KGkHrhxUt3NVNkxa69PFptdprROABKWURw3mJYQQQgghhKjlzlXZKPHTk1rrh4tNBlV/OkIIIYQQQlzk6tAA8XO14WxSSt1/9kyl1Hhgc82kJIQQQgghhLgYnKtlYxKwSCl1K/BvwbxuWMduXF2DeQkhhBBCCHFRkjEbBbTWsUBvpdQgoH3B7GVa61U1npkQQgghhBAXozrUjepcLRsAFFQupIIhhBBCCCGEOG/nVdlwNFprvvvkLXb/uw5nF1fufngqjZu3LRUXFxPJvBnPkpGeQqOmbbj30VdwMpk4uGcrs19/nIDgUAC6XjqI0TeOs3UxKuXfrZuZP2cWFouFIVeO4Lobby2xXGvN/Dmz2LZlEy4urkx8/Cmat2gFwJJfFrJyxXKUUjRu0pRHJj2Ns7OzPYpRKVprVnw7nSO7wzE5uzLmnteo37h9qbhf5j1J1Ik9GI0mQpt2ZOTtUzE6mc57fUfi0rYzvtffjTIYyPjnL9JWLiqx3HPwGNx79AVAGQw41Qsj6pl70ZnpFMwk+KnXMackkvDx6zbOvvI6zXuV4BEDyI1NILzL6DJj2r07meBh/TFnZbPz3mdI3b4PgKChfWk3YzLKaOD0pws5+tY8W6Z+wbx79CLsoUfBYCBh+VJivltQYrnBw4Omz76IKTgEZTQS88O3JK5YjktYQ5q+MK0wzqV+KFGfzyfu54W2LsIFeXRccy7rFkB2jplX3z/IoaPppWJmv94ZdzcjAH4+JvYdTuO56XsB6NLBh4n3t8DJSZGcmscjz+60af6VFTioD21eewZlMBKx4CeOvz+/xHInH286fPAy7k0aYsnJZc8jz5N+4AgAjR+4g7Dbr0NrTfq+w+x5ZDKWnFx7FKNSzrVPOvl6c8m8V3Fv3ghLdg4773+O9L2HAWjyyB00uucGUIpTny7kxMwv7FGEC3LjYDc6NDeRm6f5Ynkmp2PMpWLuHOFOy4ZOZOVoAL5YnklErJkQfwN3jvCgYYiRJWuzWLk5x9bpV5rWmj++m86R3WswObsy+u7Xyzk3P8GZk0Xn5hG3TcPoZCL+zFF+/fw5ok/tZcDVk7jsynvtUAoHUIe6UdXKku75dz2xZ04xffZibn/geb6e+1qZcT99NZMrRo9l+uzFuHt6s+6vRYXLWrTtzJQZ3zFlxncOX9Ewm83M+fB9Xpz2Oh98/Blr16zi9KkTJWK2bd3EmchIPpr/FQ9OfJyPZ70HQEJ8HEuX/MLb73/MzI8+xWy2sHZN7WikOrI7nMTYkzz06gpG3jGN5QumlhnXoddoHnzlN8ZPXUJ+Xjbb1/5YqfUdhjLgd+O9xH84nehXJuHW7XKc6oWVCEn/awmxr/+P2Nf/R8qSb8g5vK+oogF4DhxBfkykrTO/YBFf/MzmUfeVuzxoWD88WjRhdduh7J7wAh1mvWRdYDDQfuaLbB59H2s6jST05lF4tm1um6SrwmCg4cTHOfLsk+y/5zb8Bl2Ba+MmJUKCrrqWrJMnODDuLg4//ghhDzyMcnIiJ+I0B8bfbX1NuBdLTjYp68LtU45KurSbPw1D3bl5/Gbemn2IJye0LDPuoWd2cPej27j70W3sOZhK+D/xAHh6GHl8QkueeWUPtz+0lRde32fL9CvPYKDtm5PZduMDrOs9hvrXjsCjdcnts9mk+0nbfYB/+l3L7gefpc1rzwLgUj+YRuPGsmHwjfzT52qU0UC9a0fYoxSVcx77ZItnHiB1537Wdh3Djrufpv2MyQB4tm9Jo3tuYF3vG1jb7SpCRgzAvUVje5Si0jo0cyLY38iLc1P5ekUmtw51Lzf259VZTP88jemfpxERa62QZGZrvv8zkz83Z9sq5So7uiecxNgTPDj9D0bc/jK/ff1SmXEdLx3DhJd/Z9xLv5KXm8OOddYbI24evlx582QuHVpHKxl1UK2sbOzYvJpLB4xCKUXz1p3IzEgjOTGuRIzWmoO7t9DtssEA9B44iu2b/7ZHulV2+NAB6oc2oF79UEwmE336DWLThn9KxGze+A8DBg9BKUXrNu3IyEgnMTEBsFZWcnNzrP/m5OAfEGCPYlTaoR1/0emyq1BKEda8M9mZqaQlx5aKa9mpP0oplFKENulEalJ0pdZ3FM5NWpAfH405IRbM+WT9ux63Tt3LjXfv3oesbesKp42+/ri270rGP3/ZIt1qkbhuK3mJKeUuDxkzmMgFiwBI3rQTk483LvWC8O3ZicyjJ8k6HoHOyyPq+2WEjB5so6wvnEebtuRERpB7Jgqdn0/S33/i07tPySCtMbpZL1gMbm7kp6WizSXvlHp16UZOVCS5sTG2Sr1K+l4awO+rrPvl3oNpeHo4EeBXfuuqm5uRbp18Cd9orWwM6R9C+IZ4YuKsd32TU/JqPukq8Onakczjp8k6ad0+z/yynODhA0vEeLZuTkL4JgAyDh/HrWEozkHWY7NyMmJ0dUUZjRjcXMk547jHrf+czz7p1bY58X9vBCDj4DHcGjfAOTgAzzbNSdq8E0tWNtpsJiF8C/WuGmKPYlRap5bObNxj3S6PR5lxc1F4e5x/X/y0TM3JaDNmS01lWP0O7viLjpdefc5za4uORefmBk07kZpkPV55eAcQ2rQTBmOt7FxTbbRS1f5yVLWyspGUGIt/YEjhtF9AcKnKRnpaMm4enhgLNma/gBCSE4pijh3czdRJN/H+yw8TeeqobRK/QIkJ8QQGBhdOBwQGkphQsryJ8fEEBhWPCSIxPp6AwCCuvvZG7r/zZu4eez3uHh506drDZrlXRVpyDN7+9Qunvf3qkZZc/sWVOT+P3RuX0KJD3wta396MPv6YkxIKp81JiRh9yq4YKpMzrm07k7ljU+E8n+vuJmXRAtC16Kx1Dq6hIWRFRBdOZ0dG49ogpIz5Mbg2CCnrLRyKKTCI3Liik3JeXBymwJI/WRS36CdcGzem4w+LaDv/CyJmvw9al4jxG3gFSav+tEnO1SEwwIXY+KLuIbEJOQQGlF/Z6H9pIFt3JpOZZa1kNQx1w8vTiQ9evYRP3u3KsIGO/V271g8hO/JM4XR2VAyu9UvmnLb3ICGjrgCslRPXhqG4hoaQcyaWE7M+p9/OPxmwbzX5qekkrC55c8kRnc8+mbrrAPWutlYifHp0xK1xKK5h9Ujfewj/Pt0x+fticHMleHg/3BrWs2n+F8rXU5GUWnTMTU6z4OtV9qXVmL5uPH+3FzcMcsPJaKsMq19aUgze/kXfz/mdmxfTvH1fW6QnHFCtrGygS88qVaErM8Ya1KhZG16fs4wp737PoBE38+Ebj1d/jtVI63MXWJfzn5KelsbmjeuZ89k3fLpgIdnZ2axetbKGMq1eZRab8mvuv309jUatutOoVfcLWt/uykytjEIArh27k3PsQGEXKtcOXbGkpZB3+ljN5WcHqow7NVrrsp/iUdYX7nDOnbd3j15kHjnM7huv5sC4u2n4yCQM7kVdM5STE769LycpvPa01FZi0wbgiv7B/BleVCkzGhWtm3vxv6m7eXzKLu68uRENQ92qPc9qU+bXXLLAx96fj8nXm8tW/0Sj+28lbfcBdL4ZJx9vgkcMIrzrUFa3H4jRw436N4yyUeJVcB775NE352Ly86bP1kU0eeh2UnfsR+fnk37gGMfenk+v3z+l57L5pO46iCW/9LgHR1TWMaqsbfuXNVm8ND+V179Mw91VMbSXa80nV2NKF7DM/4cCv30zlUYti87NooAyVP/LQdWaNqy/f/ue8JW/ANC0RXsS44tq0UkJsfj4lbw76OntS1ZGOmZzPkajE0kJMfj4BwLg5u5ZGNexWx++nvsaaalJeHmX+MF0hxEQGER8fNGJNyE+Hv+CspSIiSseE4d/QAA7d2wjuF59fHx8Abjs8r4c2L+XAYMcs4l6y6qv2b7W2q8ztElHUhOL7g6mJkXj6Rtc5nprlswiIy2RG2//oHCet1/Iea/vCMzJiRj9iloyjH7+mFMSy4x173Y5mdvWF047N2uDa8fu1GvfBWVyRrm64XfHIyR9+UGZ69cWWZHRuIXVI6lg2rVBPXKiYjE4m3ALK7qz5toghOwox+9qkhcfi3OxFkhTUBB5CfElYgKuHEF0waDxnKhIcqPP4NqwMZkH9wPg3fNSMg8fIj8pCUd27YhQRl9pbVncfziN4ECXwmXBAS7EJ5Y94Nnby4m2Lb14bvqewnlxCTmkpOaRnWMhO8fCzj0ptGjqwemorJotxAXKjorBtUFRq6praAg50SW3T3NaBnseeb5wut/2P8g8FUHgwMvJOhlBXoL1+41d+ie+PbtwZuFS2yR/gbIL9tX/lLVP5qdlsOu+5wqnBx7+i6zjEQCc/uxHTn9mHW/X+uVJZEc6bit0/y4u9LnE2jJ3MtqMn7cBIq2VI18vA8nppVuXUzOsF+j5ZtiwO5crerqUinFkW//+mu3hPwBQv2lHUhOLWrFSk6Lx9Cn73Bq+ZBaZaYmMnDDLJnnWJtqRb35WM8etBp1l4PCbCgd0d+45gI2rl6K15ujBXbi5e+LrX7KyoZSidYfubNtg7b/+z99L6dxjAAApSfGFd5mOH96D1hpPL19bFqdSWrZqw5moSGKiz5CXl8e68FX0vPSyEjE9e/Vm9V8rrWNVDuzDw8MDf/8AgoJCOHRgHznZ2Wit2bXjX8IaNrJTSc6tx6CxjJuyiHFTFtG6y2B2bViM1pqIoztwdfPCq4zKwvbwhRzbu45rx72DMhRt0q06Dzqv9R1F7skjOAXVxxgQDEYn3LpeTtauraXilKs7Li3akb1rS+G81CXfEP3CA0RPeYjEz94l59CeWl/RAIj9dRUNbrsaAN9el5CfmkZOdBwpW3bj0aIJbk3CUCYToTeNJGap4z/4IOPAAVwaNMS5Xn2UkxN+A68g5Z/1JWJyY2Pw7mK9A+jk54dLw0bknIkqXO436AoSa0EXqp+XRxUO9l67MZ5hg6wXou1be5GemU9CUtmVjYGXB/HPlgRy84runq7dmECn9j4YDeDiYqBda29OnM60STkuROr2Pbg3a4RbowYok4n614wg9reSLVFO3l4okwmAsNuvJ3HDVsxpGWRHnsG3+yUY3Kx3vv37XUrGIcfu6guc1z7p5FNU5ob33kDiuq3kp2UA4BzkD4Brw/rUu3ookd85buVqzfacwoHeOw7lcmkHa8WhaaiR7BxdWLEorvg4jktamYiKr13dXbsPHMv9UxZz/5TFtO58Bbs3Ljr3uXntQo7tW8c1988ocW4WdU+tadkormO3Puz+dx2TH7wKZxdX7nr4pcJl77/yCHc++CK+/kFcd/tE5s54lkXfzKZR0zb0ueJqALZt+JPVK37EaDBicnbh/sdfq7AJ0N6MRiP3T3iEqc8/jdli5oqhw2nUuCm/L1sCwLCRY+jWoxfbtmzigXtvsz76dtJTALRq05beffrz+MTxGI1GmjZrwZXDa0GTPNbBZUd2hzP7uaE4Obsy5u5XC5d9+944Rt31Ml6+ISxb8BK+AaF89trNALTpOoR+ox+qcH2HZLGQ/MMnBD40GaUMZGz8m/zoCDz6WFuhMtZZu7+5XdKT7AM70bmO/4jEc+n81TsE9O+Jc6Afg46v4fC0D1Am62Hp1NzviP1tDUHD+zPgwErMWVmFd0W12cyeR6fRc9l8lNFIxOc/kb7viD2Lcn4sZk5/MIMWb1hPvgm/LSP75HECR10FQPzSxUQv+JzGT02m7bwvQCmi5n2EOdU6iF65uODdrQen3n3LnqWotA1bE7msuz/fz+1Z+Ojb/7w1pQOvf3CIhIKWjiv6BbPgx1Ml1j8ZkcmmbYl8/kF3tIZf/zjD8VOOW9nQZjP7n55Ot4VzUUYDkd/8QsbBo4TddSMAEZ//gEerZnT88DW0xUzGwaPsmfgiACnbdhO95A8u+3shOt9M2u79nP7C8R9vXN4+2Wic9bh8au53eLZtTudP30CbLaTvP8LOcZML1+/2wweY/H3R+fnsmTiV/ORUexWlUvYcy6dDczMvj/MmNx++WJ5RuOzh6z356vcMUtI194z2wMvdesEdEZvPNyus26+3h+LZO71xdVZorRnU3ZWp81PIduAnHVvPrWuYPXkIJmc3Rt9V7Nz8/v2MuvMVvHxDWL5gCj4BoXz+2k0AtO46hH6jHyY9JY5PXrmOnOx0lDKw+c8veGDaclzcPMv7yItSXfoFcVXmeIBqFL63jCr+RS7INdneKdjctqhQe6dgcwO+v9HeKdjczjm77J2CzdXvF3TuoIvIRPfp9k7B5l7450F7p2Bz+an59k7B5n59ZaO9U7C5yy9zzO7hNen2frWjf1Ly9lXVfn3s22WQQ5a9VrZsCCGEEEIIUWvVoZYNqWwIIYQQQghhQ478uxjVre5Uq4QQQgghhBA2JS0bQgghhBBC2FBdGiBed0oqhBBCCCGEsClp2RBCCCGEEMKW6tCYDalsCCGEEEIIYUPSjUoIIYQQQgghqkhaNoQQQgghhLAhXTt+e7BalNuyoZT6w5aJCCGEEEIIIS4uFbVsBNksCyGEEEIIIeqIujRmo6LKho9S6tryFmqtf66BfIQQQgghhBAXiQorG8AoKLNTmQaksiGEEEIIIURl2enRt0qpYcD7gBGYr7V+/azlY4GnCybTgQla651V+cyKKhsntdb3VOXNhRBCCCGEECVpOzwQVillBGYDQ4AIYItSaonWel+xsONAf611klJqODAX6FWVz62opHVnmLwQQgghhBAXt57AEa31Ma11LvAdcFXxAK31P1rrpILJjUBYVT+0opaN26r65kIIIYQQQoiStH26UTUAThebjqDiVot7gd+q+qEVVTY2K6XMZcxXgNZae5e3olJqHDAOYOorr3HTzWOrlmUtk2lxs3cKNpedW/cawrwa17N3CjZXv98Ze6dgc2fC4+ydgk2NWNDH3inYnH+Sl71TsDllrHvH7GN7Ttg7BZvr1dPP3ikIGyp+/V1grtZ6bvGQMlbT5bzXQKyVjSqfFCqqbBzSWne5kDctKNhcgINHT5dZCCGEEEIIIeqimnj0bfHr73JEAA2LTYcBUWcHKaU6AfOB4VrrhKrmVVFlQyoJQgghhBBCVDM7/YL4FqClUqopEAncDNxaPEAp1QjrE2dv11ofqo4PraiyEayUery8hVrrGdWRgBBCCCGEEKJmaa3zlVIPAyuwPvr2U631XqXUAwXLPwZeBAKAD5V1XEm+1rp7VT63osqGEfBEnkolhBBCCCFEtbHXL4hrrZcDy8+a93Gxv+8D7qvOz6yosnFGaz2tOj9MCCGEEEIIUXdUVNmQFg0hhBBCCCGqmZ0efWsXFVU2BtssCyGEEEIIIeoIOw0Qt4tyO4xprRNtmYgQQgghhBDi4lJRy4YQQgghhBCimtlrgLg91J2SCiGEEEIIIWxKWjaEEEIIIYSwIRmzIYQQQgghhBBVJC0bQgghhBBC2FBdGrMhlQ0hhBBCCCFsqC51o6qVlY1tWzczf86HmC0Whl45nOtvvKXEcq018+bMZuuWzbi4uPDY40/RvEVLAJYs+pk/VixHa83QYSO46urr7FGEStuxbSNfzH0Pi8XCoKGjueqG20ss11rzxdz32L51Ay4urkx4bDJNW7QmNzeHqU8/RF5eHhZLPr0uH8gNY6v1V+hrjNaaVQunc2zvGpxMroy443VCGrUvFbf0syeIPrkHo9FEvSYdGXrrNIxGE6cObeKXjx/EJzAMgFadh9B7xMO2LkalODVpi+vg60AZyNu1gZzNK0vFGBu2wG3QdWAworPSyfhuJhid8LjlMZTRCQwG8g7tIGf9cjuUoPK8e/Qi7KFHwWAgYflSYr5bUGK5wcODps++iCk4BGU0EvPDtySuWI5LWEOavjCtMM6lfihRn88n7ueFti5CpXSa9yrBIwaQG5tAeJfRZca0e3cywcP6Y87KZue9z5C6fR8AQUP70m7GZJTRwOlPF3L0rXm2TL1KhnRRNK+vyDfDr5stxCSVjhnRQ1HfX6GAxDRrXF6+dVmjIBjSxYDBAFk5sOBvi03zryzvXpfS6NFJKIOBuKVLiF7wVYnlRg8Pmr04FecQ63Yd/e3XxC9fBkDIDTcSOPoqlFLELVlMzMLv7VGESvPueSmNHnkMDEbily0h+pvSZW76/Es4F+zL0d9/Q8Jv1jIHX3cjQaPGgFLELV1C7I+1o8wAD97egB6X+JCTY+HtuSc5cjKrzLi7rq9Pv56+WCywdFU8i/6Iw9PdyBP3N6J+sAu5eRZmzD/FiYhsG5egcrTW/PnDdI7uWYPJ2ZWRd75OvTLOzUs+eYLoU3swGE3Ub9KRYWOt5+ZDO/5k7a/vo5QBg8HI4Bufo2GL7nYoibCVWlfZMJvNzPnwA6ZNf4OAwCCeeOwhel7am0aNGhfGbNu6majISObM/4KDB/fz0az3efu9WZw8cZw/ViznnXdn4WQy8dILz9CjRy9CG4TZsUTnZjGb+fSjd5j8ynsEBATz3KT76NarD2GNmhbG7Ni6gTNREbw393uOHNzL/A/fZvqMeZhMzrzw6kxc3dzJz89nylMT6NztUlq26WDHEp2f43vDSYo9wX0v/cGZEztZ+d1L3PZU6QvJdj3GMPKutwFrxWPX+oV06XcrAGEtunPdg3NsmvcFUwrXITeQ8cNsdFoynrf/j7yju7EkRBfFuLjhdsWNZPz4ETotCeXuaZ1vzifj+5mQlwsGAx63TCL/2D7MZ07YpSjnzWCg4cTHOfzUJPLiYmn94XxSNqwj++SJwpCgq64l6+QJjj7/NE4+vrT7/BuS/vqDnIjTHBh/d+H7dPz+F1LWhdunHJUQ8cXPnPhwAZ0/faPM5UHD+uHRogmr2w7Ft9cldJj1Ev9cfiMYDLSf+SKbht9NdkQMfTb+SMzSVaTvP2rjElRe8/rg76X4eLmF0AAY1s3AF3+Wriz8uV2Tm68BGNxZ0b2FYsMBjYvJus534RZSM8HdxdYlqCSDgcaPP8mhSRPJjY2l3fzPSF63luwTJwpDgq+9nqwTxzn89JM4+frS8ZvvSfhjBa4NGxE4+ir2338Plvx8Wr3zHskb/iEn4rT9ynM+DAYaPfYEh554lLy4WNrO+ZTk9WtL7svXWMt85Nn/4eTjS4cF35O4cgUuDRsRNGoM+x+411rmN98lZcN6ciIj7Fee89TjEm8ahLhy95P7aNPcnYl3N2TiS4dKxQ3t609QgDP3Pr0frcHX23r5dcuYEI6eymLq+8dpWN+Fh+9syNOvH7F1MSrl2B7ruXn8tD+IOr6TFd+8xJ3PlD43t+85htH3WM/NSz55gp3rFtK1/600aXMZLS8ZjFKK2IgDLJr3GOOm/m7rYthdXepGVetKevjQQeqHhlKvfigmk4m+/QawacP6EjGbNv7DwMFDUErRpk07MjLSSUxM4PTpU7Ru3RYXV1eMRiPtO1zChn/Wl/NJjuPIof3Uqx9GSL0GOJlM9O43mK0b15aI2bppHf0GDUMpRcs2HcjMSCMpMR6lFK5u7gCY8/Mxm/NB1Y6mu8O7/qJ9r6tRShHatDPZmamkp8SWimvWoT9KKZRS1G/cifSkGDtkW3XG+o2xJMWjUxLAYibvwDZMLTqWiHFu2528wzvRadbbwjozvWhhXq71X4MRZTQC2kaZXziPNm3JiYwg90wUOj+fpL//xKd3n5JBWmMs2IYNbm7kp6WizeYSIV5dupETFUlurON/94nrtpKXmFLu8pAxg4lcsAiA5E07Mfl441IvCN+encg8epKs4xHovDyivl9GyOjBNsq6alo1UOw+Yd0eoxLA1QQerqXjcvOL/jYZi7bg9o0VByM0qZnW6cycms23qjzatiMnIoKcKOt2nfjnSvz69CsZpDVG92Lbdap1u3Zt0oSMvXux5OSA2Uza9n/x69ffDqWoHI+27Ursy4mr/sT3PMvs1rgJ6fuKlXnn9lpRZoDeXX1Yuc76G8gHjmbi4W7E36f0fdxRgwP5+pcz6IKNOjnVurE3auDK9r1pAJw+k0NIoHNhRcRRHd71Fx0utZ6bGzTrTE5W2efm5h2LnZubdCKt4Nzs7OqBKrgOycvNKvxbXLxqXWUjISGewMDgwunAwCASEhJKxsTHExQUVDgdEBhEQnw8jRs3Ye+eXaSmppCTnc22rZuIjy+9gziaxIQ4AoKKyuwfGExiQlzpmGL/L/4BRTEWs5mnH7mTcbeNomPnHrRsXbq50xGlJ8fg5VevcNrLrx7pyeVfTJrNeezdvJim7fsWzos6voPPp4/hx1n3ER91uEbzrSrl6VtYiQCwpCWjPH1LxBj8glCu7njcNBHP2/+HqX3PYm+g8Lzzabwfeo38Ewcwnzlpo8wvnCkwiNy4on0wLy4OU2BQiZi4RT/h2rgxHX9YRNv5XxAx+30Kz9gF/AZeQdKqP22Sc01zDQ0hK6KoNSs7MhrXBiFlzI/BtUGIPVKsNE83RWpm0XeWlgVebmXHjuypePQqAwFeiq2Hrev4e4GrM4wdaODuIQY6NHHsixPnoCByY4u269y4WExBJbfrmJ9+xLVxEy5ZtJQOX3zNqfffBa3JOnYMr86dMXp7Y3Bxwfey3jgHO/737BxYuszOZ+3LsT9by9zp519p/9kCTn9QUObjR/G6pKjMPpdehqkWlBkgwM9EXGJu4XR8Yh4B/qZScaHBLvS/1I9ZU1sz/cnmhIZYm+eOncqiT3dfAFo3cyck0JmgMtZ3JGlnn5t965F2rnPzpsU0K3ZuPrh9JXOnDGPhrPGMuOPVGs3XUWlUtb8clWNXn8ugdem7taUrxWXFKBo2asy1N9zMi5OfxtXVjaZNm2M0Gmsm0WpVdnlKhpQfYzAaeeODL8hIT+Od6c9y+sQxGjZpViOZVqsyylRRq8yf302lYYvuhBX0/Qxp2J7xL6/C2dWDY3vW8Much7h/6h81lW0NOev/wGDEGNKQjB9moZxMeIx9HHPUcSxJcaA16V+8AS5ueFx9H4bA+ljiz9gn7fNWxvd51vfu3aMXmUcOc/iJibiENqDFm++yf/dOLJnW29zKyQnf3pcT9cnHtki4xpV1l09rXfa2X9Y+4oAqcwpctlmjlGZoV0W7RopdxzUGBfX8Fd/8bcHJCHdeYSAqXpOYfu73s4syv6uSkz69epF5+BAHJz6ES4MwWr87kz07byP75AnOLPiK1u9+gCUrk8wjh9Hm/NLv52jK2m7PKrRPz15kHT7MoccexqVBGK3eeZ+99+wg++RJor9ZQKt3ZhaU+Qjkm0u9nyMq85RUxm5pMily8zQPTznI5d19eOL+RjzxymG+/zWGCbeH8dErrTl+OpsjJzMxO/ZwpLKvNyrYy//4ZioNW3anYcuicRmtuwyhdZchnDq8hfAl73PLY5/XRKYOTdehFp1aV9kIDAwq0RoRHx+Hv39AiZiAwCDi4oru/CfEx+EfYI0ZeuVwhl45HIAvP/+EwMBAG2RdNf4BwSQUu/ubGB+Ln3/JvP0Dg0ko9v+SmFA6xsPTi3Ydu7Lj340OW9n4d83X7Fr/AwD1G3ckLanoTm5aUjSePsFlrrd+2Swy0xK5etyswnkubp6Ffzfr0J+V300lMz0Rd0//Gsq+anR6MsrLr3Da4OWLTi/Z3UanJZOflQ55uei8XMynj2IIamCtbPwnJ4v800dwatqWXAevbOTFx+JcrNXOFBREXkJ8iZiAK0cQXTBoPCcqktzoM7g2bEzmwf2AdVBq5uFD5CeVMeK4FsqKjMYtrB7/lca1QT1yomIxOJtwCyu6m+jaIITsKMdtme3WQtG5mfVkGpWo8XZX/HcV5uVmbd0oj9aw/5SmVxsDu45r0jIhK0eTZ4Y8M5yK0wT74rCVjdzYWJyDi7Zr56Bg8uJLtkYHjhjFmQVfApATGUHOmSjcGjchY/8+4pf9SvyyXwFoMO4BcuNKruuIcuPKKvNZ+/LwkYWDxgvL3KgJGQf2Eb/8V+KXF5T5/gdKtHg6mtFXBDJigPWa4uCxTIL8nYEMAAL9TSQk5ZVaJz4xj3VbkgFYvzWFJ++3jjPNzLbwzrxThXFfzmhHdKzj9RPctvprdq4r59ycHI2nb9nn5nVLZ5GZnsi1Y2eVubxRyx4sizvl0OdmUXW1rhtVy1atiYqKJDr6DHl5eawNX02vS3uXiOnZ6zL+/mslWmsOHNiHu4dHYYUkOdl6Co+LjWHDP+vo13+QzctQWc1btSE6KoLY6Cjy8/L4J/wvuvUq2a+9W68+hK/6Ha01hw/swd3dEz//QFJTkshIt/YHzc3JYfeOLYSGNS7rYxxC1/5jueu5xdz13GJadLqCvZsWobUm6vgOXNy8yqxs7Fq/kBP71jHqnhkoQ9EmnZ4SV9gSdubELrS24ObhV2p9R2E+cwqjXxDKJwAMRkxtupF3ZHeJmLwju3AKaw7KAE4m6ziPxBiUmye4FPRLcTLh1Lg1lgTHH7+QceAALg0a4lyvPsrJCb+BV5By1jiq3NgYvLtY74g5+fnh0rAROWeiCpf7DbqCxIukCxVA7K+raHDb1QD49rqE/NQ0cqLjSNmyG48WTXBrEoYymQi9aSQxS1fZN9kKbDui+eQPC5/8YeFQpKZjQden0ADIyYOMMh6441d0f4AWoYqEVOv+eyhS0zBIoRQ4GaFBgCIhzRaluDAZB/bj0rAhzvWt27X/FUNIWl9ynF1uTAze3XsA4OTnj2ujRuRERVqnfa3HKeeQEPz6DyDxT8dvkc04sB/XsKJ92X/QFSSfXebYGLy7Fu3Lrg0bk3PmrDIHh+DbdwCJf5Z+Ep+j+PXPeCY8f5AJzx/kn20pDOljvUhu09ydjEwziSmlW6LWb0uhczvrBt6pjScR0dYdwMPdiJPRum8MHxDA7oMZZGY7XtNGtwFjuef5xdzz/GJadr6CPRut5+bIYztwcS373Lxz3UKO71vHmHtLnpuTYk8WnpujT+3FnJ/n0OfmmqK1qvaXo6p1LRtGo5HxEx7hpeefwWKxcMXQYTRq3ITfCu4CDR85mu49erFty2bG33sHLi4uTJz0v8L1X58+lbTUVIxOTjzw4CN4ennZqyjnzWh04u4HJvHqi49jsZgZOGQUDRs3Y+XyXwAYMuIaunS/jB1bN/Do/Tfi4uLKA489B0BSYgIfvfsKFosFi8XCZX0H0a3n5fYsznlr1qE/x/auYd6UIZic3Rh+e1G/zh9n38+wsa/g6RvCH99Owds/lK/fvgkoesTtoe0r2LH2WwwGI04mV0bfM8OxB6JpC1l/LsTj+gfBoMjbvRFLQjTOl1i/r9yd67EkxpB3fD+edz0DWpO7ewOW+DMYgkLxGH4bGAyAIu/gdvKP7bVvec6HxczpD2bQ4g3rySjht2VknzxO4KirAIhfupjoBZ/T+KnJtJ33BShF1LyPMKdaW3yUiwve3Xpw6t237FmKSun81TsE9O+Jc6Afg46v4fC0D1Am66H41NzviP1tDUHD+zPgwErMWVnsus+6L2uzmT2PTqPnsvkoo5GIz38ifZ9jP7XmP0fPQIv6mgkjDeTlw9LNRRdTN/Y1sHyLhfRsGNXLgIuTtWtKTLLm963WC5KENDh6RnP/lQY0sOOYJq78Mfb2ZzZzasbbtJ7xPhgMxC9bSvbx4wRddQ0AcYt/IerzT2k6+QXaf7EAlCLiow/JT7EWqsX013Dy9kGb8zk5423MaQ5cs/qP2cyp996h1dvvFT7GOvvEcYLGFJR5yS+c+eIzmjz7PO0+W4ACIubMLixz85dftZY5P59T772NOb0WlBnYvDOVnp29+fztduTkWnh7XtFYuVeebMaM+adITM7n+6UxPDOhMdcOCyYr28K7n1ifLtYo1IWnxjfGYoGTkdnMmH+qvI9yGM079OfYnjXMecF6bh5xZ9G5+YcP7mf47a/g5RvC799Mwcc/lK/eLDg3dxlCn5EPc3D7CvZsXIzB6ISTyZWr7n/Xsc/NospUWWMgqtPBo6drR6fiapRpKWfk40Vs2ynH745W3W749xF7p2BzR3/fbu8UbO5MuON3YalOOxfss3cKNjfkg9pxA6Y6KWPdu7h7rtGH9k7B5m65p4u9U7C5uwc68EjpYg4fPVnt18ctmzd2yLLXupYNIYQQQgghajNHfnpUdat1YzaEEEIIIYQQtYO0bAghhBBCCGFD0rIhhBBCCCGEEFUkLRtCCCGEEELYkLRsCCGEEEIIIUQVScuGEEIIIYQQNiQtG4BS6lpbJiKEEEIIIURdUJd+QbyiblTP2ywLIYQQQgghxEVHulEJIYQQQghhQ3WpG1VFlY02SqldZcxXgNZad6qhnIQQQgghhBAXgYoqG8eB0bZKRAghhBBCiLpAWjascrXWJ22WiRBCCCGEEHVAXapsVDRAfP3ZM5RSzZVSzyul9tRgTkIIIYQQQoiLQLmVDa31wwBKqfpKqceUUpuBvYARuMVG+QkhhBBCCHFRqUuPvi23G5VS6n6slYow4AfgPmCx1nrqud5UKTUOGAcw86nx3HPV0OrJtpZYmFv3fqKkc1iSvVOwuYdWPWvvFGzuhPthe6dgcyMW9LF3CjZ1yW3t7J2CzT11zZf2TsHm8nNy7Z2CzX08pZ69U7C5LHPdOzeDn70TEGepaMzGbGADcKvWeiuAUkqfz5tqrecCcwEy/vn5vNYRQgghhBCiLrDUoTEbFVU2woDrgBlKqRCsrRsmm2QlhBBCCCHERUoGiFv9rrX+SGvdDxgMpACxSqn9SqlXbZOeEEIIIYQQoraqqLJRWOXSWkdord/WWncDrgJyajwzIYQQQgghLkIyQNwqSCn1eDnL0moiGSGEEEIIIcTFo6LKhhHwhDI7lcmgbyGEEEIIIS5AXRqzUVFl44zWeprNMhFCCCGEEELUGKXUMOB9rI0K87XWr5+1XBUsHwFkAndprf+tymdWVNmoO1UuIYQQQgghbMQeYyyUUkasP20xBIgAtiillmit9xULGw60LHj1Aj4q+PeCVTRAfHBV3lgIIYQQQghRmkZV++s89ASOaK2Paa1zge+wPvipuKuAL7XVRsBXKVW/KmUtt7KhtU6syhsLIYQQQgghbEMpNU4ptbXYa9xZIQ2A08WmIwrmVTamUirqRiWEEEIIIYSoZjXRjUprPReYW0HI+Tz0qdofDFVRNyohhBBCCCHExSECaFhsOgyIuoCYSpHKhhBCCCGEEDZkqYHXedgCtFRKNVVKOQM3A0vOilkC3KGsLgVStNZnLrScIN2ohBBCCCGEsCl7PI1Ka52vlHoYWIH10befaq33KqUeKFj+MbAc62Nvj2B99O3dVf3cWlnZWL/7IG9/sxSzxcI1/Xpw98gBJZav/ncfH/6yEoNSGI0GnrxlFF1aNSlcbrZYuG3qLIL8vJn52F02zf1Caa1Z+f10ju5Zg8nZlVF3vU69Ru1LxS3+5AmiT+7BYDQR2qQjw26bhtFoYs+mJWxcMQ8AZxcPrrz1JUIatrF1MSpl57YNfDX/XSxmCwOGjmHM9XeUWK615st5M9i5dQPOLi6Mf+wFmja3lmnu+6+wfet6vH38eGPWN/ZI/4LdPtKbzq1dycnTzP0pmRNReaVixl3nS5smzmTlWLtRzvkpiVNn8hnZx4Pend0BMBigQZATE16NJiPLsX+H89FxzbmsWwDZOWZeff8gh46ml4qZ/Xpn3N2MAPj5mNh3OI3npu8FoEsHHybe3wInJ0Vyah6PPLvTpvlX1pAuiub1Fflm+HWzhZik0jEjeijq+ysUkJhmjcvLty5rFARDuhgwGCArBxb8fZ73tOyk07xXCR4xgNzYBMK7jC4zpt27kwke1h9zVjY7732G1O3WJzEGDe1LuxmTUUYDpz9dyNG35tky9Sp55O7G9OriS3aOhTc+PMrh45mlYt6f2rZwu/b1NnHgaDovvHWYK/oE8P/27js8iupr4Pj37qb3npBQQu+9ShfpKNjLDxuKKL42FAtioygWsGJDUVGwYUXAjvTee69JSCe97973jw0pZAMJJLsbcj7Psw87M3c25zAzO3Pn3jt766hwALJzTLz96XGOnCi7vqN59L5G9OgcQG6u2XIsH80sU2b2K+2Kj2U/Z/YdTOfZGfuKlrdo4sVHr3fgpZn7Wb420WaxX4ytmzfw2ZzZmM0mBg4ewfU3jy61XGvN3I/fY+vm9bi6uvHQhGdo3KQZAJkZ6bz/7hucOnEMUDz02NM0b1n2vO5oauu5+XKhtV6KpUJRct5HJd5r4P+q8m/WuMqGyWzmta8W8cHEewkN8OH2qe/Tr0NLGkWEFpXp1qox/Tq2RCnFwVOneeaDb/hpxuNFy7/5ew0N64SQkZNjjxQuypHdKzkTf5wHpv1FzLEd/LHgJe6etLBMudbdRjLynpmApeKxY/VCOvX7H35BdRn9xHzcPX05snsFv89/3ur6jsJsMvHFxzOZNPVdAgJDeP6JMXTq1oe69RsWldmxZR2xMaeY9fFCDh/Yw+cfvs7UmZ8B0OeqEQy6+kY+eqtm/S5l+2auhAU58cSb8TSu58zdI3156SPrJ9tv/khj057S+/CS1ZksWW05uXds4crQnl4OX9Ho0TmAeuEe3Hr/Rlo392bi+KaMm7itTLn/e2Z70fvpk1qxen0SAF6eRh4f35SJL+0iLiEXP19nW4V+URrXgQBvxUdLzYQHwtDOBub9U7ay8M82TV6BZdtd1UHRpYli3X6Nq7NlnW9XmknLAg9XW2dQeVHzfuL4B/Pp8NlrVpcHD+2LZ5NIlrccjF/39rSZ/RJre90MBgOt332BDcPGkBMVR+/1PxC3eBkZ+47YOIPK697Rl4gwN25/ZActm3oxYWxDHpy8p0y5R18svsie8kRT1myy1DxPx+fy2Et7ycg00a2DL0+Ms76+I+nR2Z+6ddy57YHNtGrmzRPjm3D/k2Ur/g89u7Po/bSnW7J6Y1LRtMEAD9zVkI3brNTAHYzJZOKTD9/hxekzCQwK5qkJD9C1Ry/q1Y8sKrN18wZOx0Tx/icLOHhgL3Pef4vX3voQgLlzZtOxczeeenYq+fn55OU6/jVJbT03V4fa9AviNW7Mxu6jp6gbEkjdkACcnZwY0q09y7ftK1XGw80Vyw8gQnZuXqlx9XHJqazacYBr+3a1ZdiX7NCOf2nT41qUUkQ06kBudhoZqfFlyjVp2w+lFEopwiPbkX4mDoC6jTvh7ukLQHjDDqSnxNo0/so6cmgvoXXqEhIWgZOzMz36DGLLhpWlymzZsJI+Vw5HKUXTFm3IyszgTLLlwrxlm454efnYI/RL0rmlG6u3ZQNw5FQ+nm4G/Lwv7jC9op0763ZmV2V41aJPj0D+WGbZH/ccSMfL04lAf5dyy7u7G+nczo+V6y3belC/UFauSyQuIReAlNSyLUGOpFmEYtdxSyUiJgncnMHTrWy5vILi987G4keBtG6gOBClSSu8yZ2VW73xVoXk1ZvJT04td3noyKuInv8LACkbduDs64NrWDB+3dqRdeQE2cei0Pn5xHy3hNBrasZPQPXq4s9fKy376L5DGXh6GgnwK78i7O5moGNrH1YXVjb2HMwgI9MEwN5DGQQFln9MOIre3QL54z/LeWnvwbPH8nlydjfSuZ0vq9YXVzZuGBHOinWJDn8cAxw+uJ864RGE1QnH2dmZ3n0HsHH9mlJlNq5fQ/8BQ1BK0bxFazIzM0hOTiIrK5O9u3cwcPAIAJydnfH08rZHGpVSW8/N4tLUuMpGwpk0wgJ8i6ZDAnyIP1P2JLZsyx6un/Qmj749jxfvuaFo/sxvFvPozcMwGGpWjTI9JQ6fgLCiaW+/sKKKhDUmUz671/9Ko9Z9yizbueYHGrfuWy1xVpXkpAQCg0KKpgOCQjiTlFC2THCJMoFly9Q0/j5GklJNRdPJaSb8fYxWy948yIdXHg5m9HAfnM4p4uKsaNfUjU17HL+yERToSnxi8RVzfFLueS+s+vUIYvOOFLKyLf9P9cLd8fZy4r1X2jP3rU4MvTK03HUdgZe7Ii2ruLUpPRu83a2XHdFN8egoA4Heis2HLOsEeIObC4y+0sCYQQbaRNas7zJr3MJDyY4qvgGSEx2LW0SolflxuEU49vY9KyjApdR+nZiUR1BA+ft1n24BbN2dVrRflzR8QDAbt6VUR5hVKjiwdM4JiXkEBZbf9Na3RyBbdqYW5RwU4ELfHkH8+scljUW1maSkBAKDgoumA4OCSbZyngoKLlsm7nQMPr5+zH7rVZ54eCzvv/M6OTmO/31dW8/N1UFrVeUvR1XjKhvWOoScbcUoaUDn1vw043FmPXwHH/78NwArt+8jwNuTVpGX9Nsk9qGtZG4l77P+/HoK9Zp2oV7TLqXmnziwnh1rfqD/9ROrOsKqZSXfsulaK+O4B1tFWAvf2qb//q80nnw7nhc+SMDL3cDVfb1KLe/YwpWDJ/McvgsVWH+g9/me6D2wXwj/rCxu1TMaFc0be/PklF08/uJO7rq1PvXCy7l6dwCV2UOXbNS8u8hMYrqmVX3LmgYFYQGK71ea+XaFmd6tFAFeF/ggB2ftuNVaV/yAcEBWv4rOE/uAXoEsW1O2y2SH1j4MvzKEOQtOWVnLsVjfjuWXH9gnuNSx/MjYRnw47xhmxx6CVMxqbqX/D6yeulGYzCaOHj7IkOGjmPXep7i5ufPTwhowhqGWnpurg51+QdwuatyYjRB/H2JLNMfHJ6cR7Fd+k1zn5g15MT6ZM+mZ7Dh0ghXb97F65wHy8gvIzMll8sff8fL9t9gi9Erb8t8Ctq/+HoA6kW1JSy6+w5eeEou3X4jV9Vb9Npus9GRueGB2qfnxUftZ+uVz3PzIJ3h4+Vdf4FUgICiEpMTik1ByYjx+AcGlywSGkJRQokxSPH4BQTaLsaoM7O7BlV09ATgalUegb3EzRYCPkZT0snc6U9ItZ+MCE6zcmsXw3qWvNq9o5866HY57l+z64eFcM6QOAPsOpRMSVHz3MyTQlcTkPKvr+Xg70bKpN8++vLtoXkJSLqlp+eTkmsnJNbNjdypNGnpyKsZx8u/cRNGhkeVEEJOs8fFQnD0he7tbWjfKozXsO6np3sLAzmOa9CzIztXkmyDfBCcTNCF+kFx2TH2NkR0di3vdMM720neLCCM3Jh6DizPudYtbdN0iQsmJKdt91FFcOySUEVdZvqf2H8m07NcHLBsmKNCFxDPWuwb5eDnRooknz89MKTW/UX13Jt7fkGdmHCAto8DquvZ23fA6XDPIso32Hy59LAcHuZCUbL2f39ljefKMvUXzmjfx5qWJloHEvj7O9Ojsj8mkWbUhyepn2FtgUDBJicV37JMSEwgIDCpTJjGhdBn/wCBU4bJmLVoBcEWvfjWislGbzs2i6tS4lo3WDetyKj6R6IRk8gsK+HPjDvp1bFmqzMm4RMtdMWDf8WjyC0z4eXnw8E1D+ePNSSyZ+TQzxt9Gl5aNHLaiAdD5ytHc+/yv3Pv8rzTrMJDd639Ba0300e24unvj5Vu2srF99UKO7V3NqLFvogzFmzc1OYYfP3qYa+55ncDQhmXWczSNmrYkNuYU8bExFOTns37V33TuXrpLWKdufVj131K01hzavxt3Dy/8a+AX2j8bspg8O4HJsxPYsi+H3h0td+Ub13MmK9dcVLEoqeQ4js4t3YiKK76IcXdVtIh0Zes+xx1s+NPSGMY8uoUxj25h1fpEhg6wXKy0bu5NRlYBSWesVzau7BXM2k1J5OUX3zlbtT6Jdq19MRrA1dVAq+Y+HD/lWE/t2XJYM/cvM3P/MnMwWtO2sOtTeCDk5kOmlU3lX6L+2CRckZRmyflgtKZesEIpcDJCRKAiKd0WWVSf+N+WEXH7tQD4dW9PQVo6ubEJpG7ahWeTSNwj66KcnQm/ZQRxi5fZN9jz+OXPOO57ajf3PbWbNRvPMLiv5fuoZVMvMrNMJKdYr2z0uyKA9VtTyC+xX4cEujB1YjNmzD5C1GnHPZZ/XnqaeyZs454J21i1PomhV1rOS62aeZORaSKpnArWlb2CWLs5udSxfMu4Tdxc+FqxNpE3Pz7isBUNgCbNmnM6Ooq42NPk5+ezeuUyunbvWapM1+49Wb7sT7TWHNi/Bw9PTwICAvEPCCQoOIToqJMA7NyxhXr1G9gjjUqpTefm6mbWVf9yVDWuZcPJaOTp0SP5v1mfYTZrRvbpQuOIUH74bwMAN17ZnWWb97B47VacjEZcXZx4dfxtNb4Jr3GbfhzZtYKPnhuEs4s7I+56pWjZd+/dx/A7puPtF8ofC17ENyCcL1+zVKKadxxE76sfYs3i98nJTOHPr6cAYDAYGTP5J7vkUhFGoxN33z+R1156FLPZTL+BV1O3fiP++d0S88Bh19OhS0+2b1nL4/ffiIurG/c/8lzR+rPfeJ59u7eSnpbCQ2Ou4cbb7qP/4JH2SqfCth/IpX0zN2Y9HkJevmbOTylFyybeGcCnP6eQkm5m/E3++HgaQMHJ0/l89mtxa1+XVm7sOpxLbr4Df/OUsG5zMld0CeC7Od2KHn171hsvtuHV9w6SVNjSMbBvCPN/OFlq/RNRWWzYkswX73VBa/jtr9McO+lYlY2SjpyGJnU040cYyC+AxRuLK5M39zGwdJOZjBy4ursBVydLF4W4FM0fmy3bMykdjpzW3DfEgAa2H9UklD/22iF0+GoWgf264RLkz4BjKzg09T2Us+X0c3LOt8T/voLgYf3ov/9vTNnZ7Bz7LADaZGL3o1PptuRTlNFI1Bc/krH3sD1TqbD121Lo3smP+e+2JzfPzGsfHC1aNuOZ5sz8+GjRhfiAnoF8/UvpH+i988YIfLyceGxsJAAmk+aBSY79NKp1W87Qo0sA337UhZxcMzPeO1i07PXnW/Pa+4eKjuWregcz/8coe4VaJYxGJ8aOf5Spzz+J2WzmqkHDqN+gIX8u/RWAIcNH0blrD7Zu3sCDY0fj6urKQxOeLlp/7P2P8PYb0ykoKCA0rA4PPfaMvVKpsNp6bhaXRulq7v+aufanmnHFU4UW5l1v7xBsrk0dx39MYVV7+0vH6aZjK8d3HrJ3CDY3/Pbe9g7Bptrf3sreIdjczOu+tHcINleQa7318HL20awm9g7B5rJNVh51d5nr0ty/RtxdXrEnq8qvj/u19nDI3GtcNyohhBBCCCFEzVDjulEJIYQQQghRkznyo2qrmlQ2hBBCCCGEsKEa8hTvKiHdqIQQQgghhBDVQlo2hBBCCCGEsCGzA/8IX1WTlg0hhBBCCCFEtZCWDSGEEEIIIWxIBogDSikfrXWaLYMRQgghhBDicicDxC22KaVutVkkQgghhBBCiMvK+SobA4BblFJ/K6Vq389uCiGEEEIIUQ00qspfjqrcblRa6xPAdUqpocAapdQmwFxi+UgbxCeEEEIIIYSooc47QFwp1Rx4ClgFvE+JyoYQQgghhBCi8sy1aMzG+QaIvwqMBJ7QWv9uu5CEEEIIIYS4fMnTqCxMQCetdY6tghFCCCGEEEJcPs43QDz1bEVDKXVTyQVKqVeqNSohhBBCCCEuU1pX/ctRna+yUfKxt5POWTa0GmIRQgghhBBCXEbO141KlfPe2nTphUqNA8YBjJn4EQNGjru46GqoK+sesHcINrc3vZG9Q7C5N3L+z94h2NzOtTvsHYLNBZzxtncINvXUdV/aOwSbm/jznfYOweaUc+3pL37WrAUr7R2Czd08ytPeIYhymB34UbVV7XyVDV3Oe2vTpRdqPQeYAzB/lSM37AghhBBCCCGqy/kqGx2UUmlYWjHcC99TOO1W7ZEJIYQQQghxGapNt+LPV9nYobXuaLNIhBBCCCGEqAVq06NvzzdAvBbVuYQQQgghhBBV7XwtGyFKqcfLW6i1frMa4hFCCCGEEOKyJr8gbmEEvLjAk6eEEEIIIYQQwprzVTZOa62n2iwSIYQQQgghagEZIG4hLRpCCCGEEEJUMV2LLrPPN0D8KptFIYQQQgghhLjslNuyobVOtmUgQgghhBBC1Aa1aYD4+Vo2hBBCCCGEEOKinW/MhhBCCCGEEKKKyQBxIYQQQgghRLWoTZUN6UYlhBBCCCGEqBY1smVDa82f37zM4V0rcXZxY+Q9M6jToHWZcj9/MpGY47sxGp0Jb9iWEXdMwejkTOLpoyz6fBKxJ/dy5XWPccWQe+2QReVs2ryFD+d8itlsYujgwdx6842llp88FcWst9/h8OEj3H3nHdx0w3VFy+4YMxZ3d3cMBgNGo5H336kZP/6uteaneTPYt20Vzq5u/G/8y9Rr2KpMuVV/fM2K378iMe4U0+eswsvHH4C46KN8/dHzRB3by4hbHmHANWNsnUKluTZvh8+1d4LBQNaG/8hc9lup5Z79r8a9U0/LhMGIU2gEcS/cj3J1xe+28Ri9/dBak7V+GVmr/rBDBpUXNKA3LWY8gzIYiZr/I8fe+bTUcidfH9q8Nw2PyHqYc/PY/fBzZOw/DECDB+6k7h03oLUmY+8hdj88GXNunj3SqDCf7j2o/+gElMFAwuJFxM7/qtRyo6cnjV6YgktoKMpoJPabBSQuXQJA6E03E3TNKJRSJCz6lbiF39kjhYvy8JgGdO/oR06umdc+OMKhY1llyrwzpSUe7kYA/Hyc2X8kg+ffOMTA3oHcOiocgOwcE29/epwjJ8qu70jaffIKIcP7kxefxMqO11gt0+qtyYQM7YcpO4cd9z5D2ra9AAQP7kOrNyejjAZOfbaQI298YsvQL1rQoN60eqMw7i9+4Ois0nE7+fnQ7qOX8WhYH3NuLjsfmEzG3kMARD54B/XG3ARKcerzhRx//0t7pHBR/jfUi7ZNXcjLh7m/pHEytqBMmXtGedO8gQvZuWYA5v6Szqm44nKR4U48d68/H/6QxpZ9uTaL/WJorfnpi1fZW3huHj1+OvUalT03r/zja1YsnU9i3Cle/mRl0bm5outf7sy69jz6tkZWNg7vWkly/An+75U/iT66g6Xzp3Dv5O/LlGvT/RquHfsGAD9/8gTbVv1Alytvw93Tl6G3Pcf+bf/YOvSLYjKZmP3hx7w6fSpBQYE8POEJrujRjQb16xeV8fb24sH7x7F23Xqrn/HGjJfx9fWxVchVYt/2VSScPsnkt5dy4vBOFn46jcdf/qZMuYbNO9KqUz9mTy1dmfDw8uWGu59h16Zltgr50iiFz/VjSP54BqbUJIIem07unq0UxEUXFclcvpjM5YsBcG3VCc++w9DZmSgnZ9IWLaAg+jjK1Y2gCS+Td3BXqXUdksFAy9cns/mG+8iJieOKf74j/o//yDxwpKhIown3kb5rP9vvfBTPpg1p+fpzbL7uXlzrhFB/3GjW9ByJOSeX9nNnEXb9cGK++cV++VyIwUCDxydycMIj5MXH0+rTz0lZvYqc48eLioRcfyPZx49x6OmJOPn50fbr70j660/c6tUn6JpR7LvvHswFBTSb9TYp69aSG3XKfvlUUPeOvkSEuXH7Izto2dSLCWMb8uDkPWXKPfrivqL3U55oyppNZwA4HZ/LYy/tJSPTRLcOvjwxzvr6jiRq3k8c/2A+HT57zery4KF98WwSyfKWg/Hr3p42s19iba+bwWCg9bsvsGHYGHKi4ui9/gfiFi8jY98Rq5/jMAwGWr/1Ahuvvoec6Dh6rVpI/JJlZOwvjrvJk/eTtnM/W299GM9mDS3lR4zBq1VT6o25iTV9b0bn5dP110+I/2MFWUdO2DGhimnbxIXQACOT3kumUYQTd47wZvrcM1bLfv93htWKhFJw00Avdh9x7BslZ+3dvoqE2BM8984SThzaycK503n85a/LlGvUvCOtO/Vj9tR7Lmp9YXtKqQDgOyASOA7crLU+c06ZesCXQBhgBuZord853+fWyG5UB7f/S7srLHf36jbuQE5WGukp8WXKNW3XD6UUSinCI9uRdiYWAE+fQMIbtsVorBl1rQMHDxEeXoc6dcJwdnamX98+rF2/oVQZfz8/mjdritHJaKcoq96uzf/Rte9IlFJENm1PdlY6qWcSypSr27AlgSERZeZ7+wZSv3FbDDVkOzvXb4IpKQ5TcjyYTGRvW4dr687llnfveAXZ29YCYE5PoSD6OAA6N4eCuGgMvv62CPuS+HZqS9axU2SfiELn53P656WEDLuyVBmv5o1JWmnZ3zMPHcO9XjguwYEAKCcjRjc3lNGIwd2N3NNlvwcciWfLVuRGRZEbE4MuKCD5n7/x7923dCGtMXp4AGBwd6cgLQ1tMuEWGUnmnj2Yc3PBZCJ921b8+/azQxaV16uLP3+tTARg36EMPD2NBPg5l1ve3c1Ax9Y+rC6sbOw5mEFGpgmAvYcyCAp0qf6gL1Hy6s3kJ6eWuzx05FVEz/8FgJQNO3D29cE1LBi/bu3IOnKC7GOWYyLmuyWEXuP4P3vl16UdWUdOkn288Fj+YSmhV5eO26tlY5L+WwdA5sFjuDeIwCUkEK/mjUjZtANzdg7aZCJ59SbCRg60RxqV1rGFK2t35gBwNLoADzeFr1flLq0GdnNny75c0jLN1RFildu9qcS5uVl7sjMrd26u6PqXO62r/lUFngH+1Vo3Bf4tnD5XAfCE1rol0AP4P6XUeZumamRlIz0lDp+AOkXTPv5hpKfElVveVJDPrvWLaNKmjy3Cq3KJSUkEBwUVTQcHBZGUlFTxD1Aw6fkXePCRCSz5vWZ0rQFITY7DPzCsaNovIJTU5PK3c01n9PXHlFK8Xc2pyRh9A6wXdnbBtUV7cnZuLPs5/kE4R0SSf8LB74QCbnVCyYk+XTSdExOHW53QUmXS9xwg9GrLhYdvp7a41QvHLTyU3NPxHJ/9BX13/EP/vcspSMsgaflam8ZfWS7BweTFF1eI8hLicQ4OLlUm7scfcGsQSftfFtNm3gJOvvMWaE320aN4d+iA0ccHg6srflf0xCUk9Nw/4ZCCAlyITyy+o5uYlEdQQPkVhj7dAti6O42sbFOZZcMHBLNxW0p1hGlTbuGhZEfFFk3nRMfiFhFqZX4cbhGOv53dwksfy9nRsbiGl447bdcBwkYNBsC3S1vc64fjFhFG+t5DBPTqinOAHwZ3N4KH9MOtbh1qAn9vA8mpxZWE5DQz/t7WL61uGODJlAcCuHWIF2fvC/p5G+jUwpX/NmfbItwqkXImHr8S52bfwFBSkyt+o+dS1xfVahQwr/D9PODacwtorU9rrbcWvk8H9gFla5Ul1IxbvuewVntT5/nZ998XTKV+sy7Ub9alGqOqRlYSPl++53r7jdcIDAzkTEoKk557gXr16tKuTZuqjLCaWMlbXc59HK3lZv1WhVvrTuQdO4jOziz9CS6u+N81gbRfv0Ln1oCTl5WU9Tn7+9F3PqXlK5O4YvmPZOw7SPqu/egCE06+PoQMH8DKToMpSE2n/edvUuemqzm9cLGNgr8I1vbfczaxb/fuZB06yIFH/g/XiLo0f+tddu+4nZwTxzk9/yuav/Ue5uwssg4fQpvK9g13RFYP2/PchhvQK5Cly8pefHRo7cPwK0N45IW9VRidfVj7LtNal7OP1IDH1lRgGx+dOYdWMyfTe/3PpO8+SNqOfeiCAjIPHOXIm5/QbfFcTBlZhcd4zdi3rbG2tX78N5PUDDNORrjram+G9fLgt5VZ3DbEi4X/ZNSITVzE2jVJZU7Nl7r+ZcJBt3mo1vo0WCoVSqmQ8xVWSkUCHYEN5ytXYyobm5YtYNuqhQCER7YlLbn4DkramVi8/Kz/f6xYNJvM9GRuvuM9m8RZHYKCgkhITCyaTkhMJCCwnDveVgQGWrqc+Pv50fOKHhw4cMhhKxur/vyGdct+AKB+4zacSSq+w5eSHIeP/3n3+xrNlJqM0S+waNrgG4Ap1XrfX/cOxV2oilcw4n/3BLK3riFn16bqDLXK5MTE4RZRfAfTLTyU3NjSF5mm9Ex2P/xc0XTfbX+RdTKKoCt7kX0iivwky/9R/OJ/8OvW0aErG3nx8biEFO/DLsEh5CeW7j4QNPxqTs+3DI7NjY4i93QM7g0iydy3l8Qlv5G4xPLQgIhxD5CX4LhdD64dEsqIqyytNvuPZBIS5AoHMgAICnQh8Uy+1fV8vJxo0cST52emlJrfqL47E+9vyDMzDpCWUXMvRM/Kjo7FvW4YZ49wt4gwcmPiMbg44163+K6vW0QoOTGOf9fX0gJTfCy7R4SV6dZYkJ7JzvufLZruv+9fso9HARA170ei5v0IQLMpE8iJjsVRDejqTt9ObgAciykgwNcAhUOnAnwMpKSX7Q6VmmGZV2CC1dtzGNrT0lUyMtyZB270BcDLQ9GuqStms2bbAccav7Hqz29Y969l+9Rv3IaUEufm1KTKnZv9AkIvaf3LRXX8grhSahwwrsSsOVrrOeeU+QfLeItzTa7k3/ICfgQe01qnna9sjalsdB0wmq4DRgNwaOdyNi1bQOtuI4g+ugM3d2+8rVQ2tq1cyNE9q7n9iS9QhhrZYwyA5s2aEh0dw+nYWIICA1mxchXPPDmxQutm5+SgzWY8PDzIzslh69btjL7tlmqO+OL1GXIbfYbcBsCerStY9ec3dOo5jBOHd+Lu4YWvf/AFPqHmyj91BGNQGMaAYEypybh3vIKU+bPLlFNu7rg0bknK1x+Umu97yzgK4qLJXLnUViFfsrRtu/FoVB/3+hHknI6nznXD2THuyVJlnHy8MWXnoPPzqXvHjSSv24wpPZOc6NP4dWmPwd0Nc3YOAX17kLZ9t50yqZjM/ftwrVcPlzp1yE9IIGDgII5MeaFUmby4OHy6dCVj5w6c/ANwq1+f3BjLQH8nP38KUs7gEhqKf7/+7HvgPnukUSG//BnHL39auj326OjHtUNDWbYmiZZNvcjMMpGcYr2y0e+KANZvTSE/v/hMHBLowtSJzZgx+whRp3NsEn91i/9tGQ0evJ2Y75bg1709BWnp5MYmkJeQjGeTSNwj65ITHUf4LSPYdscT9g73glK37MKzSQPcG0SQExNPnRuHs31M6fOUk683pizLsVxvzE0kr95EQbqlddYlOIC8hGTc6tYhbOQg1l55qz3SqJBlm7JZtsnSctyuqQtXdXVnw+5cGkU4kZWriyoWJfl6GYrmd2rhSnS8pcL89LvFXWfvGeXNjoN5DlfRgHPPzStZ9efXlnPzoZ24VfLc3KbLlZe0vihfYcVizgXKlDsgSikVp5SqU9iqUQeweqdDKeWMpaKxQGv904XiqjGVjZKatO3H4V0ref/ZwTi5uDFyzCtFy755exxX3z0Nb79Qlsx/Cb/AcD6fYfnSatFpEH2v+T8yUhP4dPqN5GZnoJSBDf98yfipS3B197JXSudlNBp5aPz9PPv8S5jNZoYMGkhkg/osXvo7AFcPH0Zy8hkeeuxxsrKyUAYDP/+6iE8+ep+01DSmvGz5/zGZTFzZrx9du5Q/6NiRtOrYl33bVzH90WG4uLpz2wPTipZ9/Op4bh03Bd+AEFb8Pp9lv31Oekoirz99Pa069OHW+6eSlpLIrGdvIadwO6/4fT6TZv6Km4djbmfMZtJ++oKAcc+AMpC9cTkFcdF4XGEZZJm17l8A3Np2JffALnRecR9454bN8ejSh/yYkwQ9btne6Uu/J3f/dpunURnaZGLf0y/TeeEclNFA9Nc/k3ngCHXvvhmAqC++x7NZI9p+MANtNpF54Ai7H7FcnKdu2UXsor+44r+F6AIT6bv2cWreQnumc2EmEyffnEnzN98Bg4HEJYvJOXaM4FGWR1Un/PozMV98RsPJz9N63nxQiqgPP6Ag1TLQuMnLM3Dy8UWbCjjx5kxM6en2zKbC1m9LoXsnP+a/257cPDOvfXC0aNmMZ5oz8+OjJBW2dAzoGcjXv8SUWv/OGyPw8XLisbGRAJhMmgcmOfbTqDp8NYvAft1wCfJnwLEVHJr6HsrZcso9Oedb4n9fQfCwfvTf/zem7Gx2jrXc8dcmE7sfnUq3JZ+ijEaivviRjL2H7ZlKhWiTiT2PT6PborlgNBD15Y9k7DtM/bGWm1snP/0Or+aNaf/pq2iTmYz9h9k5vrjFstPX7+Ic4IfOL2DPhKkUpJz3RqnD2Hkoj3ZNXXj14UDy8jWf/Voc92P/8+WLRemkZJgZd70P3h4GUHAqtoAvF9eMY9eaVh37sHfbSqY9OhwXFzf+N3560bKPZozntvvPnpsX8O+iz0hPSeK1p26gVYc+3PbAlPOuX5tox3z07SLgLuDVwn9/PbeAsvQBnQvs01pX6LcU1Ln9o6va/FUO2iutGvWpc9DeIdjc3vRG9g7B5jrMv8veIdjczi922DsEmwto6W3vEGzqqfDzPsHwsjTx5zvtHYLNKWeHvNCpVj88vdLeIdjczaP87B2CzQ3t4FIjdu6vVpYzKPMS3NG3EgN6rVBKBQLfA/WBk8BNWutkpVQ48KnWerhSqjewCtiF5dG3AM9qrcvtVlEjWzaEEEIIIYSoqRzxVrzWOgko86xtrXUMMLzw/WqsPxKiXFLZEEIIIYQQwoaqY4C4o6q5o6aFEEIIIYQQDk1aNoQQQgghhLAhR+xGVV2kZUMIIYQQQghRLaRlQwghhBBCCBuqTS0bUtkQQgghhBDChmSAeAlKqWClVBellJ8N4hFCCCGEEEJcJs5b2VBKjQX2AO8B+5VSI20SlRBCCCGEEJcprav+5agu1I3qMaC11jpBKdUIWIDlp8yFEEIIIYQQ4rwuVNnI01onAGitjyqlXG0QkxBCCCGEEJcts9neEdjOhSobdZVS75Y3rbV+pHrCEkIIIYQQ4vLkyN2eqtqFKhtPnjO9pboCEUIIIYQQQlxezlvZ0FrPs1UgQgghhBBC1Aa1qWWjIo++vUsptVUplVn42qyUutMWwQkhhBBCCCFqrvO2bBRWKh4DHge2AgroBLyhlEJr/WU5640DxgE8/Nz7DL9hbFXG7PDMymjvEGwuNbv2/T6kucBk7xBsriCtwN4h2JwyKnuHYFMFuXn2DsHmlHPt2sYAOr8W3VYtZHSufefm9Jzad26uKWrTj/pdaC98ELhOa328xLxlSqkbgG8Bq5UNrfUcYA7AH9vzatF/pxBCCCGEEOKsC1U2fM6paACgtT6ulPKpnpCEEEIIIYS4fOlqGbThmK20F6psZF/kMiGEEEIIIYQVtWmA+IUqGy2VUjutzFdAo2qIRwghhBBCCHGZuFBloz0QCpw6Z34DIKZaIhJCCCGEEOIyVpt+QfxCj759C0jTWp8o+QKyCpcJIYQQQgghhFUXatmI1FqX6Ualtd6slIqsnpCEEEIIIYS4fMmYjWJu51nmXpWBCCGEEEIIURvUpt/ZuFA3qk1KqfvOnamUuhfYUj0hCSGEEEIIIS4HF2rZeAz4WSk1muLKRRfABbiuGuMSQgghhBDisiTdqAppreOAnkqpK4E2hbOXaK2XVXtkQgghhBBCiBrtQi0bAGit/wP+q+ZYhBBCCCGEuOzpahm0UTN/QVwIIYQQQghRhWSAuBBCCCGEEEJcohrZsqG15qcvXmXvtlU4u7oxevx06jVqVabcyj++ZsXS+STGneLlT1bi5eNfqfUdyebNm/nw4zmYzWaGDhnMLTffXGr5qVOnmPXW2xw5fJi77rqTG2+4AYC8vDwmPvU0+fn5mEwm+vTuxR23326PFCpNa83vX7/MoZ0rcXZx49p7ZxAe2bpMuQ3/zGf931+SHH+Sp95dh6e3ZTvnZKXz45wnSU0+jdlkotfQMXTsc4Ot06gU1xbt8b3+bpTBQOb6ZWT882up5V4DrsG9c28AlNGIU2gEpyePReflEfzISygnZzAYyN6xgfTfF9ojhUoLHtyHVm9ORhkNnPpsIUfe+KTUcic/H9p/8goejetjzsllx33PkrHnEACRD99J/XtuAqU4+dlCjr87zx4pVIpPtx7Uf/gxMBhJXLKI2K+/KrXc6OlJw+dewiUkFGU0Evvd1yT9vgSAkBtuJvjqkaAUCYsXEf/Dd3bI4OI8el8jenQOIDfXzCvvHODg0cwyZWa/0g4PdyMA/n7O7DuYzrMz9hUtb9HEi49e78BLM/ezfG2izWK/GEGDetPqjcL9+osfODqr7H7d7qOX8WhYH3NuLjsfmEzG3sL9+sE7qDfGsl+f+nwhx9//0h4pVFq7T14hZHh/8uKTWNnxGqtlWr01mZCh/TBl57Dj3mdI27YXuPD3gCO7dZAHbRu7kFeg+fy3DE7GmcqUGXO1J83qO5Oda7md/flvGZyKN9G9tQtDr7D8kkBOnmbBH5lExZdd35ForVmy4BUO7rCcm2+47xWr5+b1fy9g7V+Wc/Ok2WuLzs2rls5lx7rFAJhNBSTEHGXS7DV4ePnZMg27kwHiDm7v9lUkxJ7guXeWcOLQThbOnc7jL39dplyj5h1p3akfs6fec1HrOwqTycT7H3zIKy9PJygoiEcem0CPHj1oUL9+URlvb2/GP3A/69atK7Wus7Mzr814BXd3dwoKCnhi4pN06dKFli1a2DqNSju0cyVJcSd45NU/iTq6g8VfTWHc89+XKVe/aSeadejPF6/eWWr+xmULCA5vwujHPiIzLZn3nh1G2yuuwcnJxVYpVI5S+N10D4kfvIwpJYmQJ2aQs2szBXHRRUUylv1GxrLfAHBr3Qmv/iPQWZaLtsTZU9F5uWAwEvzoFHL2bif/xCG7pFJhBgOt332BDcPGkBMVR+/1PxC3eBkZ+44UFWnyzAOk7djHlpsewrN5I9q8+wIbhtyNV+um1L/nJlb3vAmdl0+3JZ8Sv3Q5WYdP2DGhCzAYqP/YExx84lHyE+Jp+fFnpKxZRc6J40VFgq+7kezjxzg86UmcfP1oM/87kv/+E9d69Qm+eiT7HrgXc0EBzV5/i9R1a8iNjrJfPhXUo7M/deu4c9sDm2nVzJsnxjfh/id3lCn30LPFvyE77emWrN6YVDRtMMADdzVk47YzNon5khgMtH7rBTZefQ850XH0WrWQ+CXLyNhfYr9+8n7Sdu5n660P49msoaX8iDF4tWpKvTE3sabvzei8fLr++gnxf6wg64gD79eFoub9xPEP5tPhs9esLg8e2hfPJpEsbzkYv+7taTP7Jdb2urlC3wOOqk1jZ0ICjEz+KIVG4U6MHurJjHlpVssuXJbF1v15peYlpph5Y34aWTmaNo2cuWNY+es7ioM7V5IUe4IJr/9B1JEdLJo3lQdeLHvjo36zjjTv0J+555yb+wy/lz7D7wVg/7b/WPPnvFpX0ahtamQ3qt2b/qNr35EopYhs1p7szHRSzySUKVe3YUsCQyIuen1HceDgQeqEh1OnTh2cnZ3p17cv69atL1XGz8+P5s2aYTSWrj8qpXB3t9w1KSgooMBkctDhQ2Xt3/YvHXqOQilFvcYdyMlKIz0lvky5Og1a4R9U18onKPJyMtFak5ebhbunLwaD49avXRo0oSAhDlNSPJhMZG1di1vbruWWd+/ci6yta4qmdV4uYGnxwOgEOP5tE79u7cg6coLsY1Ho/HxivltC6DVXlSrj3bIxif9Z9vfMA0dxbxCBS0ggXi0ac2bjDszZOWiTiaSVmwgbNcgeaVSYZ8tW5EZHkXc6Bl1QQPKyf/Dr3bd0Ia0xengAYHB3pyAtDW0y4d4gkoy9ezDn5oLJRPqObfj37WeHLCqvd7dA/vjPcuzuPZiOl6cTgf7O5ZZ3dzfSuZ0vq9YXVzZuGBHOinWJpKTmV3u8l8qvSzuyjpwk+7hlvz79w1JCry69X3u1bEzSf5abQ5kHjxXv180bkbKpeL9OXr2JsJED7ZFGpSWv3kx+cmq5y0NHXkX0/F8ASNmwA2dfH1zDgiv0PeCoOjRzYf0uy3fv0ZgCPNwM+HpW/Cx7JLqArBxdtL6/j7Fa4qxK+7Yuo0OvwnNzk/LPzeENWuEfXPYarKSd65fQrsfw6grVoZnNuspfjqpGVjZSzsTjFxhWNO0bGEpqctkdvbrWt7WkpCSCg4KKpoOCgkhKSjrPGqWZTCYefOghbv3faDp17ECLGtCqAZCeEodPQJ2iaR//MNLOxFV4/e5XjSbh9BFmTujLB8+PZNj/nsVgcNxd3uAbgCmleLuaUpIw+vpbLaucXXBr0YHsHRtKzFQEP/kaYS9/Qu6BneSfOFzdIV8yt/BQsqNii6ZzouNwiwgtVSZt537CrrVUIny7tsW9QThudcPI2HOQgN5dcA7ww+DuRsiwvrjXC8ORuQQFkxdf/F2TlxCPS1BwqTLxP/2AW4NI2v30G60/n8+p994Crck+dgTv9h0w+vhgcHXFt8cVOIeEnvsnHFJwoAvxiblF0wmJeQQFupZbvm+PQLbsTCUr29KdJCjAhb49gvj1j9PVHmtVcAsPJSe6ONbs6Fhcw8/Zr3cdIGzUYAB8u7TFvX44bhFhpO89RECvrkX7dfCQfrjVrcPloOzxHotbRGiFvgcclb+XgeQ0c9H0mXQzft7WzzPX9fPgxbG+3DzQAycrdYre7V3ZfSSv7AIHk34mDt8S11A+AWGknan8NVRebjaHdq2mdZfBVRmecECOe5v3fKx0dFOVuV1/qevbmL7EeI1GIx/Mnk1GRgZTp0/n+PHjREZGVl2A1cRaf0ZVicQP715NWP2W3P3UPJLjT/LlzHuo36wLbu5eVRhlFapEbm5tOpN77EBRFyoAtCbhjadR7h4E3jsRpzr1KDh9qhoCrULWcj5nwx95fQ6t3ppM782/kL77IGnb96ELCsjYf5SjMz+l+x+fUZCRRdrOA5gLHLuvs7V89TktUL7dupN96BAHH3sI14i6NJv1Dnvu2U7OiRPEfj2fZrPexZydRdbhw+Do+Raydtyer7/ywD7BLP67+OLzkbGN+HDeMczm8tdxKNYO5XMSPjpzDq1mTqb3+p8t+/UOy36deeAoR978hG6L52LKyCJ91350QYFt4q5m1vcDXaHvAYdlLXQrxX76L4vUTI2TEe4Y5snQK9xZvDq7aHnzBk70bu/Ka185dhcqKPudZVH5i6gD2/+jftOOtbYLVU3ZxatCjalsrPrzG9b9+yMA9Ru3ISWp+ESUmhSHj39IhT/LLyD0kta3taCgIBISiwdDJiYmEhAQWOnP8fLyol3bdmzessVhKxsb/l3A1hWWgc3hDduSllx8dzDtTCzefhXfTttW/0yfEfehlCIwtAH+QXVJPH2Uuo3aVXncVcGckoTRr3i7Gv0CMaVa75/u3qkn2SW6UJWks7PIPbwXtxbtyXDwykZOdCzudYvvkLlFhJITU/oOWUF6JjvHPls0feWhf8k+ZhmncOrzHzj1+Q8ANJ82gZzoird82UNeQjwuIcX7sEtwCPmJpQc6Bw4bUTRoPDc6itzTMbjXjyRz/14Sl/5G4lLLmJ2I+x4gL8FxW2SvG16HawZZtu3+w+mEBBW3ZAQHuZCUnGt1PR9vJ1o29WbyjL1F85o38ealiZYWWV8fZ3p09sdk0qzaUPEWXluy3Jkvbo1wjwgj97SV/fr+4v26/75/yT5u2a+j5v1I1DzL+a7ZlAnkRMdyOcguPN7Pfqu5RYSRGxOPwcX5gt8DjqR/Z1f6dnAD4FhMAQE+xS0Z/t4GUtPL1opTMy1XlgUmWLMzlyHd3YuWRQQbuXO4F+9+l0ZmtmNega7/ZwGbV1i+ayMatiG1xDVUWnIsPv7B5a1arp3rl9Kux4gqi7GmqU2VDcftU3KOPkNu46nXf+Cp13+gbdcBbFq5CK01xw/uwM3DC99K7Ohtulx5SevbWvNmzYiJiSY2Npb8/HxWrFxJjx7dK7RuSmoqGRkZAOTm5rJt+3bq1a1XneFeku5XjWb81F8YP/UXWna6iu1rf0Vrzakj23Fz965UZcM3sA5H91r6RGekJpIYewz/YMfNPe/kEZyCwzAGBIPRiEennuTs3lymnHJzx7VxK3J2FS8zeHqj3C39/HF2xrVZGwriY2wV+kVL3bQLzyaRuEfWRTk7E37LCOIWLytVxsnXG+Vs6d9f796bSF69mYJ0S4uOS3AAAG716hB27WCiv11s2wQqKXP/Ptzq1sMlrA7KyYmAAQNJWbOqVJm8+Dh8OnUBwMnfH7d6Dcg9bXlIgJOfpVudS0gofn36k/zP37ZNoBJ+XnqaeyZs454J21i1PomhV1qO3VbNvMnINJF0xvrYiyt7BbF2czJ5+cVn4lvGbeLmwteKtYm8+fERh61oAKRu2YVnkwa4N4hAOTtT58bhxC05z3495iaSV28qu1/XrUPYyEHEfL/EtglUk/jflhFx+7UA+HVvT0FaOrmxCRX6HnAky7fkMnVuKlPnprL9YB492loq0o3CncjO1UUVi5JKjuPo2MyF6ARLq2SAj4EHb/Dms0UZxCU7btNdj4GjeWjazzw07WdadbqK7WsKz82Ht+NayXMzWJ4WefzAZlp2GlBNEQtHUmNaNkpq1bEPe7etZNqjw3FxceN/46cXLftoxnhuu38KvgEhrPh9Af8u+oz0lCRee+oGWnXow20PTDnv+o7IaDTy4PjxTH7uecxmM4MHDyKyQQOWLFkKwIgRw0lOTuaRRx8jKysLZTDwyy+/8vHHH5GcnMysWW9iMpvRWtO3T2+6d+9m54wqpmm7fhzcuZJ3nh5c+OjbV4qWzX9zHCPHTMPHP5T1f3/Jmt/nkpGayIcvjKRp236Mumc6/a4Zzy9zJ/H+c5ZHMA66aWLRo/ccktlMyo+fETT+WTAYyFy/nILYKDx6WQaHZq35BwD3dt3IObCzaEA4gMHXH//RD6IMBlAGsretI2fPVrukURnaZGL3o1PptuRTlNFI1Bc/krH3MPXH3QrAyTnf4tWyMR0+ew1tMpOx7zA7xk0uWr/z9+/hHOCHLihg9yNTKEhx8C4IJhMn355Fs5lvg8FA0tLF5Bw/RvDI6wBIWPQzp+d9TuSk52j1+XwUEPXx+xSkWgbdNp72Ck4+vuiCAk6+PRNTRrr9cqmEdVvO0KNLAN9+1IWcXDMz3jtYtOz151vz2vuHSEq29FW/qncw8390/CdsnY82mdjz+DS6LZoLRgNRX/5Ixr7D1B97CwAnP/0Or+aNaf/pq5b9ev9hdo5/rmj9Tl+/a9mv8wvYM2Gq4+/XhTp8NYvAft1wCfJnwLEVHJr6HsrZcplxcs63xP++guBh/ei//29M2dlFLZblfQ/UBLuO5NO2iQsvj/cjL1/zxeKMomWP3OzNvKUZpGZoxo7yxstDoRScijMx/3dLuat7u+Pprhg91BMAkxle/rz8QfaOoFl7y7n5zSeH4OLqxvVji8/NX84ax7X3TMfHP4R1f33FqqWWc/Ps50bRrF1frrvXcr21d8s/NGnTExdXD3ulYXfmWtS0oayNB6hKf2zPqz3/m4Wae5+0dwg2tyGusb1DsLk+391q7xBsbvsH2+0dgs2F9gywdwg2NcHvdXuHYHOT/r7P3iHYnM6vdadmfpmy1t4h2NzgAQ58g62a3NTD4MCjcItN+6agyg/C529zcsjca2TLhhBCCCGEEDWVdtxec1VOKhtCCCGEEELYUHX3LHIkNWaAuBBCCCGEEKJmkcqGEEIIIYQQNmQ2V/3rUimlApRSfyulDhX+W+6gH6WUUSm1TSl1wcdASmVDCCGEEEII8Qzwr9a6KfBv4XR5HgX2VeRDpbIhhBBCCCGEDWmtq/xVBUYB8wrfzwOutVZIKVUXGAF8WpEPlQHiQgghhBBC2JC5GsaHK6XGAeNKzJqjtZ5TiY8I1VqfBtBan1ZKlfdrjW8DTwHeFflQqWwIIYQQQghRwxVWLM5buVBK/QOEWVk02co8a+tfDcRrrbcopfpXZB2pbAghhBBCCGFDujqaNiryd7UeWN4ypVScUqpOYatGHSDeSrFewEil1HDADfBRSs3XWt9e3ufKmA0hhBBCCCHEIuCuwvd3Ab+eW0BrPUlrXVdrHQncCiw7X0UDKlHZUEp5KaU8Kx6vEEIIIYQQ4lxaV/2rCrwKDFJKHQIGFU6jlApXSi292A+9YDcqpdSDWB595WmZVOnAa1rrDy72jwohhBBCCCEch9Y6CbjKyvwYYLiV+cuB5Rf63PNWNpRSzwE9gf5a66OF8xoB7yilArTW0ysSvBBCCCGEEMLCbKcxG/ZwoZaNO4D2WuucszO01keVUjcDOwCpbAghhBBCCFEJVfS7GDXCBcdslKxolJiXDVTBD6MLIYQQQgghLlcXqmxEKaXK9N0qnHe6ekISQgghhBDi8qXNVf9yVBfqRvUI8KtSajWwBdBAVyzP2B1V3kolf8Hw0edmM+LGsVUTbQ2Rbvaxdwg21ztoj71DsLkFfb+xdwg2dzQ81d4h2NzR3cftHYJNffSitd96urzNWrDS3iHYnNHZaO8QbO7aF3vaOwSb63fVTHuHYAfX2DsAcY4LVTZygbuBZkBrQAErgblAme5VZ5X8BcO/d+TWnk5pQgghhBBCXIC5Fo3ZuFBl423gWa31ZyVnKqW6FC6T6qMQQgghhBCVIAPEi0VqrXeeO1NrvRmIrJaIhBBCCCGEEJeFC7VsuJ1nmXtVBiKEEEIIIURtUJt+Z+NCLRublFL3nTtTKXUvlgHjQgghhBBCCGHVhVo2HgN+VkqNprhy0QVwAa6rxriEEEIIIYS4LNWiIRvnr2xoreOAnkqpK4E2hbOXaK2XVXtkQgghhBBCXIZ0LepGdaGWDQC01v8B/1VzLEIIIYQQQojLSIUqG0IIIYQQQoiqUZt+Z+NCA8SFEEIIIYQQ4qJIy4YQQgghhBA2VJvGbEjLhhBCCCGEEKJaSMuGEEIIIYQQNlSbWjaksiGEEEIIIYQN1aK6Rs2sbGit+eHz19izbRUurm7c8eA06jVqVaZcYnwUn7/9FFkZadRr2JI7H34FJydnsjLSmP/hCyTGncLZ2ZXR46cQXr+pHTKpuG1bNvD5nHcwm81cNfhqrrvp9lLLtdZ8Pucdtm5ej6urK//32LM0atK8aLnJZOKZCfcREBjEpBdft3X4F2Xjlm28/8lnmM1mhg+6ittuur7U8pOnonj9nfc5fOQo99zxP26+fhQAp6Kimfb6m0XlTsfGcffoW7lh1NU2jf9iaK1Zv/gVTh1YiZOLG31veIWgiNZlyq36cTKJ0XvQaHwDI+l74ys4u3pyYu+/bPnnXZQyYDAY6T5iEmGRne2QSeXcfJU7bRo7k5evmbc0i1NxpjJl7hruQdN6TmTnWr6h5y3NIireRGiAgbuGe1Iv1MiiVdn8vTHX1uFX2oN3RNC1vS+5uWZmzjnB4RPZVsvdfWMd+nbzw2yGxcsS+eWvBLw8jDxxX33qhLiSl2/mzU9Pcjwqx8YZVM7WzRv4bM5szGYTAweP4PqbR5darrVm7sfvFX5/ufHQhGdo3KQZAJkZ6bz/7hucOnEMUDz02NM0b1n2mHBE/xvqRdumLuTlw9xf0jgZW1CmzD2jvGnewIXsXDMAc39J51RccbnIcCeeu9efD39IY8s+x9+3bx3kQdvGLuQVaD7/LYOTVo7lMVd70qy+c9Gx/PlvGZyKN9G9tQtDr3AHICdPs+CPTKLiy67vKNp98gohw/uTF5/Eyo7XWC3T6q3JhAzthyk7hx33PkPatr0ABA/uQ6s3J6OMBk59tpAjb3xiy9Avydqd+5k5/1dMZjPX9uvOmGsGlFq+fMtuPvzpTwxKYTQYeGL0KDo2b0hsUgovzPmGpJR0DAbFdf178L8hfeyUhbClGlnZ2LttNQmxJ3jx3cUcP7STbz+dzpOvfF2m3K/z3+bKEXfQpdcwvpkzjXXLfqLP4Fv48+dPqBvZnHFPvk1s9DG+n/syj7zwqR0yqRiTycTcD9/k+elvERAYzKQJ99Gley/q1W9YVGbb5vWcjonivTnfcOjAXj75YBYz3pxTtHzpooVE1GtAdlamPVKoNJPJxLsffcLr014gODCQBx9/miu6dyWyfr2iMt7e3jw07l7WrN9Qat16dSOY8+6sos+55e5x9L6im03jv1hRB1eSlnSCm574g4RTO1j761RGPvhdmXLdR0zCxc0LgPVLXmXv+q9p3+8+whv3oH7LASilSD59gGXfTODGx5faOo1KadPIiZAAIy/MSaNhuJH/Dfbgta/SrZb9aXk2Ww/kl5qXlaP57p8sOjR1tkW4l6xrex8iQt0YM3EvLRp78MiYejzy0sEy5Qb3CSA40IV7n96H1uDnY/m6vm1kKEdOZjPlnWPUq+PKQ3fV4+lXD9s6jQozmUx88uE7vDh9JoFBwTw14QG69uhFvfqRRWW2bt7A6Zgo3v9kAQcP7GXO+2/x2lsfAjB3zmw6du7GU89OJT8/n7xcx65YndW2iQuhAUYmvZdMowgn7hzhzfS5Z6yW/f7vDKsVCaXgpoFe7D6SV93hVok2jZ0JCTAy+aMUGoU7MXqoJzPmpVktu3BZFlv3l84rMcXMG/PTyMrRtGnkzB3Dyl/fEUTN+4njH8ynw2evWV0ePLQvnk0iWd5yMH7d29Nm9kus7XUzGAy0fvcFNgwbQ05UHL3X/0Dc4mVk7Dti4wwqz2Q28+qXP/PBU+MIDfDljhffoV+nVjSKCCsq0611U/p1ao1SikMnY3j6/a/46bWnMRoNTLjtGlpG1iUzO4fbX3ibHm2allq3NqlN3ahq5ADxnZv/o1vfa1BK0bBZe7Iz00k9k1CqjNaag3s20rHHIAC69x/Jjk2W3yWMjTpK87bdAQiLaEhyQgxpKUm2TaISDh/cR1idCELDwnF2dqZX36vYvH51qTKbNqym34ChKKVo1qI1mZkZnElOBCApMZ6tm9Zx1WDHv7N/1v5Dh4moE0Z4WBjOzs5c2bc3azdsKlXG38+XFs2a4ORUfp15245dhNcJJTQkpLpDrhIn9i6jScdRKKUIqd+BvJw0stLiy5Q7W9HQWmPKL774cnb1RCkFQH5+luVqxcG1a+rC+t2WC61jMSbcXRU+nhWPOz1LcyLWhMlcXRFWrZ6dfPl7dTIA+49k4elhJMC37D589VVBLPj5NGcfxZ6SZrnbXT/CjW17LJWxU6dzCQ1yKaqIOKLDB/dTJzyCsDqW76/efQewcf2aUmU2rl9D/wFDUErRvPD7Kzk5iaysTPbu3sHAwSMAcHZ2xtPL2x5pVFrHFq6s3Wk5No9GF+DhpvD1qtwpd2A3d7bsyyUts2bs3B2aubB+l+VYPhpTgIebAd9KHMtHogvIytFF6/v7GKslzqqSvHoz+cmp5S4PHXkV0fN/ASBlww6cfX1wDQvGr1s7so6cIPtYFDo/n5jvlhB6zVU2ivrS7DlyknohgdQNCcTZyYnBPTqwfOueUmU83FyLzkPZuXkoLO+D/XxoGVkXAE93NxqGhxJ/xnErk6Lq1MjKRkpyPP5BxTVhv8BQUpJLX5Blpqfg7uGN0Wg5CfsHhJKaHAdARINmbN/wLwDHD+8iOeE0KYXLHFFyUgKBwcUXywFBwSQlJZYtE1RcJjAwmOTCMp/PeZfb73kQg6o5mzsxKZngoKCi6eDAABKTKl8h/G/VGgb07V2VoVWrrLQ4PH2L920PnzAyrVQ2AFb+8Cxfv9KH1IRjtL6iuFvd8T1/88Obw/lr3nj63DC92mO+VH5eijNpxRdTKelm/Lyt76sj+7jz3BhvbhrgjpNjX4eUK9DfmYTk4ju6icn5BAaUbZUJD3GlXw9/Zk9pzssTGxMe6grA0ZPZ9O7iB0DzRh6EBrkQbGV9R5GUlEBgUHDRdGBQMMlJpW8OJSclEBRctkzc6Rh8fP2Y/darPPHwWN5/53Vycqx3OXM0/t4GklOL9+vkNDP+5ezXNwzwZMoDAdw6xKtov/bzNtCphSv/ba4Z+QL4exlILnEsnznPsXxdPw9eHOvLzQM9rB7Lvdu71pgWnfK4hYeSHRVbNJ0THYtbRKiV+XG4RYTaI8RKiz+TSmigX9F0aIAfCWfKVriWbd7F9U+/xqNvzuXFsTeXWR6TkMz+E9G0aVy/OsN1aFrrKn85qppz9VmSlf9Qdc4dXI21/3RLmUHX3ktWZhoznryJFb9/Q92GLTAYataVy7k3rK3uZEqxZeMafP38aVxi/EaNUIFtfCH5+fms3bCJvr16VlVU1c7aflte3n1vfIXbJq3AN6QRR3f9XjQ/svUgbnx8KQNvf4+tf79bbbFWFav5Wdmdf16RzUufpvHql+l4uCkGd3er/uCqgdXNaSVfZ2dFXr7moRcPsHR5Ik/cZzkpf/dbHF6eRj6c3pxRg4I5fCLLsVt1rJ7/zvm+tvb1hcJkNnH08EGGDB/FrPc+xc3NnZ8Wlu0yW1NY+6/48d9Mnn0/mWmfJOPpphjWywOA24Z4sfCfDKv/Nw6rYocyP/2XxfMfp/Dy56l4uqmicRpnNW/gRO/2rvz4X1b1xGkj1r7btNbWvwRqyIa2fmVVNp8BXdry02tPM+vRu/nwxz9LLcvKyeXJ9+YxcfQovNxr5vd4VTCbdZW/HJXjtr2fY8Uf37L23x8BaNC4NWcSi+8KpCTF4esfXKq8l7c/2VnpmEwFGI1OnEmOwzfAcuff3cOLOx6cBlgO/BcfGkZgSISNMqm8gMBgkhKK724nJyYQEBBUqkxgUAhJicVlkpISCAgIZP3q/9i8YQ3bNq8nLy+P7OxM3p05lUcmvmCz+C9GUFAgCYnFrTcJSckEBgRU6jM2btlG08aNCPD3q+LoqtbedQs4sPkHAIIi2pCZWrxvZ6XF4uEdXN6qGAxGGrUdxq5Vn9Gsc+kB9HUadmVl8ilyMs/g5ulfPcFfpH4dXend3gWAE7Em/H0MEG0ZCOrnbSAlo+zVc1qm5Yu0wATrduUxsJur7QK+RNcMDGJ4/0AADhzNIjjABbCMnwoKcCbpTH6ZdRKT81m9KQWANZtTmXhfAwCycszM+uRkUbkv32xFbLzjDhwODAomKbG4JSMpMYGAwHO/v4JJTChdxj8wCFW4rFkLywNArujVz6ErGwO6utO3k+Xi6VhMAQG+BjhlWRbgYyAlvex+nVq4rxeYYPX2HIb2tFQ2IsOdeeBGXwC8PBTtmrpiNmu2HXCsu/39O7vSt0OJnH2K72H6extItZZziWN5zc5chnQvrmxEBBu5c7gX736XRma24148VUR2dCzudcM4O1LHLSKM3Jh4DC7OuNctbsF2iwglJ8Z6C7ajCfX3JS4ppWg6LjmFIH+fcst3atGYqPhvOZOeib+3J/kFJp58dx7DrujEgK5tbRCxcAQ1prLRb+it9Bt6KwC7t65k5R/f0LnXMI4f2om7h3eZyoZSimatu7Jt/d906TWMDcsX0a5LfwCyMtNwcXXHycmZtf/+SJOWnXD38LJ1ShXWpFkLTsdEERcbQ0BgMGtW/sujT75YqkyX7r34Y/FP9Op7FYcO7MXDwwv/gCBG3/0Ao+9+AIA9O7ex6OdvHL6iAdCiaROiY05zOjaOoMAA/lu5mskTH6vUZyxbuZoB/Ry/C1WrK0bT6grL03lO7l/OvvVf06jdcBJO7cDZzRsPn9LjTbTWpCefxCewAVprTu5fjm9wIwDSkk7gHVAfpRSJ0Xswm/Jx9fCzdUoXtGJbLiu2WS6Q2zRyon9nNzbvy6dhuJGcXF1UsSjJx1MVzW/fzJmYREe+nV/ab/8k8ts/lspzt/Y+jBoUzPL1Z2jR2IPMLBPJqWWfUrRmSyodWnnx58pk2rXwIirW0v/f08NIbq6ZApNmWP9Adh3IJCvHcf8vmjRrzunoKOJiTxMQGMTqlcuY8ORzpcp07d6T3xf/TO9+Azh4YC8enp4EBFgqZ0HBIURHnSSibn127thCvfoN7JFGhSzblM2yTZZuT+2aunBVV3c27M6lUYQTWbm6qGJRkq+XoWh+pxauRMdb9oWn3y3uNnrPKG92HMxzuIoGwPItuSzfYjmW2zZ25soubmzcm0ejcMuT41KtHMu+nqpofsdmLkQnWG40BPgYePAGbz5blEFcsuPu0xUV/9syGjx4OzHfLcGve3sK0tLJjU0gLyEZzyaRuEfWJSc6jvBbRrDtjifsHW6FtGpUj1NxiUQnJBHi78tf67fz8vjST5c7FZdI3ZBAlFLsOx5FvsmEn5cHWmumzf2ehuGh3D6sn50ycByO3O2pqtWYykZJrTv2Yc/WVUx5ZATOLm7cXthKAfDBjAf53/0v4RcQwqjRE/j87adY/O1s6jVswRUDLHd+Y6OP8dXsyRgMBsLqNmb0A1PslUqFGI1O3PvABF5+4QnMZjNXDhpBvQYN+WvpLwAMHn4tnbpcwbbN63n4vltxcXXj/x6bZN+gL5HRaOThB8by9IvTMJvNDBs4gMgG9fntd0tz7DXDhpB85gzjJzxFVlY2yqD4cdFiPvvgHTw9PMjJyWXL9h1M+L/77ZxJ5dRr3o+oAytZOGsITs5u9LnhlaJlf34xjt7XT8fDK4gVCyeRn5uB1prAOi3oOcpS+Ty2+y8Ob/sVg9EZo5MrV976ZqW7n9na7qMFtGlsYto4H/IKYN7S4iemPXSjF1/9kUlqhuaeazzx9rDcNY2KL+DrPy1dLHw8FZPu8sHNRaG1ZkAXN6Z8mkqO412XAbBxRxrdOvjwxcxW5OaZmfnJiaJl0yc24s1PT5KcUsB3i+N4ZnwDrh8aQnaOmbfmWm6R1w935an7G2A2w4noHN789GR5f8ohGI1OjB3/KFOff9Ly6O5Bw6jfoCF/Lv0VgCHDR9G5aw+2bt7Ag2NH4+rqykMTni5af+z9j/D2G9MpKCggNKwODz32jL1SqZSdh/Jo19SFVx8OJC9f89mvxQNhH/ufL18sSiclw8y4630s+7WCU7EFfLnY+pPYaoJdR/Jp28SFl8f7kZev+WJxRtGyR272Zt7SDFIzNGNHeePloVAKTsWZmP+7pdzVvd3xdFeMHuoJgMkML39e/gBse+vw1SwC+3XDJcifAcdWcGjqeyhny2XVyTnfEv/7CoKH9aP//r8xZWezc+yzAGiTid2PTqXbkk9RRiNRX/xIxl7HfaJcSU5GI0/deR0Pvf4JJq0Z1bcrjeuG8cOytQDcOKAn/27ayZI1W3AyGnF1dmbGg3eglGLbgWMsWbOFJvXqcNtzlsfT/99Nw+jdvqU9UxI2oKq7ZvX3jtzaU3UrFOrhuF+O1SVA14wm4Kr09a6yv+1yuTt6uPbt20d3H7d3CDb11ou17zGUsxbUrDF7VcHoXPtyvvbFmjN+r6r0Wz3T3iHYnFf3axz7Dluhe6clVPn18dzngx0y9xrZsiGEEEIIIURNJb+zIYQQQgghhBCXSFo2hBBCCCGEsCFzLRogLi0bQgghhBBCiGohLRtCCCGEEELYkIzZEEIIIYQQQohLdNEtG0opJ6112V+iEkIIIYQQQpSrNv2o33lbNpRSvymlyvxcq1JqILC9uoISQgghhBDicmU26yp/OaoLdaP6FvhPKTVZKeWslApXSn0PTAfuqv7whBBCCCGEEDXVeSsbWusFQEegPrAPWAf8A1yhtd5S/eEJIYQQQghxedFmXeUvR1WRAeKtgG7ARiAXCEWeYiWEEEIIIYS4gAuN2fgUeB94UGv9PyytHL7ADqXUYBvEJ4QQQgghxGVFa13lL0d1oZaNPUBXrfU6AK11ptZ6InAL8Hx1ByeEEEIIIcTlRpvNVf66VEqpAKXU30qpQ4X/+pdTzk8p9YNSar9Sap9S6orzfe6Fxmy8BQQqpaYUfuhCpdQUIF5r3efi0xFCCCGEEEI4kGeAf7XWTYF/C6eteQf4Q2vdAmiPZVx3uS7UjaoXsKlw8ktgfuH7DYXLhBBCCCGEEJXgoI++HQXMK3w/D7j23AJKKR+gLzAXQGudp7VOOd+HXmig9yzgWq31thLzflVK/Qx8DHS3tpJSahwwDqDzwJdp1O5/F/gzl5eP7zxh7xBsLs0zzN4h2FzPltn2DsHm6gRbbVG9rHXvVrtyzjadsXcINnfzKE97h2Bz6Tm17zkv/a6aae8QbG5F74n2DsHmRuRfY+8QarJQrfVpAK31aaVUiJUyjYAE4HOlVHtgC/Co1jqzvA+90JgNn3MqGhQGsB3wLm8lrfUcrXUXrXWX2lbREEIIIYQQ4nyqY4C4UmqcUmpzide4c/+uUuofpdRuK69RFQzdCegEfKi17ghkUn53q6IVzkcppfy11mfOmRlAxR6bK4QQQgghhCihOn4XQ2s9B5hzgTIDy1umlIpTStUpbNWoA8RbKRYFRGmtNxRO/8AFKhsXqjC8BfyllOqnlPIufPUHfi9cJoQQQgghhKj5FgF3Fb6/C/j13AJa61jglFKqeeGsq4C95/vQ87ZsaK3nKKVigGlA68LZe4DpWuvfKh67EEIIIYQQAqqnZaMKvAp8r5S6FzgJ3ASglAoHPtVaDy8s9zCwQCnlAhwFxpzvQy84QkxrvRhYfAmBCyGEEEIIIRyY1joJS0vFufNjgOElprcDXSr6ueetbCilXjh/THpaRf+QEEIIIYQQAsz60n+Er6a4UMuGtcdYeQL3AoFYulcJIYQQQgghRBkXGrMx6+x7pZQ38CiWflnfYvkNDiGEEEIIIUQlOOiYjWpxwTEbhY+5fRwYjeXXBDud+yhcIYQQQgghRMVIZaOQUuoN4Hosz+xtq7XOsElUQgghhBBCiBrvQi0bTwC5wHPAZKXU2fkKywBxn2qMTQghhBBCiMuO1tKyAYDWWn4lXAghhBBCCHFRLjhmQwghhBBCCFF1zGZ59K0QQgghhBCiGsgA8RpgzLUBdGzpTm6e5oNvEzkWnWe13K3D/OjR3hOzWfP32nR+X51eqfUdxbrtu3nr8+8wm82MvKo3d147rNTyP1Zt4Ktf/wDAw82Vp8aOpmlkPQDSM7N45aMvOXoqGpTiufF30bZZY5vnUFmbNm/hwzmfYjabGDp4MLfefGOp5SdPRTHr7Xc4fPgId995BzfdcF2p5SaTiYcee5ygwECmvXS+36d0HFprvpn7Bru2rMbF1Y17Hp5Cg8Yty5RLiIvm41mTyMxIpUGjFox9dDpOzs5Fy48d2sPLz9zFA0+8SpeeA22ZQqVprfnr25c5vGsFzi5uXDPmVeo0aF2m3M+fPMHpE7sxGp0Jb9iW4bdPxejkTOLpI/z2xbPEntxD/2sncMWQe+2QRcVprfnn+5c5stuS74i7XiWsftl8F819gtiTuzEYnakT2Zaho6diNDpzcPs/rPrtHZQyYDAYuermZ6nXpMI/5GoXO7as46tP38JsMtN/8EhG3nhnqeVaa7785E12bF6Hi6sr9z/2PA0btwBgzjvT2bZ5DT6+/rw2+2t7hH9RtNb89MWr7N22CmdXN0aPn069Rq3KlFv5x9esWDqfxLhTvPzJSrx8/Cu1viPRWrNkwSsc3LESZxc3brjvFcIjy+7b6/9ewNq/viQ5/iSTZq/F09uS86qlc9mxbjEAZlMBCTFHmTR7DR5efrZMo1LW7tzPzPm/YjKbubZfd8ZcM6DU8uVbdvPhT39iUAqjwcATo0fRsXlDYpNSeGHONySlpGMwKK7r34P/Deljpywqrt0nrxAyvD958Ums7HiN1TKt3ppMyNB+mLJz2HHvM6Rt2wtA8OA+tHpzMspo4NRnCznyxie2DF3YUY0ck9GxhTthQU48MiOaOQuTGHtDoNVy/bt6EejnxITXonn89RjWbM+s1PqOwmQ2M3Pu17z17CN889YU/lqziWNRMaXKhIcE8eFLE1kw80XG3DCCGXO+Klr21uff0aNDa757exrz33iByIg6tk6h0kwmE7M//JiXp7zIJx++z/KVKzlx8mSpMt7eXjx4/zhuvP46q5/x86LfqF+vni3CrTK7tq4hLuYkr3zwK3eOf46vPp5htdwPX77LoGtGM+ODX/Hw9GHVv78ULTObTPzw5Tu06XCFjaK+NEd2ryQ5/jgPvvwXw++Yxu8LXrJarm2PkYyf9gfjXvqN/Lxctq9eCIC7px9Dbp1Mj8GOXck46+julZyJP879U/9i6Ohp/Pn1S1bLte42kvte+oN7n/+NgrxcdhTmG9niCu55bhH3PPcrw+98hd+/es6G0Vee2WTii49n8tSLb/H6+9+wbuVfRJ08VqrMji3riI05xayPF3Lv/03i8w9fL1rW56oRPPXSW7YO+5Lt3b6KhNgTPPfOEm6970UWzp1utVyj5h158LlPCAgOv6j1HcnBnStJij3BhNf/4NoxU1g0b6rVcvWbdWTMU5/hF1Q65z7D7+WhaT/z0LSfGXzT40S26OrQFQ2T2cyrX/7MuxPH8sOrT/Ln+m0cjY4tVaZb66Z8O/1xvpn+OC+OvZlpn30PgNFoYMJt1/Dja0/xxQsPs/CfNWXWdURR835i49Vjy10ePLQvnk0iWd5yMLvGP0+b2S9ZFhgMtH73BTZeM5YV7UYQfuvVeLV0/Jue1Ulrc5W/HFWNrGx0aePByi2WisOhk7l4uhvw8zaWKTe4pzc//JXC2QH/aRnmSq3vKPYePkbdsBAiQoNxdnJiUM+urNy0o1SZds0b4+PlCUCbpo1ISEoBIDMrm237DjJyQG8AnJ2c8Pb0sGn8F+PAwUOEh9ehTp0wnJ2d6de3D2vXbyhVxt/Pj+bNmmJ0KrvtEhIT2bhpM0OHDLJVyFVi+8bl9LzyapRSNG7ejqzMdFKSE0qV0Vqzf9cmuvS8CoCeV17Ntg3/FS3/d+m3dL7iKrx9A2wa+8U6sP1f2va4FqUUdRt3ICcrjfSU+DLlmrTth1IKpRQRDduRdiYOAE+fQMIbtsNgrBkNtYd2/kubwnwjGnUgNzuNjNSy+TYukW+dyHakF+br4ubJ2ScD5udlU+IpgQ7pyKG9hNapS0hYBE7OzvToM4gtG1aWKrNlw0r6XDkcpRRNW7QhKzODM8mJALRs0xEvr5r34MPdm/6ja9+RKKWIbNae7Mx0Us8klClXt2FLAkMiLnp9R7Jv6zI69BqFUop6Tco/lsMbtMI/uGzOJe1cv4R2PYZXV6hVYs+Rk9QLCaRuSCDOTk4M7tGB5Vv3lCrj4eZadIxm5+ahsLwP9vOhZWRdADzd3WgYHkr8mTTbJnARkldvJj85tdzloSOvInr+LwCkbNiBs68PrmHB+HVrR9aRE2Qfi0Ln5xPz3RJCr7nKRlELe6uRlY0AXyOJKQVF00mpBQT4lr3gDA10omcHT2Y8VodJY0MIC3Kq1PqOIiE5hZDA4gvHkEA/EpLL/13F35atoUfHNgBExyfi7+PNtA++4M6npvHyR1+SnZNb7TFfqsSkJIKDgoqmg4OCSEpKqvD6H875lLFj7sagatYufiYpnoDA0KJp/8CQMpWNjPQUPDy9MBZeXAcEhXImKaFo/a3r/6P/kNJdzhxZ+pk4fALCiqZ9/MNIT4krt7ypIJ9d63+lcWvH73JgTXpKHN7+xfl6+10gX1M+ezb8SqMS+R7Y9jdzXhzKwtn3M/zOV6o13kuVnJRAYFBI0XRAUEjR/lqqTHCJMoFly9Q0KWfi8Qss3s6+gaGkJpe98K6u9e0h/UwcviVi9gkII+1M5WPOy83m0K7VtO4yuCrDq3LxZ1IJDfQrmg4N8CPhTNkL8WWbd3H906/x6JtzeXHszWWWxyQks/9ENG0a16/OcG3CLTyU7KjiFpqc6FjcIkKtzI/DLSLU2kfUGtqsq/zlqGrWlVgha/fxrP0XOzsp8gs0k94+zb8bMhh/S1Cl1ncUVp/FXM7dzC2797Pov9U8NPp6wNId6cCxk1w/uB9fvv487q4ufPnLH9UZbtWwkrOyuuXKWr9xE36+vjRr2qSqo6p2VvfDc9O2ujtYCn0zdyY33vkIBqPjVp7LsrKtz3O3/vevp1C/aRfqN3PscQrlquS+/dfXU6jXtAv1mhbn27zjIMZN+YPrx7/PykXvVEuYVcZavmXSrdw+UCNUKO9qXN8OtNVvsMoHfWD7f9Rv2tGhu1CB9e9ra8fygC5t+em1p5n16N18+OOfpZZl5eTy5HvzmDh6FF7ubtUUqe1YO2611tZ33lr0OxPW1KbKRs3odwAM6eXNVd29AThyKpcgPycOYLlDH+jrxJlUU5l1klJNbNiZBcDGXVk8WFjZSEo1VWh9RxES6E98UnLRdHxSCsH+fmXKHToRxSsff8lbkx7F19uraN3gQH/aNG0EwIAenfnyl99tEvelCAoKIiExsWg6ITGRgMCKdQvas3cv6zdsZNPmLeTl5ZGVncWrb8zimSefqK5wL8mypd+x8u+fAYhs0prkpOK73GeS4vHzDy5V3svHj6zMDEymAoxGJ5IT4/ALsOzbJ47s5eNZkwBLC8iuLasxGI106n6ljbKpmM3/LWDbSkvf5ToN25KWXHzHK+1MLF6+IVbXW7loNlnpyYwYP9smcVaVLcsXsGN1Yb4N2pJ+pjjf9JRYvPys57t68WyyMpK5frT1fOs37cqShJNkZSTj4eWY3eYCgkJISiy+u52cGI9fQOl9OiAwhKSEEmWS4ov26Zpk1Z/fsO7fHwGo37gNKUnF2zk1KQ4ff+vb2Rq/gNBLWt9W1v+zgM0rfgAgomEbUkvEnJYci885318VsXP9Utr1GFFlMVaXUH9f4gq7LAPEJacQ5F9+l79OLRoTFf8tZ9Iz8ff2JL/AxJPvzmPYFZ0Y0LWtDSKuftnRsbjXDeNs3wu3iDByY+IxuDjjXre41cstIpScGMduqRNVp8ZUNv5ck86fayxPkurY0p2hvbxZsy2TpvVdycoxk5JetrKwaXcWbZq68d/GDFo1diMmIR+AzXuyKrS+o2jZOJJTp+OJiU8kOMCPv9duYuojpQdoxSYmMWnmh7z40L3UDy9umgz08yU00J8TMbE0CA9j0659NKwbfu6fcDjNmzUlOjqG07GxBAUGsmLlKp55cmKF1r337ru49+67ANixcxc//PSzw1Y0AAYMv4UBw28BYMfmVSxb+h3deg/h6MFdeHh4lbkwU0rRvE0XNq/9l+59hrD2v8V06NYfgNc+XlxUbu67L9K+Sx+Hq2gAdLlyNF2uHA3AoZ3L2fzffFp3G0H00R24uXvjbeXie9uqhRzdu5rRj3+BMtSsRtnO/UfTub8l38O7lrN1+XxadhlBzLEduLp5W61c7Vi9kGN7V3PrY6XzPRN/Ar/g+iiliD25B1NBPu6e/rZKpdIaNW1JbMwp4mNjCAgMZv2qv/m/iaUHDnfq1oe/lizkir6DOHxgD+4eXvjXwMpGnyG30WfIbQDs2bqSVX9+TaeewzhxaCduHl74VuLCu02XKy9pfVvpMXA0PQZa9u0D25ez/p+vaddjOFFHduBazrF8PjlZ6Rw/sJmbHnj9woXtrFWjepyKSyQ6IYkQf1/+Wr+dl8ePLlXmVFwidUMCUUqx73gU+SYTfl4eaK2ZNvd7GoaHcvuwfnbKoOrF/7aMBg/eTsx3S/Dr3p6CtHRyYxPIS0jGs0kk7pF1yYmOI/yWEWy7w3HPy7ZgduAB3VWtxlQ2Stq2L5tOLd15d1IEefmWR9ee9czYED7+PokzaSZ++TeVR0YHMaKvDzm5Zj7+PvGC6zsiJ6ORiffcxqMvv43ZbObqK3vRqF44P/21AoDrB/dj7g9LSM3I5I1PFwBgNBr54tXJADxxz228+O5c8gsKiAgJ4rkH77ZXKhVmNBp5aPz9PPv8S5jNZoYMGkhkg/osXmpplbl6+DCSk8/w0GOPk5WVhTIY+PnXRXzy0ft4ejj+APjytOvcm11bVjNp/KjCR9++VLTs7WkPc9f/vYB/QDA33fkIH8+axC9fv0+9hi3oM/Bau8V8qZq07cfhXSt4f/IgnF3cuebu4jEI37xzH1ffNR1vv1CWzn8R38BwvphhqZg17zSIvtc8REZqAnOn30BuTgZKGdj4zzwemLoUV3cve6V0Xo3b9OPo7hV8/Lwl3+F3Fef7/Xv3MewOS75/fP0ivgHhfPW6Jd9mHQfRe8RDHNj2J7vX/4rB6ISTsxuj7nvLobscGY1O3H3/RF576VHMZjP9Bl5N3fqN+Of3nwAYOOx6OnTpyfYta3n8/htxcXXj/keKn7A1+43n2bd7K+lpKTw05hpuvO0++g8eaa90KqxVxz7s3baSaY8Ox8XFjf+NL36a1EczxnPb/VPwDQhhxe8L+HfRZ6SnJPHaUzfQqkMfbntgynnXd1TN2vfj4M6VvPnkEFxc3bh+bPG+/eWscVx7z3R8/ENY99dXrFo6l4zURGY/N4pm7fpy3b2W/PZu+YcmbXri4ur43+NORiNP3XkdD73+CSatGdW3K43rhvHDsrUA3DigJ/9u2smSNVtwMhpxdXZmxoN3oJRi24FjLFmzhSb16nDbc28C8H83DaN3+7KPOnckHb6aRWC/brgE+TPg2AoOTX0P5Wy5lDw551vif19B8LB+9N//N6bsbHaOfRYAbTKx+9GpdFvyKcpoJOqLH8nYe9ieqQgbUlbHA1Shm5847ridyKrJx3eesHcINpfmGXbhQpeZU3l17R2CzR1L9LR3CDZX4LiNntWibXj5D5+4XCVm1779Oj2nRt5rvCTD1BJ7h2BzK3pXrEfA5WRE/gHHvftSwuA7tlX59fFfX3V0yNxrVl8EIYQQQgghRI1R+25tCCGEEEIIYUfaLGM2hBBCCCGEENXAkR9VW9WkG5UQQgghhBCiWkjLhhBCCCGEEDaka9Gjb6VlQwghhBBCCFEtpGVDCCGEEEIIGzLXojEbUtkQQgghhBDChmrT06ikG5UQQgghhBCiWkjLhhBCCCGEEDYkj74VQgghhBBCiEskLRtCCCGEEELYUG169K1UNoQQQgghhLAh6UYlhBBCCCGEEJdIWjaEEEIIIYSwIXn0rRBCCCGEEEJcIqV19fYZU0qN01rPqdY/4mAk59pBcq4dalvOtS1fkJxrC8lZCPuwRcvGOBv8DUcjOdcOknPtUNtyrm35guRcW0jOQtiBdKMSQgghhBBCVAupbAghhBBCCCGqhS0qG7Wxr6DkXDtIzrVDbcu5tuULknNtITkLYQfVPkBcCCGEEEIIUTtJNyohhBBCCCFEtajyyoZS6jqllFZKtVBKbVBKbVdKnVRKJRS+366Uiqzqv2tPJXMunI5USmUX5rpXKfWRUuqyqdiVk+/uc8q8pJSaaJ8IL94FtuXZl4tS6u7CfXqbUuqQUupPpVTPEp/zhVLqWGH5rUqpK+yXVfmUUqFKqa+VUkeVUluUUuuUUntK7Lslc7/xnLy2K6XWFn7O2f+Ps+vdZ+/cKkopFVgin1ilVHSJ6SylVNsS08kl8v/H3rFfjAvkG6qUyldK3V9Y9v3y9gV751FRF8hXn3NsP6OUekUp9VqJ9RsUHh9+dkyjUpRSYUqpb5VSRwq33VKlVLPCbbhNKbVPKbVRKXVXiXVq7DF8rvPk31optUwpdbDwe/t5pZSyd7wXo3DfnVVieqJS6qUS0+OUUvsLXxuVUr0L5z+ulJpbotxopdQSmwYvah+tdZW+gO+BVcBLJebdDcyu6r/lKK9zcwYigd2F752AlcD19o7TFvmWKPMSMNHesVZHboXzS+3TwJVALNCycPoL4MbC94OBnfbOzUoOClgHPFBiXgPg4fNs16K8yvv/AEKABCDU3jlexP9Jqf0WyKhI/jX1ZSXfBwv3/+XnlLN6HNS014W2b+E8d2B/iWP5F2C0vWOvRI7WjusOQJ+S2xBoBGwHxhROXy7H8PnyPwIMLpznAfwO/J+9Y77IPHOAY0BQ4fTEEuetq4EtJZZ1Ak4CYViuSbYDvQC/ws9oZO985HV5v6r0brtSyqtwB74XuLUqP9tRXShnrXUBsBZoYuPQqsXlvI0vJTet9X9YBuJZe6b5Shxz+w8A8rTWH52dobU+obV+71I+VGsdj+Wk3uAS4xO2dxvwBFBXKRVh72DsQWudDTwOfKCUGgZ4a60X2DmsyrgSyD/nuN4OnCpZSGt9FEuej5z7ATX8GC4v/2bAGq31X4XzsoCHgGfsEWQVKMByzplgZdnTwJNa60QArfVWYB6WilUBlpsK7wOvA58V7gtCVJuq7tpzLfCH1vogkKyU6lTFn++IruU8OSulPICrgF12iK06XIv1fBuX7I4APGCvAC/BtVw4t/fPs/5WoIWV+dfgmNu/NZaYK+uNEv8fZS7ClFKNsNw1PXypAQrbUUrVA8K01huxtPDdYueQbMH9nG5UtwBorZcCycCXWC7MapI2WO5qV4TV76wafgyXl3/rc+drrY8AXkopH1sEVg3eB0YrpXzPmV8mV2Bz4Xy01muBfcBALBUOIaqVUxV/3m3A24Xvvy2cvpiLmZrEWs7vU3iBCmjgV63173aJruqVl+8RrXWHs4VK9h2tQSqU23mc2/f3DaXUc1i6I9xbRTFWm8KKVG8srR1dz1P0Sa31D1bm31LYLzgXuF9rnVwdcYpqcyuWSgZY9v+5wJv2C8cmss9zbL8PuGutD9gwHls79zvrcj6GFZbzsTU18rGcWus0pdSXWFqnsi9QvCj/wlb8LoAzEAxEVWecQlRZZUMpFYilW0YbpZQGjIBWSj1VVX/D0ZSXM/ABFb9ArTEukG+NVkW5dcRyt+is8i7KHcUe4IazE1rr/1NKBWG5A3YxvtNaP1QlkQl7uA0IVUqNLpwOV0o11VofsmdQdmQufNU0e4CKDuA/9zvrcjiGy8t/D9C35IzCFpwMrXW6LQKrJm9juan7eYl5e4HOwLIS8zoVzgeYAswH4oC3gJuqPUpRq1VlN6obgS+11g201pFa63pYBh71rsK/4WjKy7muneOqLpdzvpeUm1KqH5bxGp9UY4xVbRngppQaX2Keh72CEfajlGoOeGqtIwr3/0hgBpfZuKxaYhngWvJpUkqprpwz/kJZngo5E7ikMVoOqLz8DwG9lVIDC+e5A+9Sw7sRFbY+fU/p1vPXgdcKb6KhlOqA5QEAHyil2gIjgNewjPlooJQaZMuYRe1TlZWN24Cfz5n3I/C/Kvwbjqa8nJ+1Qyy2cDnnezG53VLYz/tgYbkbtNb7zlPeoWitNZZxKv2U5XGuG7EMInz6AquWHLOxXSnlUt2ximpX3v5/mx1isaVzx2y8au+ALlXhcX0dMKjw0a97sDyFKwZL995tSql9WC5Q39Naf17+p9U8F8h/FPCcUuoAlnF0m4DZ9oq1Cs0Cgs5OaK0XAZ8Ba5VS+7HcBLsdyxMTPwQmaK1ztNZmLGOS3pHvcVGd5BfEhRBCCCGEENXisvmhOSGEEEIIIYRjkcqGEEIIIYQQolpIZUMIIYQQQghRLaSyIYQQQgghhKgWUtkQQgghhBBCVAupbAghhBBCCCGqhVQ2hBBCCCGEENVCKhtCCCGEEEKIavH/N3astjVjbckAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df_gt.corr()\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99203170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From heatmap we can infer that NOX,CO,AH,AP,AT not shown good co-relation with TEY\n",
    "# So we can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bd3e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking target feature 'TEY' at 0th index position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cfcdf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEY</th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114.70</td>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.72</td>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114.71</td>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114.72</td>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.72</td>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TEY      AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP  \\\n",
       "0  114.70  6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605   \n",
       "1  114.72  6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598   \n",
       "2  114.71  6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601   \n",
       "3  114.72  7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606   \n",
       "4  114.72  7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612   \n",
       "\n",
       "       CO     NOX  \n",
       "0  3.1547  82.722  \n",
       "1  3.2363  82.776  \n",
       "2  3.2012  82.468  \n",
       "3  3.1923  82.670  \n",
       "4  3.2484  82.311  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_gt['TEY']\n",
    "df_gt.drop(['TEY'], axis=1, inplace=True)\n",
    "df_gt.insert(0, 'TEY', y)\n",
    "df_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e228ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_gt.drop(['TEY','AT','AP','AH','CO','NOX'], axis = 1)\n",
    "y = df_gt.iloc[:, 0]\n",
    "\n",
    "# Selecting first 600 records\n",
    "X = X.iloc[0:600, :]\n",
    "y = y.iloc[0:600]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3a24f7",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c4fabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "y = StandardScaler().fit_transform(y.values.reshape(len(y),1))[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bdace0",
   "metadata": {},
   "source": [
    "### Splitting the data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46ee4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "548adfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:  (420, 5)\n",
      "Shape of x_test:  (180, 5)\n",
      "Shape of y_train:  (420,)\n",
      "Shape of y_test:  (180,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_train: ', x_train.shape)\n",
    "print('Shape of x_test: ', x_test.shape)\n",
    "print('Shape of y_train: ', y_train.shape)\n",
    "print('Shape of y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801874b4",
   "metadata": {},
   "source": [
    "## Grid search hyperparameters all at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4f190",
   "metadata": {},
   "source": [
    "### Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22731f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "acf45d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate, dropout_rate, activation_function, init, neuron1, neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1, input_dim = 5, kernel_initializer = init, activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer = init, activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "    adam=adam_v2.Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = adam, metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e17f9a",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "092bb921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n",
      "[CV 1/5; 1/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 1/5; 1/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 1/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 2/5; 1/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 1/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 1/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.5s\n",
      "[CV 4/5; 1/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 1/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 1/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 1/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 2/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 2/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 2/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 2/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 2/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 2/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 2/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 2/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 2/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 2/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 3/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 3/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 3/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 3/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.8s\n",
      "[CV 3/5; 3/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 3/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 3/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 3/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 3/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 5/5; 3/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 4/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 1/5; 4/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 4/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 4/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 4/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 4/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 4/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 4/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 4/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 4/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 5/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 5/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 5/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 5/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.6s\n",
      "[CV 3/5; 5/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 5/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 5/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 5/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 5/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 5/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 6/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 6/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 6/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 6/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 6/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 3/5; 6/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 6/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 6/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 6/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 6/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 7/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 1/5; 7/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 7/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 7/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.5s\n",
      "[CV 3/5; 7/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 7/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 7/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 7/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 7/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 7/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 8/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 8/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 8/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 8/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 8/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 8/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 8/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 8/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 8/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 5/5; 8/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 9/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 9/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.6s\n",
      "[CV 2/5; 9/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 9/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 9/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 9/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 9/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 9/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 9/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 9/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 10/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 10/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 10/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 10/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 10/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 10/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 10/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 10/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 10/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 10/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.5s\n",
      "[CV 1/5; 11/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 11/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.9s\n",
      "[CV 2/5; 11/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 11/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 11/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 11/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.4s\n",
      "[CV 4/5; 11/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 4/5; 11/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.4s\n",
      "[CV 5/5; 11/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 11/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.7s\n",
      "[CV 1/5; 12/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 12/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.5s\n",
      "[CV 2/5; 12/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 12/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.5s\n",
      "[CV 3/5; 12/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 12/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 12/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 12/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 12/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 12/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 13/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 13/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.6s\n",
      "[CV 2/5; 13/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 13/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 13/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 13/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 13/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 13/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 13/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 13/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 14/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 14/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 14/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 14/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 14/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 14/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 14/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 14/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 14/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 14/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.5s\n",
      "[CV 1/5; 15/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 15/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 15/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 15/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.4s\n",
      "[CV 3/5; 15/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 15/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.4s\n",
      "[CV 4/5; 15/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 15/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.4s\n",
      "[CV 5/5; 15/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 15/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 16/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 16/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 16/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 16/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 16/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 16/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 16/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 16/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 16/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 16/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.9s\n",
      "[CV 1/5; 17/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 17/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   4.0s\n",
      "[CV 2/5; 17/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 17/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   3.7s\n",
      "[CV 3/5; 17/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 17/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 17/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 17/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 17/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 17/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 18/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 18/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 18/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 18/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 18/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 18/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 18/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 18/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   3.8s\n",
      "[CV 5/5; 18/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 18/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 19/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 19/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 19/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 19/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 19/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 19/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 19/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 19/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 19/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 19/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 20/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 20/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   3.5s\n",
      "[CV 2/5; 20/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 20/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 20/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 20/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 20/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 20/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   3.9s\n",
      "[CV 5/5; 20/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 20/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 21/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 21/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 21/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 2/5; 21/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   3.6s\n",
      "[CV 3/5; 21/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 21/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   4.1s\n",
      "[CV 4/5; 21/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 21/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   4.5s\n",
      "[CV 5/5; 21/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 21/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   4.2s\n",
      "[CV 1/5; 22/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 22/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 22/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 22/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 22/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 22/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   3.8s\n",
      "[CV 4/5; 22/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 22/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 22/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 22/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 23/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 23/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   3.5s\n",
      "[CV 2/5; 23/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 23/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 23/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 23/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 23/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 23/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 23/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 23/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 24/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 24/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 24/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 24/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 24/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 3/5; 24/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   3.8s\n",
      "[CV 4/5; 24/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 24/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 24/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 24/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 25/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 1/5; 25/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   3.5s\n",
      "[CV 2/5; 25/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 25/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 25/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 25/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 25/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 25/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 25/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 25/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 26/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 26/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 26/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 26/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 26/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 26/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   3.8s\n",
      "[CV 4/5; 26/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 26/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 26/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 26/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 27/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 27/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 27/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 27/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 27/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 27/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 27/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 27/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 27/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 27/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 28/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 28/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   3.5s\n",
      "[CV 2/5; 28/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 28/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 28/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 28/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   3.9s\n",
      "[CV 4/5; 28/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 28/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 28/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 28/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 29/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 29/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 29/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 29/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 29/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 3/5; 29/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 29/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 29/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 29/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 29/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 30/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 30/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   3.5s\n",
      "[CV 2/5; 30/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 30/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 30/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 30/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   4.4s\n",
      "[CV 4/5; 30/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 30/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   3.6s\n",
      "[CV 5/5; 30/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 30/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 31/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 31/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 31/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 31/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 31/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 31/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 31/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 31/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 31/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 31/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 32/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 32/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 32/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 32/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 32/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 32/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   4.4s\n",
      "[CV 4/5; 32/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 32/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 32/256] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 32/256] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 33/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 33/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 33/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 33/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 33/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 33/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 33/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 4/5; 33/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 33/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 33/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 34/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 34/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 34/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 34/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.5s\n",
      "[CV 3/5; 34/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 34/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 34/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 34/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 34/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 34/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 35/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 35/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 35/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 35/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 35/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 3/5; 35/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 35/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 35/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 35/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 35/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 36/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 36/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 36/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 36/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.6s\n",
      "[CV 3/5; 36/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 36/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 36/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 36/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 36/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 36/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 37/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 37/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 37/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 37/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 37/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 3/5; 37/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 37/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 37/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 37/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 37/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 38/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 38/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.5s\n",
      "[CV 2/5; 38/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 38/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 38/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 38/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 38/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 38/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 38/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 38/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 39/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 39/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 39/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 39/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 39/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 3/5; 39/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 39/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 39/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 39/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 39/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 40/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 40/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.5s\n",
      "[CV 2/5; 40/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 40/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 40/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 40/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 40/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 40/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 40/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 40/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 41/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 41/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 41/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 41/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 41/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 41/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 41/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 41/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 41/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 41/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 42/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 42/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.5s\n",
      "[CV 2/5; 42/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 42/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 42/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 42/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.4s\n",
      "[CV 4/5; 42/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 42/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 42/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 42/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 43/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 1/5; 43/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 43/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 43/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 43/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 43/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 43/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 43/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 43/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 43/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 44/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 44/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.6s\n",
      "[CV 2/5; 44/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 44/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 44/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 44/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 44/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 44/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 44/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 44/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 45/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 45/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 45/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 45/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 45/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 45/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 45/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 45/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 45/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 45/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 46/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 46/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.5s\n",
      "[CV 2/5; 46/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 46/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 46/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 46/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 46/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 46/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 46/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 46/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 47/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 47/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 47/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 47/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 47/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 47/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 47/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 47/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 47/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 47/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 48/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 48/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.6s\n",
      "[CV 2/5; 48/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 48/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 48/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 3/5; 48/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 48/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 48/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 48/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 48/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 49/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 49/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 49/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 49/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 49/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 49/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 49/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 49/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 49/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 49/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 50/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 50/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   4.0s\n",
      "[CV 2/5; 50/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 50/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 50/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 3/5; 50/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 50/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 4/5; 50/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 50/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 50/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 51/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 51/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 51/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 51/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 51/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 51/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 51/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 51/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 51/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 51/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 52/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 1/5; 52/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   3.9s\n",
      "[CV 2/5; 52/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 52/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 52/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 3/5; 52/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   3.6s\n",
      "[CV 4/5; 52/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 52/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 52/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 52/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 53/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 53/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 53/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 53/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 53/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 53/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   3.6s\n",
      "[CV 4/5; 53/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 53/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 53/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 53/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 54/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 54/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   4.2s\n",
      "[CV 2/5; 54/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 54/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 54/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 54/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 54/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 54/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 54/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 54/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 55/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 55/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 55/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 55/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 55/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 55/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 55/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 55/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   3.5s\n",
      "[CV 5/5; 55/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 55/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 56/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 56/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   6.2s\n",
      "[CV 2/5; 56/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 56/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   4.8s\n",
      "[CV 3/5; 56/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 56/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   3.9s\n",
      "[CV 4/5; 56/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 56/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   4.1s\n",
      "[CV 5/5; 56/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 56/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   3.9s\n",
      "[CV 1/5; 57/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 57/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   3.5s\n",
      "[CV 2/5; 57/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 57/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 57/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 3/5; 57/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 57/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 57/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 57/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 57/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 58/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 58/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   3.8s\n",
      "[CV 2/5; 58/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 58/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   3.5s\n",
      "[CV 3/5; 58/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 58/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 58/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 58/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 58/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 58/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 59/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 59/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   3.5s\n",
      "[CV 2/5; 59/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 59/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 59/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 59/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 59/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 59/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 59/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 59/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   3.9s\n",
      "[CV 1/5; 60/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 1/5; 60/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   4.4s\n",
      "[CV 2/5; 60/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 60/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   4.0s\n",
      "[CV 3/5; 60/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 60/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 60/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 60/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 60/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 60/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 61/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 61/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 61/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 61/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 61/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 61/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   3.5s\n",
      "[CV 4/5; 61/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 61/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 61/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 61/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   3.8s\n",
      "[CV 1/5; 62/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 62/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 62/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 62/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 62/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 62/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 62/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 62/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 62/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 62/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 63/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 63/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 63/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 63/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 63/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 63/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 63/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 63/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 63/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 63/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   3.8s\n",
      "[CV 1/5; 64/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 64/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 64/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 64/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 64/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 64/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 64/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 64/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 64/256] START activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 64/256] END activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   3.4s\n",
      "[CV 1/5; 65/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 65/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 65/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 65/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 65/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 65/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 65/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 65/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 65/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 65/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 66/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 66/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 66/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 66/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 66/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 66/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 66/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 66/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 66/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 66/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 67/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 67/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 67/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 67/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 67/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 67/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 67/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 67/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 67/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 67/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 68/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 68/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 68/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 68/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 68/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 68/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 68/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 68/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 68/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 68/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 69/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 69/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 69/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 69/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 69/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 69/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 69/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 69/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 69/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 69/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 70/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 70/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 70/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 70/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 70/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 70/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 70/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 70/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 70/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 70/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 71/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 71/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 71/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 71/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 71/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 71/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 71/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 71/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 71/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 71/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 72/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 72/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 72/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 72/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 72/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 72/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 72/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 72/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 72/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 72/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 73/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 73/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 73/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 73/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 73/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 73/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 73/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 73/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 73/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 1s 0s/step\n",
      "[CV 5/5; 73/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 74/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 74/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 74/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 74/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 74/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 74/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 74/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 74/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 74/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 74/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 75/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 75/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 75/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 75/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 75/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 75/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 75/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 75/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 75/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 75/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 76/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 76/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 76/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 76/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 76/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 76/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 76/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 76/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 76/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 76/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 77/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 77/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 77/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 77/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 77/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 77/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 77/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 77/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 77/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 77/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 78/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 78/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 78/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 78/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 78/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 78/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 78/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 78/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 78/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 78/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 79/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 79/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 79/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 79/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 79/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 79/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 79/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 79/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 79/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 79/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 80/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 80/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 80/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 80/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 80/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 80/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 80/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 80/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 80/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 80/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 81/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 81/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 81/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 81/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 81/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 81/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 81/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 81/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 81/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 81/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.5s\n",
      "[CV 1/5; 82/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 82/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 82/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 82/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.8s\n",
      "[CV 3/5; 82/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 82/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 82/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 82/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 82/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 82/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 83/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 83/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.4s\n",
      "[CV 2/5; 83/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 83/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.4s\n",
      "[CV 3/5; 83/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 83/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 83/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 83/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 83/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 83/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 84/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 84/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 84/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 84/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   3.1s\n",
      "[CV 3/5; 84/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 84/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.4s\n",
      "[CV 4/5; 84/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 84/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 84/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 84/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 85/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 85/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 85/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 85/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 85/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 85/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 85/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 85/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 85/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 85/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 86/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 86/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.7s\n",
      "[CV 2/5; 86/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 86/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 86/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 86/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 86/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 86/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 86/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 86/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 87/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 87/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 87/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 87/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 87/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 87/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 87/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 87/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 87/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 87/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.4s\n",
      "[CV 1/5; 88/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 88/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.8s\n",
      "[CV 2/5; 88/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 88/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 88/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 88/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.6s\n",
      "[CV 4/5; 88/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 88/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.6s\n",
      "[CV 5/5; 88/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 88/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 89/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 89/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.4s\n",
      "[CV 2/5; 89/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 89/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 89/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 89/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 89/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 89/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 89/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 89/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 90/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 90/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.7s\n",
      "[CV 2/5; 90/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 90/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 90/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 90/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 90/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 90/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 90/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 90/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 91/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 91/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 91/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 91/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 91/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 91/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 91/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 91/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 91/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 91/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 92/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 92/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.7s\n",
      "[CV 2/5; 92/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 92/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 92/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 92/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 92/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 92/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 92/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 92/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 93/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 93/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 93/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 93/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 93/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 93/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 93/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 93/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 93/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 93/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 94/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 94/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.7s\n",
      "[CV 2/5; 94/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 94/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 94/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 94/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 94/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 94/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 94/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 94/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 95/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 95/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 95/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 95/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 95/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 95/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 95/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 95/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 95/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 95/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 96/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 96/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.8s\n",
      "[CV 2/5; 96/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 96/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 96/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 96/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 96/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 96/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 96/256] START activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 96/256] END activation_function=relu, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 97/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 97/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 97/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 97/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 97/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 97/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 97/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 97/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 97/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 97/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 98/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 98/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 98/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 98/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 98/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 98/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 98/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 98/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 98/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 98/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 99/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 99/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 99/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 99/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 99/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 99/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 99/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 99/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 99/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 99/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 100/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 100/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 100/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 100/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 100/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 100/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 100/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 100/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 100/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 100/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 101/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 101/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 101/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 101/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 101/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 101/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 101/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 101/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 101/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 101/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 102/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 102/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 102/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 102/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 102/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 102/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 102/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 102/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 102/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 102/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 103/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 103/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 103/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 103/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 103/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 103/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 103/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 103/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 103/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 103/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 104/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 104/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 104/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 104/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 104/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 104/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 104/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 104/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 104/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 104/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 105/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 105/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 105/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 105/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 105/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 105/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 105/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 105/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 105/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 105/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 106/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 106/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 106/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 106/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 106/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 106/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   1.8s\n",
      "[CV 4/5; 106/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 106/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 106/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 106/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 107/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 107/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 107/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 107/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 107/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 107/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 107/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 107/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 107/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 107/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 108/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 108/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 108/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 108/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 108/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 108/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 108/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 108/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 108/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 108/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 109/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 109/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 109/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 109/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 109/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 109/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 109/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 109/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 109/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 109/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 110/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 110/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 110/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 110/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 110/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 110/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 110/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 110/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 110/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 110/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 111/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 111/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 111/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 111/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 111/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 111/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 111/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 111/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 111/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 111/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 112/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 112/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 112/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 112/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 112/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 112/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 112/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 112/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 112/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 112/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 113/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 113/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 113/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 113/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 113/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 113/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 113/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 113/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 113/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 113/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 114/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 114/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 114/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 114/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 114/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 114/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 114/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 114/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 114/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 114/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 115/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 115/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 115/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 115/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 115/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 115/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 115/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 115/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 115/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 115/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 116/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 116/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 116/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 116/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 116/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 116/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 116/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 116/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 116/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 116/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 117/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 117/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 117/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 117/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 117/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 117/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 117/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 117/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 117/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 117/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 118/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 118/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.5s\n",
      "[CV 2/5; 118/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 118/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 118/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 118/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 118/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 118/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 118/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 118/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 119/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 119/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 119/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 119/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 119/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 119/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 119/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 119/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 119/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 119/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 120/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 120/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 120/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 120/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 120/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 120/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 120/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 120/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 120/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 120/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 121/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 121/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 121/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 121/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 121/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 121/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 121/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 121/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 121/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 121/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 122/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 122/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 122/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 122/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 122/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 122/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 122/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 122/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 122/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 122/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 123/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 123/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 123/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 123/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 123/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 123/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 123/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 123/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 123/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 123/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 124/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 124/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.4s\n",
      "[CV 2/5; 124/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 124/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 124/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 124/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 124/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 124/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 124/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 124/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 125/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 125/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 125/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 125/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 125/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 125/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 125/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 125/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 125/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 125/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 126/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 126/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 126/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 126/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 126/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 126/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 126/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 126/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 126/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 126/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 127/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 127/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 127/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 127/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 127/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 127/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 127/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 127/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 127/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 127/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 128/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 128/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 128/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 128/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 128/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 128/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 128/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 128/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 128/256] START activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 128/256] END activation_function=relu, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 129/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 129/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 129/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 129/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 129/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 129/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 129/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 129/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 129/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 129/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 130/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 130/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 130/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 130/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.5s\n",
      "[CV 3/5; 130/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 130/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 130/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 130/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 130/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 130/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 131/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 131/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 131/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 131/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 131/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 131/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 131/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 131/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 131/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 131/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 132/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 132/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 132/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 132/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 132/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 132/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.5s\n",
      "[CV 4/5; 132/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 132/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 132/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 132/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 133/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 133/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 133/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 133/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 133/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 133/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 133/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 133/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 133/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 133/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 134/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 134/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 134/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 134/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 134/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 134/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 134/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 134/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.5s\n",
      "[CV 5/5; 134/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 134/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 135/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 135/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 135/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 135/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 135/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 135/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 135/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 135/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 135/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 135/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 136/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 136/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 136/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 136/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 136/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 136/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 136/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 136/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.5s\n",
      "[CV 5/5; 136/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 136/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 137/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 137/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 137/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 137/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 137/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 137/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 137/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 137/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 137/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 137/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 138/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 138/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 138/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 138/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 138/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 138/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 138/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 138/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.5s\n",
      "[CV 5/5; 138/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 138/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 139/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 139/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 139/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 139/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 139/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 139/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 139/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 139/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 139/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 139/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 140/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 140/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 140/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 140/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 140/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 140/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 140/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 140/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 140/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 140/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.5s\n",
      "[CV 1/5; 141/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 141/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 141/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 141/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 141/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 141/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 141/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 141/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 141/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 141/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 142/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 142/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 142/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 142/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 142/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 142/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 142/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 142/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 142/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 142/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.5s\n",
      "[CV 1/5; 143/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 143/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 143/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 143/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 143/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 143/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 143/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 143/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 143/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 143/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 144/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 144/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 144/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 144/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.1s\n",
      "[CV 3/5; 144/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 144/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.1s\n",
      "[CV 4/5; 144/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 144/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 144/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 144/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.5s\n",
      "[CV 1/5; 145/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 145/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   3.3s\n",
      "[CV 2/5; 145/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 145/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   3.3s\n",
      "[CV 3/5; 145/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 145/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   3.3s\n",
      "[CV 4/5; 145/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 145/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   3.3s\n",
      "[CV 5/5; 145/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 145/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   3.3s\n",
      "[CV 1/5; 146/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 146/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   3.9s\n",
      "[CV 2/5; 146/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 146/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=180.1min\n",
      "[CV 3/5; 146/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 146/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   3.7s\n",
      "[CV 4/5; 146/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 1s 0s/step\n",
      "[CV 4/5; 146/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=342.5min\n",
      "[CV 5/5; 146/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 146/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   6.8s\n",
      "[CV 1/5; 147/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 147/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   4.5s\n",
      "[CV 2/5; 147/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 147/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   4.1s\n",
      "[CV 3/5; 147/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 147/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   3.3s\n",
      "[CV 4/5; 147/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 147/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   3.7s\n",
      "[CV 5/5; 147/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 147/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   3.5s\n",
      "[CV 1/5; 148/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 148/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   3.3s\n",
      "[CV 2/5; 148/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 148/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 148/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 148/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   3.3s\n",
      "[CV 4/5; 148/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 148/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   3.6s\n",
      "[CV 5/5; 148/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 148/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   3.8s\n",
      "[CV 1/5; 149/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 149/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   3.6s\n",
      "[CV 2/5; 149/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 149/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 149/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 149/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   3.1s\n",
      "[CV 4/5; 149/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 149/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 149/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 149/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 150/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 150/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 150/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 150/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 150/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 150/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 150/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 150/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 150/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 150/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 151/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 1/5; 151/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   3.7s\n",
      "[CV 2/5; 151/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 151/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   3.1s\n",
      "[CV 3/5; 151/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 3/5; 151/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 151/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 151/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 151/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 151/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 152/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 152/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 152/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 152/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 152/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 152/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 152/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 152/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 152/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 152/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 153/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 153/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   3.1s\n",
      "[CV 2/5; 153/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 153/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   3.6s\n",
      "[CV 3/5; 153/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 153/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 153/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 153/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 153/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 153/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 154/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 154/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 154/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 154/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 154/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 154/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 154/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 154/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 154/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 154/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   3.1s\n",
      "[CV 1/5; 155/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 1/5; 155/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 155/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 2/5; 155/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   3.6s\n",
      "[CV 3/5; 155/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 155/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 155/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 155/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   3.4s\n",
      "[CV 5/5; 155/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 155/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 156/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 156/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=11.6min\n",
      "[CV 2/5; 156/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 156/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   4.0s\n",
      "[CV 3/5; 156/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 156/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   3.4s\n",
      "[CV 4/5; 156/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 156/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   4.2s\n",
      "[CV 5/5; 156/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 156/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   4.7s\n",
      "[CV 1/5; 157/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 157/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   3.8s\n",
      "[CV 2/5; 157/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 157/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   4.9s\n",
      "[CV 3/5; 157/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 157/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   3.7s\n",
      "[CV 4/5; 157/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 4/5; 157/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   3.8s\n",
      "[CV 5/5; 157/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 157/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   4.1s\n",
      "[CV 1/5; 158/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 158/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   3.7s\n",
      "[CV 2/5; 158/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 158/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   3.6s\n",
      "[CV 3/5; 158/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 158/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   4.4s\n",
      "[CV 4/5; 158/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 158/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   4.5s\n",
      "[CV 5/5; 158/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 158/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   4.3s\n",
      "[CV 1/5; 159/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 1/5; 159/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 159/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 159/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   3.4s\n",
      "[CV 3/5; 159/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 159/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   3.6s\n",
      "[CV 4/5; 159/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 159/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 159/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 159/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 160/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 160/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 160/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 160/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   3.1s\n",
      "[CV 3/5; 160/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 3/5; 160/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   3.1s\n",
      "[CV 4/5; 160/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 160/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 160/256] START activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 160/256] END activation_function=linear, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 161/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 161/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   1.9s\n",
      "[CV 2/5; 161/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 161/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 161/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 3/5; 161/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 161/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 4/5; 161/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.4s\n",
      "[CV 5/5; 161/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 161/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 162/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 162/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   1.9s\n",
      "[CV 2/5; 162/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 162/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 162/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 162/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 162/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 162/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 162/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 162/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 163/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 163/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   1.9s\n",
      "[CV 2/5; 163/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 163/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 163/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 163/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 163/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 163/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.4s\n",
      "[CV 5/5; 163/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 163/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 164/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 164/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 164/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 164/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 164/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 164/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 164/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 4/5; 164/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.1s\n",
      "[CV 5/5; 164/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 164/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.1s\n",
      "[CV 1/5; 165/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 1/5; 165/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   1.9s\n",
      "[CV 2/5; 165/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 165/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   1.9s\n",
      "[CV 3/5; 165/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 165/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   1.9s\n",
      "[CV 4/5; 165/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 165/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.4s\n",
      "[CV 5/5; 165/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 165/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   1.9s\n",
      "[CV 1/5; 166/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 166/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 166/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 166/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 166/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 166/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 166/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 166/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 166/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 166/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 167/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 167/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 167/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 2/5; 167/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 167/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 167/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 167/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 167/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 167/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 167/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.4s\n",
      "[CV 1/5; 168/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 1/5; 168/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   1.9s\n",
      "[CV 2/5; 168/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 2/5; 168/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 168/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 168/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 168/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 168/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 168/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 168/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 169/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 169/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 169/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 169/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 169/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 169/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 169/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 4/5; 169/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 169/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 169/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 170/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 170/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.4s\n",
      "[CV 2/5; 170/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 170/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 170/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 170/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 170/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 170/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 170/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 170/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   1.9s\n",
      "[CV 1/5; 171/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 1/5; 171/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 171/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 171/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 171/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 171/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 171/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 171/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 171/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 171/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 172/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 172/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.4s\n",
      "[CV 2/5; 172/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 2/5; 172/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   1.9s\n",
      "[CV 3/5; 172/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 172/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   1.9s\n",
      "[CV 4/5; 172/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 172/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 172/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 172/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 173/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 1/5; 173/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 173/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 173/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 173/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 173/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 173/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 173/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 173/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 173/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 174/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 174/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   1.9s\n",
      "[CV 2/5; 174/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 174/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.4s\n",
      "[CV 3/5; 174/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 3/5; 174/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   1.9s\n",
      "[CV 4/5; 174/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 174/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 174/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 174/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 175/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 175/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 175/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 175/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 175/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 175/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 175/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 175/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 175/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 175/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 176/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 176/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 176/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 176/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 176/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 176/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.5s\n",
      "[CV 4/5; 176/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 176/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 176/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 176/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 177/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 177/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 177/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 177/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 177/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 3/5; 177/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   3.1s\n",
      "[CV 4/5; 177/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 177/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   3.1s\n",
      "[CV 5/5; 177/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 177/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 178/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 178/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 178/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 178/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   3.1s\n",
      "[CV 3/5; 178/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 178/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   3.6s\n",
      "[CV 4/5; 178/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 178/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   3.1s\n",
      "[CV 5/5; 178/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 178/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   3.1s\n",
      "[CV 1/5; 179/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 179/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 179/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 179/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   4.3s\n",
      "[CV 3/5; 179/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 179/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   5.5s\n",
      "[CV 4/5; 179/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 179/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   4.9s\n",
      "[CV 5/5; 179/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 179/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   3.1s\n",
      "[CV 1/5; 180/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 1/5; 180/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 180/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 180/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 180/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 180/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 180/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 180/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   3.6s\n",
      "[CV 5/5; 180/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 180/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   3.3s\n",
      "[CV 1/5; 181/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 181/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   3.4s\n",
      "[CV 2/5; 181/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 181/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 181/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 3/5; 181/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 181/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 181/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 181/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 181/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 182/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 182/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 182/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 2/5; 182/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 182/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 3/5; 182/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 182/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 182/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 182/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 182/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   3.7s\n",
      "[CV 1/5; 183/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 183/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 183/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 183/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 183/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 183/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 183/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 183/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   3.1s\n",
      "[CV 5/5; 183/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 183/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 184/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 184/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 184/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 184/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   3.3s\n",
      "[CV 3/5; 184/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 184/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 184/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 184/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 184/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 184/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   3.6s\n",
      "[CV 1/5; 185/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 185/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 185/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 185/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   3.1s\n",
      "[CV 3/5; 185/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 185/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   3.1s\n",
      "[CV 4/5; 185/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 185/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 185/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 185/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 186/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 186/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 186/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 186/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   3.1s\n",
      "[CV 3/5; 186/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 186/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 186/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 186/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   3.1s\n",
      "[CV 5/5; 186/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 186/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   3.1s\n",
      "[CV 1/5; 187/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 1/5; 187/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   3.6s\n",
      "[CV 2/5; 187/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 187/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 187/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 187/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 187/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 187/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   3.1s\n",
      "[CV 5/5; 187/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 187/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   3.1s\n",
      "[CV 1/5; 188/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 1/5; 188/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 188/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 188/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 188/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 188/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 188/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 4/5; 188/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 188/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 5/5; 188/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   3.1s\n",
      "[CV 1/5; 189/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 189/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 189/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 189/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   3.6s\n",
      "[CV 3/5; 189/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 189/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 189/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 4/5; 189/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   3.1s\n",
      "[CV 5/5; 189/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 189/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   3.1s\n",
      "[CV 1/5; 190/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 190/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   3.1s\n",
      "[CV 2/5; 190/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 190/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 190/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 190/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 190/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 190/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   3.1s\n",
      "[CV 5/5; 190/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 190/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   3.1s\n",
      "[CV 1/5; 191/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 1/5; 191/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 191/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 1s 7ms/step\n",
      "[CV 2/5; 191/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   3.6s\n",
      "[CV 3/5; 191/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 191/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   3.1s\n",
      "[CV 4/5; 191/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 191/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 191/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 191/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   3.1s\n",
      "[CV 1/5; 192/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 1/5; 192/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   3.2s\n",
      "[CV 2/5; 192/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 192/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   3.2s\n",
      "[CV 3/5; 192/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 192/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   3.2s\n",
      "[CV 4/5; 192/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 192/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   3.2s\n",
      "[CV 5/5; 192/256] START activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 192/256] END activation_function=linear, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   3.2s\n",
      "[CV 1/5; 193/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 193/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   1.4s\n",
      "[CV 2/5; 193/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 2/5; 193/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   1.4s\n",
      "[CV 3/5; 193/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 193/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   1.9s\n",
      "[CV 4/5; 193/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 4/5; 193/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   1.4s\n",
      "[CV 5/5; 193/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 5/5; 193/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   1.4s\n",
      "[CV 1/5; 194/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 194/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   1.4s\n",
      "[CV 2/5; 194/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 194/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 194/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 194/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 194/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 194/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 194/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 194/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 195/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 195/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 195/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 195/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 195/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 195/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   1.4s\n",
      "[CV 4/5; 195/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 195/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 195/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 195/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 196/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 1/5; 196/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 196/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 2/5; 196/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 196/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 196/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 196/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 196/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 196/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 196/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 197/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 197/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 197/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 197/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   1.4s\n",
      "[CV 3/5; 197/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 197/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   1.4s\n",
      "[CV 4/5; 197/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 197/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   1.4s\n",
      "[CV 5/5; 197/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 197/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   1.9s\n",
      "[CV 1/5; 198/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 1/5; 198/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 198/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 2/5; 198/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   1.4s\n",
      "[CV 3/5; 198/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 198/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 198/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 4/5; 198/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   1.4s\n",
      "[CV 5/5; 198/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 198/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   1.4s\n",
      "[CV 1/5; 199/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 1/5; 199/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 199/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 2/5; 199/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 199/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 3/5; 199/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 199/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 199/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 199/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 5/5; 199/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   1.9s\n",
      "[CV 1/5; 200/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 1/5; 200/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 200/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 2/5; 200/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 200/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 200/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   1.4s\n",
      "[CV 4/5; 200/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 4/5; 200/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 200/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 200/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 201/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 201/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 201/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 2/5; 201/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 201/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 3/5; 201/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 201/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "[CV 4/5; 201/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 201/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 5/5; 201/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 202/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 202/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 202/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 202/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 202/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 3/5; 202/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   1.7s\n",
      "[CV 4/5; 202/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 202/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 202/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[CV 5/5; 202/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 203/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 1/5; 203/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 203/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 203/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 203/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 203/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 203/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 203/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 203/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 5/5; 203/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 204/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 204/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.1s\n",
      "[CV 2/5; 204/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 204/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 204/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 3/5; 204/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 204/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[CV 4/5; 204/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 204/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "[CV 5/5; 204/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 205/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 205/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 205/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "[CV 2/5; 205/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 205/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "[CV 3/5; 205/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 205/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[CV 4/5; 205/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 205/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "[CV 5/5; 205/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 206/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 206/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   1.7s\n",
      "[CV 2/5; 206/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 206/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 206/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 206/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 206/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 206/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 206/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 206/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 207/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 207/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 207/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 207/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 207/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 207/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 207/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 207/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 207/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 207/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 208/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 208/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 208/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 208/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 208/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 208/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 208/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 208/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 208/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 208/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 209/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 209/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 209/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 209/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 209/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 209/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 209/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 209/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 209/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 209/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 210/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 210/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 210/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 210/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 210/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 210/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 210/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 210/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.7s\n",
      "[CV 5/5; 210/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 210/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 211/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 211/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 211/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 211/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 211/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 211/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 211/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 211/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 211/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 211/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 212/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 212/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 212/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 212/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 212/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 212/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 212/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 212/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 212/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 212/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.8s\n",
      "[CV 1/5; 213/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 213/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 213/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 213/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 213/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 213/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 213/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 213/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 213/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 213/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 214/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 214/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 214/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 214/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.2s\n",
      "[CV 3/5; 214/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 214/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 214/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 214/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 214/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 214/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.7s\n",
      "[CV 1/5; 215/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 215/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 215/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 215/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 215/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 215/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 215/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 215/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 215/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 215/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 216/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 216/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 216/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 216/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 216/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 216/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 216/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 216/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 216/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 216/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 217/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 217/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.7s\n",
      "[CV 2/5; 217/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 217/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 217/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 217/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 217/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 217/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 217/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 217/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 218/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 218/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 218/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 218/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 218/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 218/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 218/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 218/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 218/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 218/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 219/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 219/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 219/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 219/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.8s\n",
      "[CV 3/5; 219/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 219/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 219/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 219/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 219/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 219/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 220/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 220/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 220/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 220/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 220/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 220/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 220/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 220/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 220/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 220/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 221/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 221/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 221/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 221/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 221/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 221/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 221/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 221/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 221/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 221/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 222/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 222/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 222/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 222/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 222/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 222/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 222/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 222/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 222/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 222/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 223/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 223/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 223/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 223/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 223/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 223/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.7s\n",
      "[CV 4/5; 223/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 223/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 223/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 223/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 224/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 224/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 224/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 224/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 224/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 224/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.4s\n",
      "[CV 4/5; 224/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 224/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 224/256] START activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 224/256] END activation_function=linear, batch_size=40, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 225/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 225/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 225/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 225/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 225/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 225/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 225/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 225/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 225/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 225/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 226/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 226/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 226/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 226/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 226/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 226/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 226/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 226/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 226/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 226/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 227/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 227/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 227/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 227/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 227/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 227/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 227/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 227/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 227/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 227/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 228/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 228/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 228/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 228/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 228/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 228/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 228/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 228/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 228/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 228/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 229/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 229/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 229/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 229/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 229/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 229/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 229/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 229/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 229/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 229/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 230/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 230/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 230/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 230/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 230/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 230/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 230/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 230/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 230/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 230/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 231/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 231/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 231/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 231/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 231/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 231/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 231/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 231/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 231/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 231/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 232/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 232/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.0s\n",
      "[CV 2/5; 232/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 232/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 232/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 232/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 232/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 232/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 232/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 232/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 233/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 233/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 233/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 233/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   1.7s\n",
      "[CV 3/5; 233/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 233/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 233/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 233/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 233/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 233/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 234/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 234/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 234/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 234/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.0s\n",
      "[CV 3/5; 234/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 234/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 234/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 234/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 234/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 234/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 235/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 235/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   1.6s\n",
      "[CV 2/5; 235/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 235/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 235/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 235/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 235/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 235/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 235/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 235/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 236/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 236/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 236/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 236/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 236/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 236/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.0s\n",
      "[CV 4/5; 236/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 236/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 236/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 236/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   1.6s\n",
      "[CV 1/5; 237/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 237/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 237/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 237/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   1.6s\n",
      "[CV 3/5; 237/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 237/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 237/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 237/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 237/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 237/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 238/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 238/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 238/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 238/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 238/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 238/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 238/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 238/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.0s\n",
      "[CV 5/5; 238/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 238/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 239/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 239/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 239/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 239/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 239/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 239/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   1.6s\n",
      "[CV 4/5; 239/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 239/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   1.6s\n",
      "[CV 5/5; 239/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 239/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   1.5s\n",
      "[CV 1/5; 240/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 240/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   1.5s\n",
      "[CV 2/5; 240/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 240/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   1.5s\n",
      "[CV 3/5; 240/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 240/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   1.5s\n",
      "[CV 4/5; 240/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 240/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   1.5s\n",
      "[CV 5/5; 240/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 240/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.0s\n",
      "[CV 1/5; 241/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 241/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 241/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 241/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 241/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 241/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.2s\n",
      "[CV 4/5; 241/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 241/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 241/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 241/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 242/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 242/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 242/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 242/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 242/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 242/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 242/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 242/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 242/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 242/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 243/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 243/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.8s\n",
      "[CV 2/5; 243/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 243/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 243/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 243/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 243/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 243/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.4s\n",
      "[CV 5/5; 243/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 243/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 244/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 244/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 244/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 244/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 244/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 244/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 244/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 244/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 244/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 244/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 245/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 245/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.2s\n",
      "[CV 2/5; 245/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 245/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.7s\n",
      "[CV 3/5; 245/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 245/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 245/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 245/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 245/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 245/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 246/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 246/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 246/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 246/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 246/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 246/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 246/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 246/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 246/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 246/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 247/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 247/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 247/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 2/5; 247/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 247/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 247/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.8s\n",
      "[CV 4/5; 247/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 247/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 247/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 5/5; 247/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 248/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 248/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 248/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 248/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 248/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 248/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 248/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 248/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 248/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 248/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 249/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 249/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 249/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 249/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 249/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 249/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 249/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 249/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-4.955 total time=   2.2s\n",
      "[CV 5/5; 249/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 249/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=-5.345 total time=   2.8s\n",
      "[CV 1/5; 250/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 250/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 250/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 250/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 250/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 250/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 250/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 250/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 250/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 250/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 251/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 251/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 251/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 251/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 251/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 251/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 251/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 4/5; 251/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 251/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 251/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 252/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 252/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.893 total time=   2.8s\n",
      "[CV 2/5; 252/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 252/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 252/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 252/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 252/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 252/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 252/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 252/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 253/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 1/5; 253/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 253/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 253/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 253/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 253/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 253/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 253/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 253/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 253/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=-5.345 total time=   2.2s\n",
      "[CV 1/5; 254/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 254/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.893 total time=   2.7s\n",
      "[CV 2/5; 254/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 254/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 254/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 254/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 254/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 254/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 254/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 254/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 255/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 255/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 255/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 255/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-3.982 total time=   2.3s\n",
      "[CV 3/5; 255/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[CV 3/5; 255/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 255/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 255/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 255/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 255/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=-5.345 total time=   2.3s\n",
      "[CV 1/5; 256/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 1/5; 256/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.893 total time=   2.3s\n",
      "[CV 2/5; 256/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 2/5; 256/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-3.982 total time=   2.8s\n",
      "[CV 3/5; 256/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 3/5; 256/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.619 total time=   2.3s\n",
      "[CV 4/5; 256/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 4/5; 256/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-4.955 total time=   2.3s\n",
      "[CV 5/5; 256/256] START activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "[CV 5/5; 256/256] END activation_function=linear, batch_size=40, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=-5.345 total time=   2.3s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model, verbose = 0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "batch_size = [20, 40]\n",
    "epochs = [50, 100]\n",
    "learning_rate = [0.01, 0.1]\n",
    "dropout_rate = [0.1, 0.2]\n",
    "activation_function = ['relu','linear']\n",
    "init = ['uniform','normal']\n",
    "neuron1 = [4, 8]\n",
    "neuron2 = [2, 4]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(batch_size = batch_size, epochs = epochs, learning_rate = learning_rate, dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function, init = init, neuron1 = neuron1, neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grids, cv = KFold(), verbose = 10, scoring='neg_mean_squared_error')\n",
    "grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e925eb",
   "metadata": {},
   "source": [
    "### Summarize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e60a01b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : -4.758532348031901, using {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b605f",
   "metadata": {},
   "source": [
    "## Training model with optimum values of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26360b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Sequential()\n",
    "final_model.add(Dense(4, input_dim = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "final_model.add(Dropout(0.1))\n",
    "final_model.add(Dense(2, input_dim = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "final_model.add(Dropout(0.1))\n",
    "final_model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "adam = adam_v2.Adam(learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4990874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "\n",
    "final_model.compile(loss = 'mean_squared_error', optimizer = adam, metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfdb5d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 2ms/step - loss: 0.9921 - mse: 0.9921\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9808 - mse: 0.9808\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9803 - mse: 0.9803\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9808 - mse: 0.9808\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9812 - mse: 0.9812\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9800 - mse: 0.9800\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9818 - mse: 0.9818\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9806 - mse: 0.9806\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9798 - mse: 0.9798\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9799 - mse: 0.9799\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9800 - mse: 0.9800\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9796 - mse: 0.9796\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9802 - mse: 0.9802\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9801 - mse: 0.9801\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9804 - mse: 0.9804\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9805 - mse: 0.9805\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9805 - mse: 0.9805\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9800 - mse: 0.9800\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9806 - mse: 0.9806\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9807 - mse: 0.9807\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9797 - mse: 0.9797\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9798 - mse: 0.9798\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9807 - mse: 0.9807\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9798 - mse: 0.9798\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9812 - mse: 0.9812\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9800 - mse: 0.9800\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9801 - mse: 0.9801\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9820 - mse: 0.9820\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9801 - mse: 0.9801\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9806 - mse: 0.9806\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9797 - mse: 0.9797\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9804 - mse: 0.9804\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9813 - mse: 0.9813\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9804 - mse: 0.9804\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9798 - mse: 0.9798\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9800 - mse: 0.9800\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9801 - mse: 0.9801\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9810 - mse: 0.9810\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9799 - mse: 0.9799\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9805 - mse: 0.9805\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9797 - mse: 0.9797\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9806 - mse: 0.9806\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9806 - mse: 0.9806\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9804 - mse: 0.9804\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9798 - mse: 0.9798\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9806 - mse: 0.9806\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9801 - mse: 0.9801\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9806 - mse: 0.9806\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9802 - mse: 0.9802\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9802 - mse: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbc8a037c0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "final_model.fit(x_train, y_train, epochs=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85a00d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0482 - mse: 1.0482\n",
      "mse\n"
     ]
    }
   ],
   "source": [
    "scores = final_model.evaluate(x_test, y_test)\n",
    "print((final_model.metrics_names[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b38c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
